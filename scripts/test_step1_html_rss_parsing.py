#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""æ­¥é©Ÿ 1 HTML è§£æå’Œ RSS è™•ç†åŠŸèƒ½æ¸¬è©¦è…³æœ¬

æ­¤è…³æœ¬ç”¨æ–¼æ¸¬è©¦çµ±ä¸€ä¸‹è¼‰å™¨ä¸­æ–°å¯¦ç¾çš„ HTML è§£æå’Œ RSS è™•ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. è­‰äº¤æ‰€é‡å¤§è¨Šæ¯å…¬å‘Šè§£æ
2. è­‰äº¤æ‰€æ³•èªªæœƒæœŸç¨‹è§£æ
3. cnyes å°è‚¡æ–°è RSS è§£æ
4. æ«ƒè²·ä¸­å¿ƒèè³‡èåˆ¸ HTML è§£æ

Usage:
    python scripts/test_step1_html_rss_parsing.py
"""

import logging
import sys
from datetime import date, timedelta
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.unified_data_downloader import UnifiedDataDownloader
from src.data.twse_downloader import DownloadConfig

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/step1_html_rss_test.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)


def test_twse_material_news():
    """æ¸¬è©¦è­‰äº¤æ‰€é‡å¤§è¨Šæ¯å…¬å‘Šè§£æ"""
    logger.info("=== æ¸¬è©¦è­‰äº¤æ‰€é‡å¤§è¨Šæ¯å…¬å‘Šè§£æ ===")
    
    try:
        config = DownloadConfig(
            request_delay=2.0,
            max_retries=2,
            enable_cache=False
        )
        downloader = UnifiedDataDownloader(config)
        
        # æ¸¬è©¦æ—¥æœŸï¼ˆä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰
        test_date = date.today() - timedelta(days=1)
        while test_date.weekday() >= 5:  # è·³éé€±æœ«
            test_date -= timedelta(days=1)
        
        logger.info("æ¸¬è©¦æ—¥æœŸ: %s", test_date)
        
        # æ¸¬è©¦é‡å¤§è¨Šæ¯ä¸‹è¼‰
        result = downloader._download_twse_material_news("2330.TW", test_date)
        
        if result is not None and not result.empty:
            logger.info("âœ… é‡å¤§è¨Šæ¯è§£ææˆåŠŸ: %d ç­†è³‡æ–™", len(result))
            logger.info("è³‡æ–™æ¬„ä½: %s", list(result.columns))
            logger.info("å‰3ç­†è³‡æ–™:")
            logger.info("\n%s", result.head(3).to_string())
        else:
            logger.info("â„¹ï¸ ç•¶æ—¥ç„¡é‡å¤§è¨Šæ¯è³‡æ–™")
        
        return True
        
    except Exception as e:
        logger.error("âŒ é‡å¤§è¨Šæ¯è§£ææ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_twse_investor_conference():
    """æ¸¬è©¦è­‰äº¤æ‰€æ³•èªªæœƒæœŸç¨‹è§£æ"""
    logger.info("=== æ¸¬è©¦è­‰äº¤æ‰€æ³•èªªæœƒæœŸç¨‹è§£æ ===")
    
    try:
        config = DownloadConfig(request_delay=2.0, max_retries=2, enable_cache=False)
        downloader = UnifiedDataDownloader(config)
        
        # æ¸¬è©¦æ—¥æœŸ
        test_date = date.today()
        
        logger.info("æ¸¬è©¦æ—¥æœŸ: %s", test_date)
        
        # æ¸¬è©¦æ³•èªªæœƒæœŸç¨‹ä¸‹è¼‰
        result = downloader._download_twse_investor_conference("2330.TW", test_date)
        
        if result is not None and not result.empty:
            logger.info("âœ… æ³•èªªæœƒæœŸç¨‹è§£ææˆåŠŸ: %d ç­†è³‡æ–™", len(result))
            logger.info("è³‡æ–™æ¬„ä½: %s", list(result.columns))
        else:
            logger.info("â„¹ï¸ ç•¶æ—¥ç„¡æ³•èªªæœƒæœŸç¨‹è³‡æ–™")
        
        return True
        
    except Exception as e:
        logger.error("âŒ æ³•èªªæœƒæœŸç¨‹è§£ææ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_cnyes_stock_news():
    """æ¸¬è©¦ cnyes å°è‚¡æ–°è RSS è§£æ"""
    logger.info("=== æ¸¬è©¦ cnyes å°è‚¡æ–°è RSS è§£æ ===")
    
    try:
        config = DownloadConfig(request_delay=1.0, max_retries=2, enable_cache=False)
        downloader = UnifiedDataDownloader(config)
        
        # æ¸¬è©¦æ—¥æœŸï¼ˆä½¿ç”¨ä»Šå¤©ï¼Œæ–°èé€šå¸¸ç•¶å¤©å°±æœ‰ï¼‰
        test_date = date.today()
        
        logger.info("æ¸¬è©¦æ—¥æœŸ: %s", test_date)
        
        # æ¸¬è©¦æ–°èä¸‹è¼‰
        result = downloader._download_cnyes_stock_news(test_date)
        
        if result is not None and not result.empty:
            logger.info("âœ… å°è‚¡æ–°è RSS è§£ææˆåŠŸ: %d ç­†è³‡æ–™", len(result))
            logger.info("è³‡æ–™æ¬„ä½: %s", list(result.columns))
            logger.info("å‰3ç­†æ–°èæ¨™é¡Œ:")
            for i, row in result.head(3).iterrows():
                logger.info("  %d. %s", i+1, row.get('title', 'N/A'))
        else:
            logger.info("â„¹ï¸ ç•¶æ—¥ç„¡å°è‚¡æ–°èè³‡æ–™")
        
        return True
        
    except Exception as e:
        logger.error("âŒ å°è‚¡æ–°è RSS è§£ææ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_tpex_margin_parsing():
    """æ¸¬è©¦æ«ƒè²·ä¸­å¿ƒèè³‡èåˆ¸è§£æ"""
    logger.info("=== æ¸¬è©¦æ«ƒè²·ä¸­å¿ƒèè³‡èåˆ¸è§£æ ===")
    
    try:
        config = DownloadConfig(request_delay=2.0, max_retries=2, enable_cache=False)
        downloader = UnifiedDataDownloader(config)
        
        # æ¸¬è©¦æ—¥æœŸï¼ˆä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰
        test_date = date.today() - timedelta(days=1)
        while test_date.weekday() >= 5:  # è·³éé€±æœ«
            test_date -= timedelta(days=1)
        
        logger.info("æ¸¬è©¦æ—¥æœŸ: %s", test_date)
        
        # æ¸¬è©¦æ«ƒè²·èè³‡èåˆ¸ä¸‹è¼‰ï¼ˆä½¿ç”¨æ«ƒè²·è‚¡ç¥¨ä»£ç¢¼ï¼‰
        result = downloader._download_tpex_margin("6488.TW", test_date)
        
        if result is not None and not result.empty:
            logger.info("âœ… æ«ƒè²·èè³‡èåˆ¸è§£ææˆåŠŸ: %d ç­†è³‡æ–™", len(result))
            logger.info("è³‡æ–™æ¬„ä½: %s", list(result.columns))
            logger.info("å‰3ç­†è³‡æ–™:")
            logger.info("\n%s", result.head(3).to_string())
        else:
            logger.info("â„¹ï¸ ç•¶æ—¥ç„¡æ«ƒè²·èè³‡èåˆ¸è³‡æ–™")
        
        return True
        
    except Exception as e:
        logger.error("âŒ æ«ƒè²·èè³‡èåˆ¸è§£ææ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_stock_symbol_extraction():
    """æ¸¬è©¦è‚¡ç¥¨ä»£ç¢¼æå–åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦è‚¡ç¥¨ä»£ç¢¼æå–åŠŸèƒ½ ===")
    
    try:
        config = DownloadConfig()
        downloader = UnifiedDataDownloader(config)
        
        # æ¸¬è©¦æ–‡æœ¬
        test_texts = [
            "å°ç©é›»(2330)ä»Šæ—¥è‚¡åƒ¹ä¸Šæ¼²",
            "é´»æµ·(2317)èˆ‡è¯ç™¼ç§‘(2454)åˆä½œ",
            "å¤§ç«‹å…‰3008è‚¡åƒ¹å‰µæ–°é«˜",
            "ç„¡è‚¡ç¥¨ä»£ç¢¼çš„æ–°èå…§å®¹",
            "1234 æ˜¯ç„¡æ•ˆä»£ç¢¼ï¼Œ2330 æ˜¯æœ‰æ•ˆä»£ç¢¼"
        ]
        
        for text in test_texts:
            symbols = downloader._extract_stock_symbols_from_text(text)
            logger.info("æ–‡æœ¬: %s", text)
            logger.info("æå–çš„è‚¡ç¥¨ä»£ç¢¼: %s", symbols)
            logger.info("---")
        
        logger.info("âœ… è‚¡ç¥¨ä»£ç¢¼æå–åŠŸèƒ½æ¸¬è©¦å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error("âŒ è‚¡ç¥¨ä»£ç¢¼æå–åŠŸèƒ½æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_unified_event_data_download():
    """æ¸¬è©¦çµ±ä¸€äº‹ä»¶é¢è³‡æ–™ä¸‹è¼‰"""
    logger.info("=== æ¸¬è©¦çµ±ä¸€äº‹ä»¶é¢è³‡æ–™ä¸‹è¼‰ ===")
    
    try:
        config = DownloadConfig(
            request_delay=1.5,
            max_retries=2,
            enable_cache=False,
            enable_parallel=False  # æ¸¬è©¦æ™‚ä½¿ç”¨åºåˆ—ä¸‹è¼‰
        )
        downloader = UnifiedDataDownloader(config)
        
        # æ¸¬è©¦æ—¥æœŸ
        test_date = date.today()
        
        # æ¸¬è©¦äº‹ä»¶é¢è³‡æ–™é¡å‹
        event_types = ["stock_news"]  # å…ˆæ¸¬è©¦æœ€å®¹æ˜“æˆåŠŸçš„
        
        for event_type in event_types:
            logger.info("æ¸¬è©¦äº‹ä»¶é¢è³‡æ–™é¡å‹: %s", event_type)
            
            try:
                result = downloader.download_data_type(
                    category="event",
                    data_type=event_type,
                    start_date=test_date.strftime("%Y-%m-%d"),
                    end_date=test_date.strftime("%Y-%m-%d"),
                    check_existing_data=False
                )
                
                logger.info("ä¸‹è¼‰çµæœ: %s", result)
                
            except Exception as e:
                logger.warning("äº‹ä»¶é¢è³‡æ–™é¡å‹ %s ä¸‹è¼‰å¤±æ•—: %s", event_type, e)
        
        logger.info("âœ… çµ±ä¸€äº‹ä»¶é¢è³‡æ–™ä¸‹è¼‰æ¸¬è©¦å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error("âŒ çµ±ä¸€äº‹ä»¶é¢è³‡æ–™ä¸‹è¼‰æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("é–‹å§‹æ­¥é©Ÿ 1 HTML è§£æå’Œ RSS è™•ç†åŠŸèƒ½æ¸¬è©¦")
    
    # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
    Path("logs").mkdir(exist_ok=True)
    
    test_results = []
    
    # åŸ·è¡Œå„é …æ¸¬è©¦
    test_results.append(("è­‰äº¤æ‰€é‡å¤§è¨Šæ¯è§£æ", test_twse_material_news()))
    test_results.append(("è­‰äº¤æ‰€æ³•èªªæœƒæœŸç¨‹è§£æ", test_twse_investor_conference()))
    test_results.append(("cnyes å°è‚¡æ–°è RSS è§£æ", test_cnyes_stock_news()))
    test_results.append(("æ«ƒè²·ä¸­å¿ƒèè³‡èåˆ¸è§£æ", test_tpex_margin_parsing()))
    test_results.append(("è‚¡ç¥¨ä»£ç¢¼æå–åŠŸèƒ½", test_stock_symbol_extraction()))
    test_results.append(("çµ±ä¸€äº‹ä»¶é¢è³‡æ–™ä¸‹è¼‰", test_unified_event_data_download()))
    
    # è¼¸å‡ºæ¸¬è©¦çµæœ
    logger.info("=== æ­¥é©Ÿ 1 æ¸¬è©¦çµæœæ‘˜è¦ ===")
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        logger.info("%s: %s", test_name, status)
        if result:
            passed += 1
    
    logger.info("ç¸½è¨ˆ: %d/%d æ¸¬è©¦é€šé", passed, total)
    
    if passed >= total * 0.8:  # 80% é€šéç‡è¦–ç‚ºæˆåŠŸ
        logger.info("ğŸ‰ æ­¥é©Ÿ 1 HTML è§£æå’Œ RSS è™•ç†åŠŸèƒ½åŸºæœ¬å®Œæˆï¼")
        return 0
    else:
        logger.error("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦é€²ä¸€æ­¥èª¿æ•´å¯¦ç¾")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
