#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""æ­¥é©Ÿ 2 è³‡æ–™åº«æ¨¡å‹å’Œ UPSERT æ©Ÿåˆ¶æ¸¬è©¦è…³æœ¬

æ­¤è…³æœ¬ç”¨æ–¼æ¸¬è©¦æ“´å±•çš„è³‡æ–™åº«æ¨¡å‹å’Œ UPSERT æ©Ÿåˆ¶ï¼ŒåŒ…æ‹¬ï¼š
1. ChipData æ¨¡å‹çš„æ–°æ¬„ä½
2. ImportantNews æ¨¡å‹çš„æ–°æ¬„ä½
3. upsert_chip_data åŠŸèƒ½
4. upsert_important_news åŠŸèƒ½
5. çµ±ä¸€ä¸‹è¼‰å™¨çš„è³‡æ–™ä¿å­˜åŠŸèƒ½

Usage:
    python scripts/test_step2_database_upsert.py
"""

import logging
import sys
from datetime import date, datetime, timedelta
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.unified_data_downloader import UnifiedDataDownloader
from src.data.twse_downloader import DownloadConfig

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/step2_database_test.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)


def test_chip_data_model():
    """æ¸¬è©¦ ChipData æ¨¡å‹çš„æ–°æ¬„ä½"""
    logger.info("=== æ¸¬è©¦ ChipData æ¨¡å‹çš„æ–°æ¬„ä½ ===")
    
    try:
        from src.database.models.integration_models import ChipData
        
        # æª¢æŸ¥æ–°æ¬„ä½æ˜¯å¦å­˜åœ¨
        new_fields = [
            'margin_buy', 'margin_sell', 'short_sell', 'short_cover',
            'foreign_holding_ratio', 'foreign_holding_shares',
            'broker_id', 'broker_name', 'buy_amount', 'sell_amount', 'net_amount'
        ]
        
        chip_data_columns = [col.name for col in ChipData.__table__.columns]
        logger.info("ChipData æ¨¡å‹æ¬„ä½: %s", chip_data_columns)
        
        missing_fields = [field for field in new_fields if field not in chip_data_columns]
        if missing_fields:
            logger.warning("âš ï¸ ç¼ºå°‘æ¬„ä½: %s", missing_fields)
        else:
            logger.info("âœ… æ‰€æœ‰æ–°æ¬„ä½éƒ½å·²æ·»åŠ ")
        
        # æ¸¬è©¦å‰µå»º ChipData å¯¦ä¾‹
        test_data = ChipData(
            symbol='2330.TW',
            date=date.today(),
            margin_buy=1000000,
            margin_sell=500000,
            foreign_holding_ratio=75.5,
            broker_id='1234',
            broker_name='æ¸¬è©¦åˆ¸å•†'
        )
        
        logger.info("âœ… ChipData å¯¦ä¾‹å‰µå»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error("âŒ ChipData æ¨¡å‹æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_important_news_model():
    """æ¸¬è©¦ ImportantNews æ¨¡å‹çš„æ–°æ¬„ä½"""
    logger.info("=== æ¸¬è©¦ ImportantNews æ¨¡å‹çš„æ–°æ¬„ä½ ===")
    
    try:
        from src.database.models.integration_models import ImportantNews
        
        # æª¢æŸ¥æ–°æ¬„ä½æ˜¯å¦å­˜åœ¨
        new_fields = [
            'event_type', 'publish_date', 'publish_time', 
            'location', 'stock_symbols', 'summary'
        ]
        
        news_columns = [col.name for col in ImportantNews.__table__.columns]
        logger.info("ImportantNews æ¨¡å‹æ¬„ä½: %s", news_columns)
        
        missing_fields = [field for field in new_fields if field not in news_columns]
        if missing_fields:
            logger.warning("âš ï¸ ç¼ºå°‘æ¬„ä½: %s", missing_fields)
        else:
            logger.info("âœ… æ‰€æœ‰æ–°æ¬„ä½éƒ½å·²æ·»åŠ ")
        
        # æ¸¬è©¦å‰µå»º ImportantNews å¯¦ä¾‹
        test_news = ImportantNews(
            title='æ¸¬è©¦æ–°è',
            announce_date=datetime.now(),
            category='test',
            source='test_source',
            event_type='stock_news',
            publish_date=date.today(),
            stock_symbols='2330.TW,2317.TW'
        )
        
        logger.info("âœ… ImportantNews å¯¦ä¾‹å‰µå»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error("âŒ ImportantNews æ¨¡å‹æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_upsert_chip_data():
    """æ¸¬è©¦ upsert_chip_data åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦ upsert_chip_data åŠŸèƒ½ ===")
    
    try:
        from src.utils.database_utils import upsert_chip_data
        
        # æº–å‚™æ¸¬è©¦è³‡æ–™
        test_chip_data = [
            {
                'symbol': '2330.TW',
                'date': date.today(),
                'margin_buy': 1000000,
                'margin_sell': 500000,
                'foreign_holding_ratio': 75.5,
                'source': 'TEST'
            },
            {
                'symbol': '2317.TW',
                'date': date.today(),
                'margin_buy': 800000,
                'margin_sell': 400000,
                'foreign_holding_ratio': 65.2,
                'source': 'TEST'
            }
        ]
        
        # åŸ·è¡Œ UPSERT
        result = upsert_chip_data(test_chip_data)
        
        if result > 0:
            logger.info("âœ… upsert_chip_data æˆåŠŸ: %d ç­†è¨˜éŒ„", result)
        else:
            logger.warning("âš ï¸ upsert_chip_data æ²’æœ‰è™•ç†ä»»ä½•è¨˜éŒ„")
        
        return True
        
    except Exception as e:
        logger.error("âŒ upsert_chip_data æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_upsert_important_news():
    """æ¸¬è©¦ upsert_important_news åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦ upsert_important_news åŠŸèƒ½ ===")
    
    try:
        from src.utils.database_utils import upsert_important_news
        
        # æº–å‚™æ¸¬è©¦è³‡æ–™
        test_news_data = [
            {
                'title': 'æ¸¬è©¦é‡å¤§è¨Šæ¯ 1',
                'announce_date': datetime.now(),
                'category': 'test',
                'source': 'TEST',
                'event_type': 'material_news',
                'symbol': '2330.TW',
                'importance_level': 5
            },
            {
                'title': 'æ¸¬è©¦å°è‚¡æ–°è 1',
                'announce_date': datetime.now(),
                'category': 'test',
                'source': 'TEST',
                'event_type': 'stock_news',
                'stock_symbols': '2330.TW,2317.TW',
                'importance_level': 3
            }
        ]
        
        # åŸ·è¡Œ UPSERT
        result = upsert_important_news(test_news_data)
        
        if result > 0:
            logger.info("âœ… upsert_important_news æˆåŠŸ: %d ç­†è¨˜éŒ„", result)
        else:
            logger.warning("âš ï¸ upsert_important_news æ²’æœ‰è™•ç†ä»»ä½•è¨˜éŒ„")
        
        return True
        
    except Exception as e:
        logger.error("âŒ upsert_important_news æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_unified_downloader_save():
    """æ¸¬è©¦çµ±ä¸€ä¸‹è¼‰å™¨çš„è³‡æ–™ä¿å­˜åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦çµ±ä¸€ä¸‹è¼‰å™¨çš„è³‡æ–™ä¿å­˜åŠŸèƒ½ ===")
    
    try:
        config = DownloadConfig(
            request_delay=1.0,
            max_retries=1,
            enable_cache=False
        )
        downloader = UnifiedDataDownloader(config)
        
        # æ¸¬è©¦ç±Œç¢¼é¢è³‡æ–™ä¿å­˜
        import pandas as pd
        
        chip_test_data = pd.DataFrame([
            {
                'symbol': '2330.TW',
                'date': date.today(),
                'margin_buy': 1500000,
                'margin_sell': 750000,
                'data_source': 'TEST_CHIP'
            }
        ])
        
        chip_result = downloader._save_chip_data(chip_test_data, 'institutional_trading')
        logger.info("ç±Œç¢¼é¢è³‡æ–™ä¿å­˜çµæœ: %d ç­†", chip_result)
        
        # æ¸¬è©¦äº‹ä»¶é¢è³‡æ–™ä¿å­˜
        event_test_data = pd.DataFrame([
            {
                'title': 'çµ±ä¸€ä¸‹è¼‰å™¨æ¸¬è©¦æ–°è',
                'announce_date': datetime.now(),
                'data_source': 'TEST_EVENT',
                'event_type': 'stock_news'
            }
        ])
        
        event_result = downloader._save_event_data(event_test_data, 'stock_news')
        logger.info("äº‹ä»¶é¢è³‡æ–™ä¿å­˜çµæœ: %d ç­†", event_result)
        
        if chip_result > 0 and event_result > 0:
            logger.info("âœ… çµ±ä¸€ä¸‹è¼‰å™¨è³‡æ–™ä¿å­˜åŠŸèƒ½æ­£å¸¸")
        else:
            logger.warning("âš ï¸ çµ±ä¸€ä¸‹è¼‰å™¨è³‡æ–™ä¿å­˜åŠŸèƒ½å¯èƒ½æœ‰å•é¡Œ")
        
        return True
        
    except Exception as e:
        logger.error("âŒ çµ±ä¸€ä¸‹è¼‰å™¨è³‡æ–™ä¿å­˜æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_data_validation():
    """æ¸¬è©¦è³‡æ–™é©—è­‰åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦è³‡æ–™é©—è­‰åŠŸèƒ½ ===")
    
    try:
        config = DownloadConfig()
        downloader = UnifiedDataDownloader(config)
        
        import pandas as pd
        
        # æ¸¬è©¦æœ‰æ•ˆè³‡æ–™
        valid_data = pd.DataFrame([
            {'symbol': '2330.TW', 'date': date.today(), 'value': 100},
            {'symbol': '2317.TW', 'date': date.today(), 'value': 200}
        ])
        
        required_fields = ['symbol', 'date']
        validated = downloader._validate_data_fields(valid_data, required_fields)
        
        logger.info("æœ‰æ•ˆè³‡æ–™é©—è­‰: åŸå§‹ %d ç­† -> é©—è­‰å¾Œ %d ç­†", len(valid_data), len(validated))
        
        # æ¸¬è©¦ç„¡æ•ˆè³‡æ–™
        invalid_data = pd.DataFrame([
            {'symbol': None, 'date': None, 'value': None},
            {'symbol': '2330.TW', 'date': date.today(), 'value': 100}
        ])
        
        validated_invalid = downloader._validate_data_fields(invalid_data, required_fields)
        logger.info("ç„¡æ•ˆè³‡æ–™é©—è­‰: åŸå§‹ %d ç­† -> é©—è­‰å¾Œ %d ç­†", len(invalid_data), len(validated_invalid))
        
        logger.info("âœ… è³‡æ–™é©—è­‰åŠŸèƒ½æ­£å¸¸")
        return True
        
    except Exception as e:
        logger.error("âŒ è³‡æ–™é©—è­‰æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("é–‹å§‹æ­¥é©Ÿ 2 è³‡æ–™åº«æ¨¡å‹å’Œ UPSERT æ©Ÿåˆ¶æ¸¬è©¦")
    
    # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
    Path("logs").mkdir(exist_ok=True)
    
    test_results = []
    
    # åŸ·è¡Œå„é …æ¸¬è©¦
    test_results.append(("ChipData æ¨¡å‹æ–°æ¬„ä½", test_chip_data_model()))
    test_results.append(("ImportantNews æ¨¡å‹æ–°æ¬„ä½", test_important_news_model()))
    test_results.append(("upsert_chip_data åŠŸèƒ½", test_upsert_chip_data()))
    test_results.append(("upsert_important_news åŠŸèƒ½", test_upsert_important_news()))
    test_results.append(("çµ±ä¸€ä¸‹è¼‰å™¨è³‡æ–™ä¿å­˜", test_unified_downloader_save()))
    test_results.append(("è³‡æ–™é©—è­‰åŠŸèƒ½", test_data_validation()))
    
    # è¼¸å‡ºæ¸¬è©¦çµæœ
    logger.info("=== æ­¥é©Ÿ 2 æ¸¬è©¦çµæœæ‘˜è¦ ===")
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        logger.info("%s: %s", test_name, status)
        if result:
            passed += 1
    
    logger.info("ç¸½è¨ˆ: %d/%d æ¸¬è©¦é€šé", passed, total)
    
    if passed >= total * 0.8:  # 80% é€šéç‡è¦–ç‚ºæˆåŠŸ
        logger.info("ğŸ‰ æ­¥é©Ÿ 2 è³‡æ–™åº«æ¨¡å‹å’Œ UPSERT æ©Ÿåˆ¶åŸºæœ¬å®Œæˆï¼")
        return 0
    else:
        logger.error("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦é€²ä¸€æ­¥èª¿æ•´å¯¦ç¾")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
