#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""çµ±ä¸€ä¸‹è¼‰å™¨æ“´å±•åŠŸèƒ½æ¸¬è©¦è…³æœ¬

æ­¤è…³æœ¬ç”¨æ–¼æ¸¬è©¦çµ±ä¸€ä¸‹è¼‰å™¨çš„æ“´å±•åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. ç±Œç¢¼é¢è³‡æ–™ä¸‹è¼‰åŠŸèƒ½
2. äº‹ä»¶é¢è³‡æ–™ä¸‹è¼‰åŠŸèƒ½  
3. ä¸¦è¡Œä¸‹è¼‰å’Œå¿«å–æ©Ÿåˆ¶
4. æ•ˆèƒ½å„ªåŒ–é©—è­‰

Usage:
    python scripts/test_unified_downloader_extended.py
"""

import logging
import sys
import time
from datetime import date, timedelta
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.unified_data_downloader import UnifiedDataDownloader
from src.data.twse_downloader import DownloadConfig
from src.data.data_integration_system import DataIntegrationSystem

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/unified_downloader_extended_test.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)


def test_chip_data_types():
    """æ¸¬è©¦ç±Œç¢¼é¢è³‡æ–™é¡å‹æ”¯æ´"""
    logger.info("=== æ¸¬è©¦ç±Œç¢¼é¢è³‡æ–™é¡å‹æ”¯æ´ ===")
    
    try:
        config = DownloadConfig(
            request_delay=1.0,
            max_retries=2,
            enable_resume=False
        )
        downloader = UnifiedDataDownloader(config)
        
        # æª¢æŸ¥ç±Œç¢¼é¢è³‡æ–™é¡å‹
        supported_types = downloader.get_supported_data_types()
        chip_types = supported_types.get("chip", [])
        
        expected_chip_types = [
            "institutional_trading",
            "margin_trading", 
            "foreign_holding",
            "broker_trading"
        ]
        
        logger.info("ç±Œç¢¼é¢æ”¯æ´çš„è³‡æ–™é¡å‹: %s", chip_types)
        
        for expected in expected_chip_types:
            if expected in chip_types:
                logger.info("âœ… ç±Œç¢¼é¢è³‡æ–™é¡å‹ %s æ”¯æ´", expected)
            else:
                logger.warning("âš ï¸ ç±Œç¢¼é¢è³‡æ–™é¡å‹ %s ä¸æ”¯æ´", expected)
        
        # æ¸¬è©¦ç±Œç¢¼é¢è³‡æ–™ä¾†æºé…ç½®
        for chip_type in chip_types:
            sources = downloader.get_data_sources_for_type(chip_type)
            logger.info("è³‡æ–™é¡å‹ %s çš„è³‡æ–™ä¾†æº: %d å€‹", chip_type, len(sources))
            for source in sources:
                logger.info("  - %s (å„ªå…ˆç´š: %d)", source.name, source.priority)
        
        return True
        
    except Exception as e:
        logger.error("âŒ ç±Œç¢¼é¢è³‡æ–™é¡å‹æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_event_data_types():
    """æ¸¬è©¦äº‹ä»¶é¢è³‡æ–™é¡å‹æ”¯æ´"""
    logger.info("=== æ¸¬è©¦äº‹ä»¶é¢è³‡æ–™é¡å‹æ”¯æ´ ===")
    
    try:
        config = DownloadConfig(request_delay=1.0, max_retries=2)
        downloader = UnifiedDataDownloader(config)
        
        # æª¢æŸ¥äº‹ä»¶é¢è³‡æ–™é¡å‹
        supported_types = downloader.get_supported_data_types()
        event_types = supported_types.get("event", [])
        
        expected_event_types = [
            "material_news",
            "investor_conference",
            "stock_news", 
            "dividend_announcement_events"
        ]
        
        logger.info("äº‹ä»¶é¢æ”¯æ´çš„è³‡æ–™é¡å‹: %s", event_types)
        
        for expected in expected_event_types:
            if expected in event_types:
                logger.info("âœ… äº‹ä»¶é¢è³‡æ–™é¡å‹ %s æ”¯æ´", expected)
            else:
                logger.warning("âš ï¸ äº‹ä»¶é¢è³‡æ–™é¡å‹ %s ä¸æ”¯æ´", expected)
        
        # æ¸¬è©¦äº‹ä»¶é¢è³‡æ–™ä¾†æºé…ç½®
        for event_type in event_types:
            sources = downloader.get_data_sources_for_type(event_type)
            logger.info("è³‡æ–™é¡å‹ %s çš„è³‡æ–™ä¾†æº: %d å€‹", event_type, len(sources))
        
        return True
        
    except Exception as e:
        logger.error("âŒ äº‹ä»¶é¢è³‡æ–™é¡å‹æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_cache_functionality():
    """æ¸¬è©¦å¿«å–åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦å¿«å–åŠŸèƒ½ ===")
    
    try:
        # å•Ÿç”¨å¿«å–çš„é…ç½®
        config = DownloadConfig(
            request_delay=0.5,
            max_retries=1,
            enable_cache=True,
            cache_expire_hours=1
        )
        downloader = UnifiedDataDownloader(config)
        
        # æª¢æŸ¥å¿«å–ç›®éŒ„
        cache_dir = downloader.cache_dir
        logger.info("å¿«å–ç›®éŒ„: %s", cache_dir)
        logger.info("å¿«å–å•Ÿç”¨: %s", downloader.enable_cache)
        logger.info("å¿«å–éæœŸæ™‚é–“: %d å°æ™‚", downloader.cache_expire_hours)
        
        # æ¸¬è©¦å¿«å–éµå€¼ç”Ÿæˆ
        test_date = date.today() - timedelta(days=1)
        cache_key = downloader._get_cache_key("technical", "2330.TW", test_date)
        logger.info("æ¸¬è©¦å¿«å–éµå€¼: %s", cache_key)
        
        # æ¸¬è©¦å¿«å–è·¯å¾‘
        cache_path = downloader._get_cache_path(cache_key)
        logger.info("å¿«å–æª”æ¡ˆè·¯å¾‘: %s", cache_path)
        
        # æ¸¬è©¦å¿«å–æœ‰æ•ˆæ€§æª¢æŸ¥
        is_valid = downloader._is_cache_valid(cache_path)
        logger.info("å¿«å–æœ‰æ•ˆæ€§: %s", is_valid)
        
        # æ¸¬è©¦æ¸…ç†éæœŸå¿«å–
        downloader._clean_expired_cache()
        logger.info("âœ… å¿«å–åŠŸèƒ½æ¸¬è©¦å®Œæˆ")
        
        return True
        
    except Exception as e:
        logger.error("âŒ å¿«å–åŠŸèƒ½æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_parallel_download():
    """æ¸¬è©¦ä¸¦è¡Œä¸‹è¼‰åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦ä¸¦è¡Œä¸‹è¼‰åŠŸèƒ½ ===")
    
    try:
        # å•Ÿç”¨ä¸¦è¡Œä¸‹è¼‰çš„é…ç½®
        config = DownloadConfig(
            request_delay=0.5,
            max_retries=1,
            enable_parallel=True,
            max_workers=2,
            enable_cache=True
        )
        downloader = UnifiedDataDownloader(config)
        
        logger.info("ä¸¦è¡Œä¸‹è¼‰å•Ÿç”¨: %s", downloader.enable_parallel)
        logger.info("æœ€å¤§å·¥ä½œè€…æ•¸é‡: %d", downloader.max_workers)
        
        # æ¸¬è©¦ä¸¦è¡Œä¸‹è¼‰ï¼ˆä½¿ç”¨è¼ƒå°‘çš„è‚¡ç¥¨å’Œè¼ƒçŸ­çš„æ™‚é–“ç¯„åœï¼‰
        end_date = date.today()
        start_date = end_date - timedelta(days=2)
        
        test_symbols = ["2330.TW", "2317.TW"]  # å°ç©é›»ã€é´»æµ·
        
        logger.info("æ¸¬è©¦ä¸¦è¡Œä¸‹è¼‰æŠ€è¡“é¢è³‡æ–™...")
        start_time = time.time()
        
        try:
            result = downloader.download_data_type(
                category="technical",
                data_type="odd_lot_trading",
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d"),
                symbols=test_symbols,
                check_existing_data=False  # è·³éå­˜åœ¨æ€§æª¢æŸ¥ä»¥ç°¡åŒ–æ¸¬è©¦
            )
            
            end_time = time.time()
            download_time = end_time - start_time
            
            logger.info("âœ… ä¸¦è¡Œä¸‹è¼‰å®Œæˆ")
            logger.info("ä¸‹è¼‰æ™‚é–“: %.2f ç§’", download_time)
            logger.info("ä¸‹è¼‰çµæœ: %s", result)
            
            # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸¦è¡Œä¸‹è¼‰
            if result.get('parallel_enabled'):
                logger.info("âœ… ä¸¦è¡Œä¸‹è¼‰æ©Ÿåˆ¶å·²å•Ÿç”¨")
            else:
                logger.info("â„¹ï¸ ä½¿ç”¨åºåˆ—ä¸‹è¼‰ï¼ˆå¯èƒ½å› ç‚ºè‚¡ç¥¨æ•¸é‡å¤ªå°‘ï¼‰")
            
        except Exception as e:
            logger.warning("âš ï¸ ä¸¦è¡Œä¸‹è¼‰æ¸¬è©¦å¤±æ•—: %s", e)
        
        return True
        
    except Exception as e:
        logger.error("âŒ ä¸¦è¡Œä¸‹è¼‰åŠŸèƒ½æ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_performance_comparison():
    """æ¸¬è©¦æ•ˆèƒ½æ¯”è¼ƒï¼ˆåºåˆ— vs ä¸¦è¡Œï¼‰"""
    logger.info("=== æ¸¬è©¦æ•ˆèƒ½æ¯”è¼ƒ ===")
    
    try:
        test_symbols = ["2330.TW", "2317.TW", "2454.TW"]  # 3å€‹è‚¡ç¥¨
        end_date = date.today()
        start_date = end_date - timedelta(days=1)
        
        # æ¸¬è©¦åºåˆ—ä¸‹è¼‰
        logger.info("æ¸¬è©¦åºåˆ—ä¸‹è¼‰...")
        config_serial = DownloadConfig(
            request_delay=0.3,
            max_retries=1,
            enable_parallel=False,
            enable_cache=False
        )
        downloader_serial = UnifiedDataDownloader(config_serial)
        
        start_time = time.time()
        try:
            result_serial = downloader_serial.download_data_type(
                category="technical",
                data_type="benchmark_index",
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d"),
                symbols=test_symbols,
                check_existing_data=False
            )
            serial_time = time.time() - start_time
            logger.info("åºåˆ—ä¸‹è¼‰æ™‚é–“: %.2f ç§’", serial_time)
        except Exception as e:
            logger.warning("åºåˆ—ä¸‹è¼‰æ¸¬è©¦å¤±æ•—: %s", e)
            serial_time = 0
        
        # æ¸¬è©¦ä¸¦è¡Œä¸‹è¼‰
        logger.info("æ¸¬è©¦ä¸¦è¡Œä¸‹è¼‰...")
        config_parallel = DownloadConfig(
            request_delay=0.3,
            max_retries=1,
            enable_parallel=True,
            max_workers=3,
            enable_cache=False
        )
        downloader_parallel = UnifiedDataDownloader(config_parallel)
        
        start_time = time.time()
        try:
            result_parallel = downloader_parallel.download_data_type(
                category="technical",
                data_type="benchmark_index",
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d"),
                symbols=test_symbols,
                check_existing_data=False
            )
            parallel_time = time.time() - start_time
            logger.info("ä¸¦è¡Œä¸‹è¼‰æ™‚é–“: %.2f ç§’", parallel_time)
        except Exception as e:
            logger.warning("ä¸¦è¡Œä¸‹è¼‰æ¸¬è©¦å¤±æ•—: %s", e)
            parallel_time = 0
        
        # æ•ˆèƒ½æ¯”è¼ƒ
        if serial_time > 0 and parallel_time > 0:
            speedup = serial_time / parallel_time
            logger.info("æ•ˆèƒ½æå‡: %.2fx", speedup)
            if speedup > 1.2:
                logger.info("âœ… ä¸¦è¡Œä¸‹è¼‰é¡¯è‘—æå‡æ•ˆèƒ½")
            else:
                logger.info("â„¹ï¸ ä¸¦è¡Œä¸‹è¼‰æ•ˆèƒ½æå‡æœ‰é™ï¼ˆå¯èƒ½å› ç‚ºç¶²è·¯å»¶é²ï¼‰")
        
        return True
        
    except Exception as e:
        logger.error("âŒ æ•ˆèƒ½æ¯”è¼ƒæ¸¬è©¦å¤±æ•—: %s", e)
        return False


def test_integration_with_system():
    """æ¸¬è©¦èˆ‡è³‡æ–™æ•´åˆç³»çµ±çš„æ•´åˆ"""
    logger.info("=== æ¸¬è©¦èˆ‡è³‡æ–™æ•´åˆç³»çµ±çš„æ•´åˆ ===")
    
    try:
        system = DataIntegrationSystem()
        
        # æª¢æŸ¥æ–°çš„è³‡æ–™é¡å‹æ˜¯å¦æ­£ç¢ºæ•´åˆ
        supported_types = system.get_supported_data_types()
        logger.info("ç³»çµ±æ”¯æ´çš„è³‡æ–™é¡å‹:")
        for category, types in supported_types.items():
            logger.info("  %s: %s", category, types)
        
        # æª¢æŸ¥ç±Œç¢¼é¢å’Œäº‹ä»¶é¢æ˜¯å¦æ”¯æ´
        if "chip" in supported_types:
            logger.info("âœ… ç±Œç¢¼é¢è³‡æ–™å·²æ•´åˆåˆ°ç³»çµ±")
        else:
            logger.warning("âš ï¸ ç±Œç¢¼é¢è³‡æ–™æœªæ•´åˆåˆ°ç³»çµ±")
        
        if "event" in supported_types:
            logger.info("âœ… äº‹ä»¶é¢è³‡æ–™å·²æ•´åˆåˆ°ç³»çµ±")
        else:
            logger.warning("âš ï¸ äº‹ä»¶é¢è³‡æ–™æœªæ•´åˆåˆ°ç³»çµ±")
        
        return True
        
    except Exception as e:
        logger.error("âŒ ç³»çµ±æ•´åˆæ¸¬è©¦å¤±æ•—: %s", e)
        return False


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("é–‹å§‹çµ±ä¸€ä¸‹è¼‰å™¨æ“´å±•åŠŸèƒ½æ¸¬è©¦")
    
    # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
    Path("logs").mkdir(exist_ok=True)
    
    test_results = []
    
    # åŸ·è¡Œå„é …æ¸¬è©¦
    test_results.append(("ç±Œç¢¼é¢è³‡æ–™é¡å‹æ”¯æ´", test_chip_data_types()))
    test_results.append(("äº‹ä»¶é¢è³‡æ–™é¡å‹æ”¯æ´", test_event_data_types()))
    test_results.append(("å¿«å–åŠŸèƒ½", test_cache_functionality()))
    test_results.append(("ä¸¦è¡Œä¸‹è¼‰åŠŸèƒ½", test_parallel_download()))
    test_results.append(("æ•ˆèƒ½æ¯”è¼ƒ", test_performance_comparison()))
    test_results.append(("ç³»çµ±æ•´åˆ", test_integration_with_system()))
    
    # è¼¸å‡ºæ¸¬è©¦çµæœ
    logger.info("=== æ¸¬è©¦çµæœæ‘˜è¦ ===")
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        logger.info("%s: %s", test_name, status)
        if result:
            passed += 1
    
    logger.info("ç¸½è¨ˆ: %d/%d æ¸¬è©¦é€šé", passed, total)
    
    if passed >= total * 0.8:  # 80% é€šéç‡è¦–ç‚ºæˆåŠŸ
        logger.info("ğŸ‰ çµ±ä¸€ä¸‹è¼‰å™¨æ“´å±•åŠŸèƒ½æ¸¬è©¦åŸºæœ¬æˆåŠŸï¼")
        return 0
    else:
        logger.error("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ“´å±•åŠŸèƒ½å¯¦ç¾")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
