# å‚™ä»½å’Œæ¢å¾©ç¨‹åº

## æ¦‚è¿°

æœ¬æ–‡æª”æä¾› AI è‚¡ç¥¨è‡ªå‹•äº¤æ˜“ç³»çµ±çš„å®Œæ•´å‚™ä»½å’Œæ¢å¾©ç­–ç•¥ï¼ŒåŒ…æ‹¬è³‡æ–™åº«å‚™ä»½ã€è¨­å®šæª”å‚™ä»½ã€ç³»çµ±ç‹€æ…‹å¿«ç…§åŠæ¢å¾©æµç¨‹çš„è©³ç´°æ“ä½œæŒ‡å—ã€‚

## å‚™ä»½ç­–ç•¥

### å‚™ä»½æ¶æ§‹
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ‡‰ç”¨ç¨‹å¼      â”‚â”€â”€â”€â–¶â”‚   æœ¬åœ°å‚™ä»½      â”‚â”€â”€â”€â–¶â”‚   é ç«¯å‚™ä»½      â”‚
â”‚   (Live Data)   â”‚    â”‚  (Local Store)  â”‚    â”‚ (Cloud Storage) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è³‡æ–™åº«        â”‚    â”‚   è¨­å®šæª”        â”‚    â”‚   ç³»çµ±å¿«ç…§      â”‚
â”‚  (Database)     â”‚    â”‚  (Config Files) â”‚    â”‚ (System State)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å‚™ä»½é¡å‹å’Œé »ç‡

| å‚™ä»½é¡å‹ | é »ç‡ | ä¿ç•™æœŸé™ | å„²å­˜ä½ç½® |
|---------|------|----------|----------|
| å®Œæ•´å‚™ä»½ | æ¯æ—¥ | 30å¤© | æœ¬åœ° + é›²ç«¯ |
| å¢é‡å‚™ä»½ | æ¯å°æ™‚ | 7å¤© | æœ¬åœ° |
| è¨­å®šæª”å‚™ä»½ | è®Šæ›´æ™‚ | æ°¸ä¹… | æœ¬åœ° + é›²ç«¯ |
| ç³»çµ±å¿«ç…§ | éƒ¨ç½²å‰ | 90å¤© | æœ¬åœ° + é›²ç«¯ |

## è³‡æ–™åº«å‚™ä»½ç­–ç•¥

### 1. è‡ªå‹•åŒ–è³‡æ–™åº«å‚™ä»½

#### å•Ÿå‹•è³‡æ–™åº«å‚™ä»½æœå‹™
```bash
# åŸ·è¡Œå®Œæ•´è³‡æ–™åº«å‚™ä»½
python -c "
from src.database.data_backup import DataBackupManager
backup_manager = DataBackupManager()
backup_path = backup_manager.create_full_backup()
print(f'å®Œæ•´å‚™ä»½å·²å»ºç«‹: {backup_path}')
"
```

#### è³‡æ–™åº«å‚™ä»½é…ç½®
**æª”æ¡ˆè·¯å¾‘**: `src/database/data_backup.py`
```python
BACKUP_CONFIG = {
    "backup_directory": "backups/database",
    "compression": True,
    "encryption": True,
    "retention_days": 30,
    "backup_types": {
        "full": {
            "schedule": "0 2 * * *",  # æ¯æ—¥å‡Œæ™¨2é»
            "compression_level": 9
        },
        "incremental": {
            "schedule": "0 * * * *",  # æ¯å°æ™‚
            "compression_level": 6
        }
    }
}
```

### 2. è³‡æ–™åº«å‚™ä»½è…³æœ¬

#### å®Œæ•´å‚™ä»½è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/backup_database_full.sh

set -e

BACKUP_DIR="/opt/trading_system/backups/database"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="full_backup_${TIMESTAMP}.sql.gz"

echo "é–‹å§‹å®Œæ•´è³‡æ–™åº«å‚™ä»½..."

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p ${BACKUP_DIR}

# åŸ·è¡Œè³‡æ–™åº«å‚™ä»½
python -c "
from src.database.data_backup import DataBackupManager
backup_manager = DataBackupManager()
backup_path = backup_manager.create_full_backup('${BACKUP_DIR}/${BACKUP_FILE}')
print(f'å‚™ä»½å®Œæˆ: {backup_path}')
"

# é©—è­‰å‚™ä»½æª”æ¡ˆ
if [ -f "${BACKUP_DIR}/${BACKUP_FILE}" ]; then
    echo "å‚™ä»½æª”æ¡ˆé©—è­‰æˆåŠŸ: ${BACKUP_FILE}"
    
    # ä¸Šå‚³åˆ°é›²ç«¯å„²å­˜
    python -c "
    from src.database.data_backup import CloudBackupManager
    cloud_backup = CloudBackupManager()
    cloud_backup.upload_backup('${BACKUP_DIR}/${BACKUP_FILE}')
    print('å‚™ä»½å·²ä¸Šå‚³åˆ°é›²ç«¯')
    "
else
    echo "éŒ¯èª¤: å‚™ä»½æª”æ¡ˆå»ºç«‹å¤±æ•—"
    exit 1
fi

echo "å®Œæ•´è³‡æ–™åº«å‚™ä»½å®Œæˆ"
```

#### å¢é‡å‚™ä»½è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/backup_database_incremental.sh

set -e

BACKUP_DIR="/opt/trading_system/backups/database/incremental"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="incremental_backup_${TIMESTAMP}.sql.gz"

echo "é–‹å§‹å¢é‡è³‡æ–™åº«å‚™ä»½..."

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p ${BACKUP_DIR}

# åŸ·è¡Œå¢é‡å‚™ä»½
python -c "
from src.database.data_backup import DataBackupManager
backup_manager = DataBackupManager()
backup_path = backup_manager.create_incremental_backup('${BACKUP_DIR}/${BACKUP_FILE}')
print(f'å¢é‡å‚™ä»½å®Œæˆ: {backup_path}')
"

echo "å¢é‡è³‡æ–™åº«å‚™ä»½å®Œæˆ"
```

### 3. è³‡æ–™å®Œæ•´æ€§é©—è­‰

#### å‚™ä»½é©—è­‰è…³æœ¬
```bash
# é©—è­‰å‚™ä»½æª”æ¡ˆå®Œæ•´æ€§
python -c "
from src.database.checksum_manager import ChecksumManager
checksum_manager = ChecksumManager()

# é©—è­‰å‚™ä»½æª”æ¡ˆ
backup_file = 'backups/database/full_backup_20241225_020000.sql.gz'
is_valid = checksum_manager.verify_backup(backup_file)
print(f'å‚™ä»½æª”æ¡ˆé©—è­‰çµæœ: {\"é€šé\" if is_valid else \"å¤±æ•—\"}')
"
```

## è¨­å®šæª”å‚™ä»½

### 1. è¨­å®šæª”å‚™ä»½ç¯„åœ

#### éœ€è¦å‚™ä»½çš„è¨­å®šæª”
```bash
# æ ¸å¿ƒè¨­å®šæª”åˆ—è¡¨
CONFIG_FILES=(
    "src/config.py"
    "config/environment_config.py"
    "config/deployment_production.json"
    "config/monitoring_production.json"
    ".env.prod"
    "docker-compose.prod.yml"
    "k8s/"
    "src/monitoring/prometheus/prometheus.yml"
    "src/monitoring/prometheus/alertmanager.yml"
    "src/monitoring/grafana/provisioning/"
)
```

#### è¨­å®šæª”å‚™ä»½è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/backup_config_files.sh

set -e

BACKUP_DIR="/opt/trading_system/backups/config"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_ARCHIVE="config_backup_${TIMESTAMP}.tar.gz"

echo "é–‹å§‹è¨­å®šæª”å‚™ä»½..."

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p ${BACKUP_DIR}

# å»ºç«‹è¨­å®šæª”æ¸…å–®
cat > /tmp/config_files.txt << EOF
src/config.py
config/environment_config.py
config/deployment_production.json
config/monitoring_production.json
.env.prod
docker-compose.prod.yml
k8s/
src/monitoring/prometheus/prometheus.yml
src/monitoring/prometheus/alertmanager.yml
src/monitoring/grafana/provisioning/
EOF

# å»ºç«‹å£“ç¸®å‚™ä»½
tar -czf "${BACKUP_DIR}/${BACKUP_ARCHIVE}" -T /tmp/config_files.txt

# é©—è­‰å‚™ä»½
if [ -f "${BACKUP_DIR}/${BACKUP_ARCHIVE}" ]; then
    echo "è¨­å®šæª”å‚™ä»½å®Œæˆ: ${BACKUP_ARCHIVE}"
    
    # è¨ˆç®—æ ¡é©—å’Œ
    sha256sum "${BACKUP_DIR}/${BACKUP_ARCHIVE}" > "${BACKUP_DIR}/${BACKUP_ARCHIVE}.sha256"
    echo "æ ¡é©—å’Œæª”æ¡ˆå·²å»ºç«‹"
else
    echo "éŒ¯èª¤: è¨­å®šæª”å‚™ä»½å¤±æ•—"
    exit 1
fi

# æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
rm -f /tmp/config_files.txt

echo "è¨­å®šæª”å‚™ä»½å®Œæˆ"
```

### 2. ç‰ˆæœ¬æ§åˆ¶æ•´åˆ

#### Git å‚™ä»½è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/backup_git_repository.sh

set -e

BACKUP_DIR="/opt/trading_system/backups/git"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
REPO_BACKUP="repository_backup_${TIMESTAMP}.tar.gz"

echo "é–‹å§‹ Git å€‰åº«å‚™ä»½..."

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p ${BACKUP_DIR}

# å»ºç«‹ Git å€‰åº«å‚™ä»½
git bundle create "${BACKUP_DIR}/repository_${TIMESTAMP}.bundle" --all

# å‚™ä»½å·¥ä½œç›®éŒ„ï¼ˆæ’é™¤ .gitï¼‰
tar --exclude='.git' --exclude='node_modules' --exclude='__pycache__' \
    -czf "${BACKUP_DIR}/${REPO_BACKUP}" .

echo "Git å€‰åº«å‚™ä»½å®Œæˆ: ${REPO_BACKUP}"
```

## ç³»çµ±ç‹€æ…‹å¿«ç…§

### 1. ç³»çµ±å¿«ç…§å»ºç«‹

#### ç³»çµ±ç‹€æ…‹å¿«ç…§è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/create_system_snapshot.sh

set -e

SNAPSHOT_DIR="/opt/trading_system/backups/snapshots"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
SNAPSHOT_NAME="system_snapshot_${TIMESTAMP}"

echo "é–‹å§‹å»ºç«‹ç³»çµ±ç‹€æ…‹å¿«ç…§..."

# å»ºç«‹å¿«ç…§ç›®éŒ„
mkdir -p "${SNAPSHOT_DIR}/${SNAPSHOT_NAME}"

# æ”¶é›†ç³»çµ±è³‡è¨Š
echo "æ”¶é›†ç³»çµ±è³‡è¨Š..."
{
    echo "=== ç³»çµ±è³‡è¨Š ==="
    uname -a
    echo ""
    
    echo "=== ç£ç¢Ÿä½¿ç”¨æƒ…æ³ ==="
    df -h
    echo ""
    
    echo "=== è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³ ==="
    free -h
    echo ""
    
    echo "=== åŸ·è¡Œä¸­çš„ç¨‹åº ==="
    ps aux | grep -E "(python|trading|api)"
    echo ""
    
    echo "=== ç¶²è·¯é€£ç·š ==="
    netstat -tlnp | grep -E "(8000|8501|3000)"
    echo ""
    
    echo "=== Docker å®¹å™¨ç‹€æ…‹ ==="
    docker ps -a 2>/dev/null || echo "Docker æœªå®‰è£æˆ–æœªåŸ·è¡Œ"
    echo ""
    
} > "${SNAPSHOT_DIR}/${SNAPSHOT_NAME}/system_info.txt"

# æ”¶é›†æ‡‰ç”¨ç¨‹å¼ç‹€æ…‹
echo "æ”¶é›†æ‡‰ç”¨ç¨‹å¼ç‹€æ…‹..."
python -c "
import json
from datetime import datetime
from src.monitoring.health_checker import HealthChecker
from src.monitoring.system_resource_checker import SystemResourceChecker

# å¥åº·æª¢æŸ¥
health_checker = HealthChecker()
health_status = health_checker.check_all_services()

# ç³»çµ±è³‡æº
resource_checker = SystemResourceChecker()
system_metrics = resource_checker.get_system_metrics()

# å»ºç«‹ç‹€æ…‹å ±å‘Š
status_report = {
    'timestamp': datetime.now().isoformat(),
    'health_status': health_status,
    'system_metrics': system_metrics
}

# å„²å­˜ç‹€æ…‹å ±å‘Š
with open('${SNAPSHOT_DIR}/${SNAPSHOT_NAME}/app_status.json', 'w', encoding='utf-8') as f:
    json.dump(status_report, f, indent=2, ensure_ascii=False)

print('æ‡‰ç”¨ç¨‹å¼ç‹€æ…‹å·²æ”¶é›†')
"

# å‚™ä»½ç•¶å‰è¨­å®š
echo "å‚™ä»½ç•¶å‰è¨­å®š..."
cp -r config/ "${SNAPSHOT_DIR}/${SNAPSHOT_NAME}/config_backup/"

# å»ºç«‹å¿«ç…§å£“ç¸®æª”
echo "å»ºç«‹å¿«ç…§å£“ç¸®æª”..."
cd ${SNAPSHOT_DIR}
tar -czf "${SNAPSHOT_NAME}.tar.gz" "${SNAPSHOT_NAME}/"
rm -rf "${SNAPSHOT_NAME}/"

echo "ç³»çµ±ç‹€æ…‹å¿«ç…§å»ºç«‹å®Œæˆ: ${SNAPSHOT_NAME}.tar.gz"
```

### 2. éƒ¨ç½²å‰å¿«ç…§

#### éƒ¨ç½²å‰è‡ªå‹•å¿«ç…§
```python
# æª”æ¡ˆè·¯å¾‘: scripts/deploy_production.py (å·²å­˜åœ¨ï¼Œæ–°å¢å¿«ç…§åŠŸèƒ½)

def create_pre_deployment_snapshot(self) -> Optional[str]:
    """å»ºç«‹éƒ¨ç½²å‰å¿«ç…§"""
    logger.info("ğŸ”„ å»ºç«‹éƒ¨ç½²å‰å¿«ç…§...")
    
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        snapshot_dir = PROJECT_ROOT / f"backups/pre_deployment_{timestamp}"
        snapshot_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. è³‡æ–™åº«å¿«ç…§
        from src.database.data_backup import DataBackupManager
        backup_manager = DataBackupManager()
        db_backup = backup_manager.create_full_backup(
            str(snapshot_dir / "database_snapshot.sql.gz")
        )
        
        # 2. è¨­å®šæª”å¿«ç…§
        import shutil
        config_backup_dir = snapshot_dir / "config"
        config_backup_dir.mkdir(exist_ok=True)
        
        config_files = [
            "src/config.py",
            "config/",
            ".env.prod",
            "docker-compose.prod.yml"
        ]
        
        for config_file in config_files:
            config_path = PROJECT_ROOT / config_file
            if config_path.exists():
                if config_path.is_dir():
                    shutil.copytree(config_path, config_backup_dir / config_file)
                else:
                    shutil.copy2(config_path, config_backup_dir)
        
        # 3. ç³»çµ±ç‹€æ…‹å¿«ç…§
        from src.monitoring.health_checker import HealthChecker
        health_checker = HealthChecker()
        health_status = health_checker.check_all_services()
        
        status_file = snapshot_dir / "system_status.json"
        with open(status_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'health_status': health_status,
                'deployment_config': self.deployment_config
            }, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… éƒ¨ç½²å‰å¿«ç…§å·²å»ºç«‹: {snapshot_dir}")
        return str(snapshot_dir)
        
    except Exception as e:
        logger.error(f"å»ºç«‹éƒ¨ç½²å‰å¿«ç…§å¤±æ•—: {e}")
        return None
```

## æ¢å¾©ç¨‹åº

### 1. è³‡æ–™åº«æ¢å¾©

#### å®Œæ•´è³‡æ–™åº«æ¢å¾©
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/restore_database_full.sh

set -e

if [ $# -ne 1 ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <backup_file>"
    echo "ç¯„ä¾‹: $0 backups/database/full_backup_20241225_020000.sql.gz"
    exit 1
fi

BACKUP_FILE=$1

echo "é–‹å§‹å®Œæ•´è³‡æ–™åº«æ¢å¾©..."
echo "å‚™ä»½æª”æ¡ˆ: ${BACKUP_FILE}"

# é©—è­‰å‚™ä»½æª”æ¡ˆå­˜åœ¨
if [ ! -f "${BACKUP_FILE}" ]; then
    echo "éŒ¯èª¤: å‚™ä»½æª”æ¡ˆä¸å­˜åœ¨: ${BACKUP_FILE}"
    exit 1
fi

# é©—è­‰å‚™ä»½æª”æ¡ˆå®Œæ•´æ€§
echo "é©—è­‰å‚™ä»½æª”æ¡ˆå®Œæ•´æ€§..."
python -c "
from src.database.checksum_manager import ChecksumManager
checksum_manager = ChecksumManager()
is_valid = checksum_manager.verify_backup('${BACKUP_FILE}')
if not is_valid:
    print('éŒ¯èª¤: å‚™ä»½æª”æ¡ˆæ ¡é©—å¤±æ•—')
    exit(1)
print('å‚™ä»½æª”æ¡ˆæ ¡é©—é€šé')
"

# åœæ­¢ç›¸é—œæœå‹™
echo "åœæ­¢ç›¸é—œæœå‹™..."
python -c "
from src.monitoring.service_checker import ServiceChecker
service_checker = ServiceChecker()
service_checker.stop_service('trading_engine')
service_checker.stop_service('api_server')
print('æœå‹™å·²åœæ­¢')
"

# åŸ·è¡Œè³‡æ–™åº«æ¢å¾©
echo "åŸ·è¡Œè³‡æ–™åº«æ¢å¾©..."
python -c "
from src.database.data_backup import DataBackupManager
backup_manager = DataBackupManager()
success = backup_manager.restore_full_backup('${BACKUP_FILE}')
if success:
    print('è³‡æ–™åº«æ¢å¾©æˆåŠŸ')
else:
    print('éŒ¯èª¤: è³‡æ–™åº«æ¢å¾©å¤±æ•—')
    exit(1)
"

# é‡å•Ÿæœå‹™
echo "é‡å•Ÿæœå‹™..."
python -c "
from src.monitoring.service_checker import ServiceChecker
service_checker = ServiceChecker()
service_checker.start_service('api_server')
service_checker.start_service('trading_engine')
print('æœå‹™å·²é‡å•Ÿ')
"

# é©—è­‰æ¢å¾©çµæœ
echo "é©—è­‰æ¢å¾©çµæœ..."
python -c "
from src.monitoring.health_checker import HealthChecker
health_checker = HealthChecker()
health_status = health_checker.check_all_services()
if health_status.get('overall_status') == 'healthy':
    print('âœ… è³‡æ–™åº«æ¢å¾©å®Œæˆï¼Œç³»çµ±å¥åº·')
else:
    print('âš ï¸ è³‡æ–™åº«æ¢å¾©å®Œæˆï¼Œä½†ç³»çµ±ç‹€æ…‹ç•°å¸¸')
    print(f'å¥åº·ç‹€æ…‹: {health_status}')
"

echo "å®Œæ•´è³‡æ–™åº«æ¢å¾©å®Œæˆ"
```

### 2. è¨­å®šæª”æ¢å¾©

#### è¨­å®šæª”æ¢å¾©è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/restore_config_files.sh

set -e

if [ $# -ne 1 ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <config_backup_archive>"
    echo "ç¯„ä¾‹: $0 backups/config/config_backup_20241225_120000.tar.gz"
    exit 1
fi

BACKUP_ARCHIVE=$1

echo "é–‹å§‹è¨­å®šæª”æ¢å¾©..."
echo "å‚™ä»½æª”æ¡ˆ: ${BACKUP_ARCHIVE}"

# é©—è­‰å‚™ä»½æª”æ¡ˆå­˜åœ¨
if [ ! -f "${BACKUP_ARCHIVE}" ]; then
    echo "éŒ¯èª¤: å‚™ä»½æª”æ¡ˆä¸å­˜åœ¨: ${BACKUP_ARCHIVE}"
    exit 1
fi

# é©—è­‰æ ¡é©—å’Œ
if [ -f "${BACKUP_ARCHIVE}.sha256" ]; then
    echo "é©—è­‰å‚™ä»½æª”æ¡ˆæ ¡é©—å’Œ..."
    sha256sum -c "${BACKUP_ARCHIVE}.sha256"
    if [ $? -ne 0 ]; then
        echo "éŒ¯èª¤: å‚™ä»½æª”æ¡ˆæ ¡é©—å’Œé©—è­‰å¤±æ•—"
        exit 1
    fi
    echo "æ ¡é©—å’Œé©—è­‰é€šé"
fi

# å»ºç«‹ç•¶å‰è¨­å®šæª”å‚™ä»½
echo "å»ºç«‹ç•¶å‰è¨­å®šæª”å‚™ä»½..."
CURRENT_BACKUP="backups/config/current_config_$(date +%Y%m%d_%H%M%S).tar.gz"
mkdir -p backups/config
tar -czf "${CURRENT_BACKUP}" src/config.py config/ .env.prod docker-compose.prod.yml k8s/ 2>/dev/null || true
echo "ç•¶å‰è¨­å®šæª”å·²å‚™ä»½è‡³: ${CURRENT_BACKUP}"

# è§£å£“ç¸®ä¸¦æ¢å¾©è¨­å®šæª”
echo "æ¢å¾©è¨­å®šæª”..."
tar -xzf "${BACKUP_ARCHIVE}" -C /

# é©—è­‰é—œéµè¨­å®šæª”
echo "é©—è­‰é—œéµè¨­å®šæª”..."
CRITICAL_FILES=(
    "src/config.py"
    "config/environment_config.py"
    ".env.prod"
)

for file in "${CRITICAL_FILES[@]}"; do
    if [ -f "${file}" ]; then
        echo "âœ… ${file} æ¢å¾©æˆåŠŸ"
    else
        echo "âŒ ${file} æ¢å¾©å¤±æ•—"
    fi
done

echo "è¨­å®šæª”æ¢å¾©å®Œæˆ"
```

### 3. ç³»çµ±ç‹€æ…‹æ¢å¾©

#### ç³»çµ±ç‹€æ…‹æ¢å¾©è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/restore_system_snapshot.sh

set -e

if [ $# -ne 1 ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <snapshot_archive>"
    echo "ç¯„ä¾‹: $0 backups/snapshots/system_snapshot_20241225_120000.tar.gz"
    exit 1
fi

SNAPSHOT_ARCHIVE=$1

echo "é–‹å§‹ç³»çµ±ç‹€æ…‹æ¢å¾©..."
echo "å¿«ç…§æª”æ¡ˆ: ${SNAPSHOT_ARCHIVE}"

# é©—è­‰å¿«ç…§æª”æ¡ˆå­˜åœ¨
if [ ! -f "${SNAPSHOT_ARCHIVE}" ]; then
    echo "éŒ¯èª¤: å¿«ç…§æª”æ¡ˆä¸å­˜åœ¨: ${SNAPSHOT_ARCHIVE}"
    exit 1
fi

# è§£å£“ç¸®å¿«ç…§
TEMP_DIR="/tmp/system_restore_$(date +%s)"
mkdir -p "${TEMP_DIR}"
tar -xzf "${SNAPSHOT_ARCHIVE}" -C "${TEMP_DIR}"

SNAPSHOT_DIR=$(find "${TEMP_DIR}" -name "system_snapshot_*" -type d | head -1)

if [ -z "${SNAPSHOT_DIR}" ]; then
    echo "éŒ¯èª¤: ç„¡æ³•æ‰¾åˆ°å¿«ç…§ç›®éŒ„"
    exit 1
fi

echo "å¿«ç…§ç›®éŒ„: ${SNAPSHOT_DIR}"

# æ¢å¾©è¨­å®šæª”
if [ -d "${SNAPSHOT_DIR}/config_backup" ]; then
    echo "æ¢å¾©è¨­å®šæª”..."
    cp -r "${SNAPSHOT_DIR}/config_backup/"* ./
    echo "è¨­å®šæª”æ¢å¾©å®Œæˆ"
fi

# é¡¯ç¤ºå¿«ç…§è³‡è¨Š
if [ -f "${SNAPSHOT_DIR}/system_info.txt" ]; then
    echo "å¿«ç…§ç³»çµ±è³‡è¨Š:"
    cat "${SNAPSHOT_DIR}/system_info.txt"
fi

if [ -f "${SNAPSHOT_DIR}/app_status.json" ]; then
    echo "å¿«ç…§æ‡‰ç”¨ç¨‹å¼ç‹€æ…‹:"
    python -c "
import json
with open('${SNAPSHOT_DIR}/app_status.json', 'r', encoding='utf-8') as f:
    status = json.load(f)
    print(f'å¿«ç…§æ™‚é–“: {status[\"timestamp\"]}')
    print(f'å¥åº·ç‹€æ…‹: {status[\"health_status\"]}')
"
fi

# æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
rm -rf "${TEMP_DIR}"

echo "ç³»çµ±ç‹€æ…‹æ¢å¾©å®Œæˆ"
```

## è‡ªå‹•åŒ–å‚™ä»½æ’ç¨‹

### 1. Cron æ’ç¨‹è¨­å®š

#### å‚™ä»½æ’ç¨‹é…ç½®
```bash
# ç·¨è¼¯ crontab
crontab -e

# æ–°å¢ä»¥ä¸‹æ’ç¨‹
# æ¯æ—¥å‡Œæ™¨2é»åŸ·è¡Œå®Œæ•´è³‡æ–™åº«å‚™ä»½
0 2 * * * /opt/trading_system/scripts/backup_database_full.sh >> /var/log/backup.log 2>&1

# æ¯å°æ™‚åŸ·è¡Œå¢é‡è³‡æ–™åº«å‚™ä»½
0 * * * * /opt/trading_system/scripts/backup_database_incremental.sh >> /var/log/backup.log 2>&1

# æ¯é€±æ—¥å‡Œæ™¨3é»åŸ·è¡Œè¨­å®šæª”å‚™ä»½
0 3 * * 0 /opt/trading_system/scripts/backup_config_files.sh >> /var/log/backup.log 2>&1

# æ¯æœˆ1è™Ÿå‡Œæ™¨4é»åŸ·è¡Œ Git å€‰åº«å‚™ä»½
0 4 1 * * /opt/trading_system/scripts/backup_git_repository.sh >> /var/log/backup.log 2>&1
```

### 2. å‚™ä»½ç›£æ§å’Œé€šçŸ¥

#### å‚™ä»½ç‹€æ…‹ç›£æ§è…³æœ¬
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/monitor_backup_status.sh

set -e

BACKUP_LOG="/var/log/backup.log"
ALERT_EMAIL="admin@company.com"

echo "æª¢æŸ¥å‚™ä»½ç‹€æ…‹..."

# æª¢æŸ¥æœ€è¿‘24å°æ™‚çš„å‚™ä»½æ—¥èªŒ
RECENT_BACKUPS=$(grep -c "å‚™ä»½å®Œæˆ" "${BACKUP_LOG}" | tail -24)

if [ "${RECENT_BACKUPS}" -lt 1 ]; then
    echo "è­¦å‘Š: æœ€è¿‘24å°æ™‚å…§æ²’æœ‰æˆåŠŸçš„å‚™ä»½"
    
    # ç™¼é€å‘Šè­¦é€šçŸ¥
    python -c "
from src.monitoring.notification_manager import NotificationManager
notifier = NotificationManager()
notifier.send_alert(
    title='å‚™ä»½å¤±æ•—å‘Šè­¦',
    message='æœ€è¿‘24å°æ™‚å…§æ²’æœ‰æˆåŠŸçš„å‚™ä»½ï¼Œè«‹æª¢æŸ¥å‚™ä»½ç³»çµ±',
    severity='critical'
)
print('å‘Šè­¦é€šçŸ¥å·²ç™¼é€')
"
else
    echo "å‚™ä»½ç‹€æ…‹æ­£å¸¸"
fi
```

## ç½é›£æ¢å¾©æ¸¬è©¦

### 1. æ¢å¾©æ¸¬è©¦è¨ˆåŠƒ

#### æœˆåº¦æ¢å¾©æ¸¬è©¦
```bash
#!/bin/bash
# æª”æ¡ˆè·¯å¾‘: scripts/disaster_recovery_test.sh

set -e

echo "é–‹å§‹ç½é›£æ¢å¾©æ¸¬è©¦..."

# 1. å»ºç«‹æ¸¬è©¦ç’°å¢ƒ
echo "å»ºç«‹æ¸¬è©¦ç’°å¢ƒ..."
docker-compose -f docker-compose.test.yml up -d

# 2. åŸ·è¡Œè³‡æ–™åº«æ¢å¾©æ¸¬è©¦
echo "æ¸¬è©¦è³‡æ–™åº«æ¢å¾©..."
LATEST_BACKUP=$(ls -t backups/database/full_backup_*.sql.gz | head -1)
./scripts/restore_database_full.sh "${LATEST_BACKUP}"

# 3. é©—è­‰æ¢å¾©çµæœ
echo "é©—è­‰æ¢å¾©çµæœ..."
python -c "
from src.monitoring.health_checker import HealthChecker
health_checker = HealthChecker()
health_status = health_checker.check_all_services()
print(f'æ¢å¾©æ¸¬è©¦çµæœ: {health_status}')
"

# 4. æ¸…ç†æ¸¬è©¦ç’°å¢ƒ
echo "æ¸…ç†æ¸¬è©¦ç’°å¢ƒ..."
docker-compose -f docker-compose.test.yml down

echo "ç½é›£æ¢å¾©æ¸¬è©¦å®Œæˆ"
```

## æ•…éšœæ’é™¤

### å¸¸è¦‹å‚™ä»½å•é¡Œ

#### 1. å‚™ä»½ç©ºé–“ä¸è¶³
**ç—‡ç‹€**: å‚™ä»½å¤±æ•—ï¼ŒéŒ¯èª¤è¨Šæ¯é¡¯ç¤ºç£ç¢Ÿç©ºé–“ä¸è¶³
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥ç£ç¢Ÿä½¿ç”¨æƒ…æ³
df -h

# æ¸…ç†èˆŠå‚™ä»½æª”æ¡ˆ
find backups/ -name "*.gz" -mtime +30 -delete

# æª¢æŸ¥å‚™ä»½ç›®éŒ„å¤§å°
du -sh backups/
```

#### 2. å‚™ä»½æª”æ¡ˆæå£
**ç—‡ç‹€**: æ¢å¾©æ™‚æ ¡é©—å’Œé©—è­‰å¤±æ•—
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# é‡æ–°å»ºç«‹å‚™ä»½
./scripts/backup_database_full.sh

# å¾é›²ç«¯ä¸‹è¼‰å‚™ä»½
python -c "
from src.database.data_backup import CloudBackupManager
cloud_backup = CloudBackupManager()
cloud_backup.download_latest_backup()
"
```

#### 3. æ¢å¾©éç¨‹ä¸­æ–·
**ç—‡ç‹€**: æ¢å¾©ç¨‹åºåŸ·è¡Œä¸­æ–·ï¼Œç³»çµ±ç‹€æ…‹ä¸ä¸€è‡´
**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥ç³»çµ±ç‹€æ…‹
python -c "
from src.monitoring.health_checker import HealthChecker
health_checker = HealthChecker()
status = health_checker.check_all_services()
print(f'ç³»çµ±ç‹€æ…‹: {status}')
"

# é‡æ–°åŸ·è¡Œæ¢å¾©ç¨‹åº
./scripts/restore_database_full.sh <backup_file>
```

## ç›¸é—œæ–‡ä»¶

- [ç³»çµ±ç›£æ§æŒ‡å—](./ç³»çµ±ç›£æ§æŒ‡å—.md)
- [ç½é›£æ¢å¾©è¨ˆåŠƒ](./ç½é›£æ¢å¾©è¨ˆåŠƒ.md)
- [æ•ˆèƒ½èª¿å„ªæŒ‡å—](./æ•ˆèƒ½èª¿å„ªæŒ‡å—.md)
- [ç³»çµ±éƒ¨ç½²æŒ‡å—](../ç³»çµ±éƒ¨ç½²æŒ‡å—.md)

---

**æœ€å¾Œæ›´æ–°**: 2024å¹´12æœˆ25æ—¥  
**æ–‡ä»¶ç‰ˆæœ¬**: v1.0  
**ç¶­è­·äººå“¡**: ç³»çµ±ç®¡ç†åœ˜éšŠ
