# 錯誤處理和故障排除文檔

## 概述

本文檔提供訊號產生器模組的錯誤處理機制說明和常見問題的故障排除指南。

## 錯誤處理機制

### 異常類型

訊號產生器模組定義了以下異常類型：

```python
class SignalGeneratorError(Exception):
    """訊號產生器基礎異常"""
    pass

class DataValidationError(SignalGeneratorError):
    """資料驗證錯誤"""
    pass

class ConfigurationError(SignalGeneratorError):
    """配置錯誤"""
    pass

class CalculationError(SignalGeneratorError):
    """計算錯誤"""
    pass
```

### 錯誤處理策略

#### 1. 優雅降級 (Graceful Degradation)

當某個策略失敗時，系統會繼續執行其他策略：

```python
def generate_all_signals(self, **kwargs):
    """生成所有類型的訊號，即使部分策略失敗也會繼續"""
    all_signals = {}
    
    # 生成基本面訊號
    try:
        fundamental_signals = self.fundamental_generator.generate_all_fundamental_signals(**kwargs)
        all_signals.update(fundamental_signals)
        logger.info("基本面訊號生成完成")
    except Exception as e:
        logger.warning("基本面訊號生成失敗: %s", e)
        # 繼續執行其他策略
    
    # 其他策略...
    return all_signals
```

#### 2. 資料驗證

在處理前驗證輸入資料：

```python
def validate_data(self, required_data: str) -> bool:
    """驗證所需資料是否可用"""
    data_map = {
        'price': self.price_data,
        'financial': self.financial_data,
        'news': self.news_data,
        'volume': self.volume_data,
    }
    
    data = data_map.get(required_data)
    if data is None:
        logger.warning("缺少 %s 資料", required_data)
        return False
    
    if data.empty:
        logger.warning("%s 資料為空", required_data)
        return False
    
    return True
```

#### 3. 安全的數值計算

處理 NaN 值和除零錯誤：

```python
def _calculate_rsi(self, price_series: pd.Series, period: int = 14) -> pd.Series:
    """安全計算 RSI，處理 NaN 和除零情況"""
    try:
        delta = price_series.diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = -delta.where(delta < 0, 0).rolling(window=period).mean()
        
        # 避免除零錯誤
        rs = gain / loss.replace(0, np.nan)
        rsi = 100 - (100 / (1 + rs))
        
        return rsi.fillna(50)  # 用中性值填充 NaN
    except Exception as e:
        logger.error("計算 RSI 時發生錯誤: %s", e)
        return pd.Series(50, index=price_series.index)  # 返回中性值
```

## 常見錯誤和解決方案

### 1. 資料格式錯誤

#### 錯誤訊息
```
KeyError: 'close'
IndexError: index out of bounds
```

#### 原因
- 價格資料缺少必要欄位
- 索引格式不正確

#### 解決方案
```python
# 檢查必要欄位
required_columns = ['open', 'high', 'low', 'close', 'volume']
missing_columns = [col for col in required_columns if col not in price_data.columns]
if missing_columns:
    raise DataValidationError(f"價格資料缺少欄位: {missing_columns}")

# 確保正確的多層索引格式
if not isinstance(price_data.index, pd.MultiIndex):
    raise DataValidationError("價格資料必須使用 MultiIndex (股票代號, 日期)")

# 檢查索引層級名稱
expected_names = ['symbol', 'date']
if price_data.index.names != expected_names:
    logger.warning("索引名稱不符合預期，嘗試重新命名")
    price_data.index.names = expected_names
```

### 2. 記憶體不足錯誤

#### 錯誤訊息
```
MemoryError: Unable to allocate array
```

#### 原因
- 資料量過大
- 重複計算導致記憶體累積

#### 解決方案
```python
def process_large_dataset(self, data, chunk_size=1000):
    """分批處理大型資料集"""
    results = []
    
    for i in range(0, len(data), chunk_size):
        chunk = data.iloc[i:i+chunk_size]
        try:
            chunk_result = self._process_chunk(chunk)
            results.append(chunk_result)
        except MemoryError:
            logger.warning("記憶體不足，減少批次大小")
            # 遞歸處理更小的批次
            smaller_results = self.process_large_dataset(chunk, chunk_size//2)
            results.extend(smaller_results)
        finally:
            # 清理記憶體
            del chunk
            gc.collect()
    
    return pd.concat(results, ignore_index=True)
```

### 3. 計算超時錯誤

#### 錯誤訊息
```
TimeoutError: Calculation timeout
```

#### 原因
- 複雜計算耗時過長
- 資料量超出預期

#### 解決方案
```python
import signal
from contextlib import contextmanager

@contextmanager
def timeout(duration):
    """設定計算超時"""
    def timeout_handler(signum, frame):
        raise TimeoutError("計算超時")
    
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(duration)
    try:
        yield
    finally:
        signal.alarm(0)

def safe_calculate_signals(self, **kwargs):
    """安全計算訊號，設定超時限制"""
    try:
        with timeout(300):  # 5分鐘超時
            return self.generate_signals(**kwargs)
    except TimeoutError:
        logger.error("訊號計算超時，返回空結果")
        return pd.DataFrame()
```

### 4. 索引不匹配錯誤

#### 錯誤訊息
```
ValueError: cannot reindex from a duplicate axis
KeyError: 'AAPL' not found in index
```

#### 原因
- 不同資料源的索引格式不一致
- 股票代號或日期不匹配

#### 解決方案
```python
def align_data_indices(self, *dataframes):
    """對齊多個 DataFrame 的索引"""
    if not dataframes:
        return []
    
    # 找到共同的索引
    common_index = dataframes[0].index
    for df in dataframes[1:]:
        common_index = common_index.intersection(df.index)
    
    if common_index.empty:
        logger.warning("沒有找到共同的索引")
        return [df.iloc[:0] for df in dataframes]  # 返回空 DataFrame
    
    # 重新索引所有 DataFrame
    aligned_dfs = []
    for df in dataframes:
        aligned_df = df.reindex(common_index)
        aligned_dfs.append(aligned_df)
    
    logger.info("成功對齊 %d 個 DataFrame，共同索引長度: %d", 
                len(dataframes), len(common_index))
    return aligned_dfs
```

### 5. 配置參數錯誤

#### 錯誤訊息
```
ValueError: Invalid parameter value
ConfigurationError: Strategy weights must sum to 1.0
```

#### 原因
- 參數值超出有效範圍
- 策略權重配置錯誤

#### 解決方案
```python
def validate_parameters(self, **kwargs):
    """驗證參數有效性"""
    validators = {
        'pe_threshold': lambda x: x > 0,
        'pb_threshold': lambda x: x > 0,
        'window': lambda x: isinstance(x, int) and x > 0,
        'std_dev': lambda x: x > 0,
        'sentiment_threshold': lambda x: -1 <= x <= 1,
    }
    
    for param, value in kwargs.items():
        if param in validators:
            if not validators[param](value):
                raise ConfigurationError(f"參數 {param} 的值 {value} 無效")
    
    # 驗證策略權重
    if 'strategy_weights' in kwargs:
        weights = kwargs['strategy_weights']
        if abs(sum(weights.values()) - 1.0) > 0.01:
            raise ConfigurationError("策略權重總和必須等於 1.0")
```

## 除錯工具

### 1. 日誌配置

```python
import logging

def setup_logging(level=logging.INFO):
    """設定詳細的日誌記錄"""
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('signal_generator.log'),
            logging.StreamHandler()
        ]
    )
    
    # 設定特定模組的日誌級別
    logging.getLogger('src.core.signal_generators').setLevel(logging.DEBUG)
```

### 2. 效能監控

```python
import time
import functools

def monitor_performance(func):
    """監控函數執行效能"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info("函數 %s 執行時間: %.2f 秒", func.__name__, execution_time)
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error("函數 %s 執行失敗 (%.2f 秒): %s", 
                        func.__name__, execution_time, e)
            raise
    return wrapper

# 使用範例
@monitor_performance
def generate_signals(self, **kwargs):
    # 原始函數邏輯
    pass
```

### 3. 資料品質檢查

```python
def check_data_quality(self, data, data_type):
    """檢查資料品質"""
    issues = []
    
    # 檢查缺失值
    missing_ratio = data.isnull().sum().sum() / (len(data) * len(data.columns))
    if missing_ratio > 0.1:
        issues.append(f"{data_type} 資料缺失值比例過高: {missing_ratio:.2%}")
    
    # 檢查重複值
    duplicate_ratio = data.duplicated().sum() / len(data)
    if duplicate_ratio > 0.05:
        issues.append(f"{data_type} 資料重複值比例過高: {duplicate_ratio:.2%}")
    
    # 檢查異常值
    if data_type == 'price':
        for col in ['open', 'high', 'low', 'close']:
            if col in data.columns:
                q99 = data[col].quantile(0.99)
                q01 = data[col].quantile(0.01)
                outliers = ((data[col] > q99 * 10) | (data[col] < q01 / 10)).sum()
                if outliers > 0:
                    issues.append(f"{col} 欄位有 {outliers} 個極端異常值")
    
    if issues:
        logger.warning("資料品質問題:\n" + "\n".join(issues))
    else:
        logger.info("%s 資料品質檢查通過", data_type)
    
    return issues
```

## 故障排除流程

### 1. 問題診斷步驟

```python
def diagnose_issue(self, error_message, **context):
    """診斷問題並提供解決建議"""
    
    diagnosis = {
        'error_type': type(error_message).__name__,
        'error_message': str(error_message),
        'context': context,
        'suggestions': []
    }
    
    # 根據錯誤類型提供建議
    if 'KeyError' in diagnosis['error_type']:
        diagnosis['suggestions'].extend([
            "檢查資料欄位名稱是否正確",
            "確認索引格式是否為 MultiIndex",
            "驗證股票代號是否存在於資料中"
        ])
    
    elif 'MemoryError' in diagnosis['error_type']:
        diagnosis['suggestions'].extend([
            "減少資料量或使用分批處理",
            "檢查是否有記憶體洩漏",
            "考慮使用更高效的資料結構"
        ])
    
    elif 'ValueError' in diagnosis['error_type']:
        diagnosis['suggestions'].extend([
            "檢查參數值是否在有效範圍內",
            "確認資料類型是否正確",
            "驗證計算邏輯是否合理"
        ])
    
    return diagnosis
```

### 2. 自動修復機制

```python
def auto_fix_common_issues(self, data):
    """自動修復常見的資料問題"""
    fixed_data = data.copy()
    fixes_applied = []
    
    # 修復缺失值
    if fixed_data.isnull().any().any():
        # 對數值欄位使用前向填充
        numeric_cols = fixed_data.select_dtypes(include=[np.number]).columns
        fixed_data[numeric_cols] = fixed_data[numeric_cols].fillna(method='ffill')
        fixes_applied.append("使用前向填充處理數值欄位的缺失值")
    
    # 修復重複索引
    if fixed_data.index.duplicated().any():
        fixed_data = fixed_data[~fixed_data.index.duplicated(keep='last')]
        fixes_applied.append("移除重複的索引")
    
    # 修復異常值
    for col in fixed_data.select_dtypes(include=[np.number]).columns:
        q99 = fixed_data[col].quantile(0.99)
        q01 = fixed_data[col].quantile(0.01)
        
        # 限制極端值
        outlier_mask = (fixed_data[col] > q99 * 5) | (fixed_data[col] < q01 / 5)
        if outlier_mask.any():
            fixed_data.loc[outlier_mask, col] = np.nan
            fixed_data[col] = fixed_data[col].fillna(method='ffill')
            fixes_applied.append(f"修復 {col} 欄位的極端異常值")
    
    if fixes_applied:
        logger.info("自動修復完成:\n" + "\n".join(fixes_applied))
    
    return fixed_data, fixes_applied
```

## 測試和驗證

### 1. 單元測試範例

```python
import unittest

class TestSignalGenerator(unittest.TestCase):
    
    def setUp(self):
        """設定測試資料"""
        self.sample_data = self.create_sample_data()
        self.generator = SignalGenerator(price_data=self.sample_data)
    
    def test_data_validation(self):
        """測試資料驗證功能"""
        self.assertTrue(self.generator.validate_data('price'))
        self.assertFalse(self.generator.validate_data('financial'))
    
    def test_error_handling(self):
        """測試錯誤處理"""
        # 測試空資料
        empty_generator = SignalGenerator()
        signals = empty_generator.generate_signals()
        self.assertTrue(signals.empty)
        
        # 測試無效參數
        with self.assertRaises(ConfigurationError):
            self.generator.generate_signals(pe_threshold=-1)
```

### 2. 整合測試

```python
def integration_test():
    """整合測試，驗證整個流程"""
    try:
        # 準備測試資料
        test_data = prepare_test_data()
        
        # 初始化產生器
        generator = SignalGenerator(**test_data)
        
        # 生成訊號
        signals = generator.generate_all_signals()
        
        # 驗證結果
        assert not signals.empty, "訊號不應為空"
        assert all(col in signals for col in ['signal']), "缺少必要欄位"
        
        logger.info("整合測試通過")
        return True
        
    except Exception as e:
        logger.error("整合測試失敗: %s", e)
        return False
```

## 最佳實踐

1. **預防性檢查**: 在處理前驗證所有輸入
2. **優雅降級**: 部分失敗時繼續執行其他功能
3. **詳細日誌**: 記錄足夠的資訊用於問題診斷
4. **自動恢復**: 實現常見問題的自動修復機制
5. **測試覆蓋**: 確保錯誤處理邏輯得到充分測試

## 聯絡支援

如果遇到無法解決的問題，請提供以下資訊：

1. 完整的錯誤訊息和堆疊追蹤
2. 輸入資料的格式和範例
3. 使用的參數配置
4. 系統環境資訊（Python 版本、套件版本等）
5. 重現問題的最小範例代碼
