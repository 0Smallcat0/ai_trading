"""
AI æ¨¡å‹è¨“ç·´æ¨¡çµ„

æ­¤æ¨¡çµ„æä¾›æ¨¡å‹è¨“ç·´çš„å®Œæ•´åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- å¿«é€Ÿè¨“ç·´é…ç½®
- æ¨™æº–è¨“ç·´é…ç½®  
- æ·±åº¦è¨“ç·´é…ç½®
- è‡ªå‹•èª¿å„ªé…ç½®
- è¨“ç·´çµæœé¡¯ç¤º
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from typing import Dict, List, Optional, Any

from .base import get_ai_model_service, safe_strftime, create_info_card, validate_model_config


def show_model_training_enhanced():
    """é¡¯ç¤ºå¢å¼·ç‰ˆæ¨¡å‹è¨“ç·´é é¢
    
    æä¾›å®Œæ•´çš„æ¨¡å‹è¨“ç·´åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - è¨“ç·´æ¨¡å¼é¸æ“‡
    - é…ç½®åƒæ•¸è¨­å®š
    - è¨“ç·´é€²åº¦ç›£æ§
    - çµæœåˆ†æ
    """
    st.header("ğŸ¯ æ¨¡å‹è¨“ç·´")
    
    # è¨“ç·´æ¨¡å¼é¸æ“‡
    training_modes = {
        "å¿«é€Ÿè¨“ç·´": "quick",
        "æ¨™æº–è¨“ç·´": "standard", 
        "æ·±åº¦è¨“ç·´": "deep",
        "è‡ªå‹•èª¿å„ª": "auto_tuning"
    }
    
    selected_mode = st.selectbox(
        "é¸æ“‡è¨“ç·´æ¨¡å¼",
        options=list(training_modes.keys()),
        help="ä¸åŒæ¨¡å¼æä¾›ä¸åŒç¨‹åº¦çš„é…ç½®é¸é …å’Œè¨“ç·´æ·±åº¦"
    )
    
    mode_key = training_modes[selected_mode]
    
    # é¡¯ç¤ºæ¨¡å¼èªªæ˜
    _show_training_mode_info(mode_key)
    
    # æ ¹æ“šé¸æ“‡çš„æ¨¡å¼é¡¯ç¤ºå°æ‡‰çš„é…ç½®ä»‹é¢
    if mode_key == "quick":
        show_quick_training_config({}, False)
    elif mode_key == "standard":
        show_standard_training_config({}, False)
    elif mode_key == "deep":
        show_deep_training_config({}, False)
    elif mode_key == "auto_tuning":
        show_auto_tuning_config({}, False)


def show_quick_training_config(model_data: Dict, is_editing: bool):
    """é¡¯ç¤ºå¿«é€Ÿè¨“ç·´é…ç½®
    
    Args:
        model_data: æ¨¡å‹è³‡æ–™
        is_editing: æ˜¯å¦ç‚ºç·¨è¼¯æ¨¡å¼
    """
    st.subheader("âš¡ å¿«é€Ÿè¨“ç·´é…ç½®")
    
    create_info_card(
        "å¿«é€Ÿè¨“ç·´",
        "ä½¿ç”¨é è¨­åƒæ•¸å¿«é€Ÿè¨“ç·´æ¨¡å‹ï¼Œé©åˆåŸå‹é–‹ç™¼å’Œåˆæ­¥é©—è­‰ã€‚",
        "âš¡"
    )
    
    with st.form("quick_training_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            model_name = st.text_input(
                "æ¨¡å‹åç¨±*",
                value=model_data.get('name', ''),
                placeholder="è¼¸å…¥æ¨¡å‹åç¨±"
            )
            
            algorithm = st.selectbox(
                "æ¼”ç®—æ³•*",
                options=["RandomForest", "XGBoost", "LightGBM", "LogisticRegression"],
                index=0
            )
            
            target_column = st.text_input(
                "ç›®æ¨™æ¬„ä½*",
                value=model_data.get('target_column', ''),
                placeholder="ä¾‹å¦‚: price, return, signal"
            )
        
        with col2:
            data_source = st.selectbox(
                "è³‡æ–™ä¾†æº*",
                options=["æœ¬åœ°æª”æ¡ˆ", "è³‡æ–™åº«", "API"],
                index=0
            )
            
            train_size = st.slider(
                "è¨“ç·´é›†æ¯”ä¾‹",
                min_value=0.5,
                max_value=0.9,
                value=0.8,
                step=0.05
            )
            
            max_time = st.number_input(
                "æœ€å¤§è¨“ç·´æ™‚é–“ (åˆ†é˜)",
                min_value=1,
                max_value=60,
                value=10
            )
        
        # è³‡æ–™ä¸Šå‚³
        st.subheader("ğŸ“ è³‡æ–™ä¸Šå‚³")
        uploaded_file = st.file_uploader(
            "é¸æ“‡è¨“ç·´è³‡æ–™æª”æ¡ˆ",
            type=['csv', 'xlsx', 'parquet'],
            help="æ”¯æ´ CSVã€Excel å’Œ Parquet æ ¼å¼"
        )
        
        # æäº¤æŒ‰éˆ•
        submitted = st.form_submit_button("ğŸš€ é–‹å§‹å¿«é€Ÿè¨“ç·´", use_container_width=True)
        
        if submitted:
            _start_quick_training(model_name, algorithm, target_column, data_source, 
                                train_size, max_time, uploaded_file)


def show_standard_training_config(model_data: Dict, is_editing: bool):
    """é¡¯ç¤ºæ¨™æº–è¨“ç·´é…ç½®
    
    Args:
        model_data: æ¨¡å‹è³‡æ–™
        is_editing: æ˜¯å¦ç‚ºç·¨è¼¯æ¨¡å¼
    """
    st.subheader("ğŸ¯ æ¨™æº–è¨“ç·´é…ç½®")
    
    create_info_card(
        "æ¨™æº–è¨“ç·´",
        "æä¾›æ›´å¤šé…ç½®é¸é …ï¼ŒåŒ…æ‹¬ç‰¹å¾µå·¥ç¨‹ã€äº¤å‰é©—è­‰å’Œè¶…åƒæ•¸èª¿æ•´ã€‚",
        "ğŸ¯"
    )
    
    # åŸºæœ¬é…ç½®
    with st.expander("ğŸ“‹ åŸºæœ¬é…ç½®", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            model_name = st.text_input("æ¨¡å‹åç¨±*", value=model_data.get('name', ''))
            model_type = st.selectbox("æ¨¡å‹é¡å‹*", ["classification", "regression"])
            algorithm = st.selectbox(
                "æ¼”ç®—æ³•*",
                options=["RandomForest", "XGBoost", "LightGBM", "SVM", "Neural Network"]
            )
        
        with col2:
            target_column = st.text_input("ç›®æ¨™æ¬„ä½*", value=model_data.get('target_column', ''))
            validation_method = st.selectbox("é©—è­‰æ–¹æ³•", ["K-Fold", "Time Series Split", "Stratified"])
            cv_folds = st.number_input("äº¤å‰é©—è­‰æŠ˜æ•¸", min_value=3, max_value=10, value=5)
    
    # ç‰¹å¾µå·¥ç¨‹
    with st.expander("ğŸ”§ ç‰¹å¾µå·¥ç¨‹"):
        col1, col2 = st.columns(2)
        
        with col1:
            feature_selection = st.checkbox("å•Ÿç”¨ç‰¹å¾µé¸æ“‡", value=True)
            feature_scaling = st.selectbox("ç‰¹å¾µç¸®æ”¾", ["StandardScaler", "MinMaxScaler", "RobustScaler"])
            handle_missing = st.selectbox("ç¼ºå¤±å€¼è™•ç†", ["å¡«å……å‡å€¼", "å¡«å……ä¸­ä½æ•¸", "åˆªé™¤", "å‰å‘å¡«å……"])
        
        with col2:
            outlier_detection = st.checkbox("ç•°å¸¸å€¼æª¢æ¸¬", value=False)
            feature_engineering = st.multiselect(
                "ç‰¹å¾µå·¥ç¨‹",
                options=["å¤šé …å¼ç‰¹å¾µ", "äº¤äº’ç‰¹å¾µ", "æ™‚é–“ç‰¹å¾µ", "æŠ€è¡“æŒ‡æ¨™"],
                default=["æŠ€è¡“æŒ‡æ¨™"]
            )
    
    # è¶…åƒæ•¸é…ç½®
    with st.expander("âš™ï¸ è¶…åƒæ•¸é…ç½®"):
        if st.button("ğŸ² ä½¿ç”¨æ¨è–¦åƒæ•¸"):
            st.info("å·²è¼‰å…¥æ¨è–¦çš„è¶…åƒæ•¸é…ç½®")
        
        # æ ¹æ“šé¸æ“‡çš„æ¼”ç®—æ³•é¡¯ç¤ºå°æ‡‰çš„è¶…åƒæ•¸
        _show_hyperparameter_config(algorithm)
    
    # è¨“ç·´è¨­å®š
    with st.expander("ğŸƒ è¨“ç·´è¨­å®š"):
        col1, col2 = st.columns(2)
        
        with col1:
            max_time = st.number_input("æœ€å¤§è¨“ç·´æ™‚é–“ (å°æ™‚)", min_value=0.5, max_value=24.0, value=2.0)
            early_stopping = st.checkbox("æ—©åœæ©Ÿåˆ¶", value=True)
            save_checkpoints = st.checkbox("ä¿å­˜æª¢æŸ¥é»", value=True)
        
        with col2:
            gpu_enabled = st.checkbox("ä½¿ç”¨ GPU", value=False)
            parallel_jobs = st.number_input("ä¸¦è¡Œä»»å‹™æ•¸", min_value=1, max_value=8, value=4)
            random_seed = st.number_input("éš¨æ©Ÿç¨®å­", min_value=0, max_value=9999, value=42)
    
    # é–‹å§‹è¨“ç·´æŒ‰éˆ•
    if st.button("ğŸš€ é–‹å§‹æ¨™æº–è¨“ç·´", use_container_width=True, type="primary"):
        _start_standard_training(locals())


def show_deep_training_config(model_data: Dict, is_editing: bool):
    """é¡¯ç¤ºæ·±åº¦è¨“ç·´é…ç½®
    
    Args:
        model_data: æ¨¡å‹è³‡æ–™
        is_editing: æ˜¯å¦ç‚ºç·¨è¼¯æ¨¡å¼
    """
    st.subheader("ğŸ§  æ·±åº¦è¨“ç·´é…ç½®")
    
    create_info_card(
        "æ·±åº¦è¨“ç·´",
        "æä¾›æœ€å®Œæ•´çš„é…ç½®é¸é …ï¼ŒåŒ…æ‹¬æ·±åº¦å­¸ç¿’æ¨¡å‹ã€é«˜ç´šç‰¹å¾µå·¥ç¨‹å’Œæ¨¡å‹é›†æˆã€‚",
        "ğŸ§ "
    )
    
    # æ·±åº¦å­¸ç¿’æ¨¡å‹é…ç½®
    with st.expander("ğŸ¤– æ·±åº¦å­¸ç¿’æ¨¡å‹", expanded=True):
        model_architecture = st.selectbox(
            "æ¨¡å‹æ¶æ§‹",
            options=["LSTM", "GRU", "Transformer", "CNN-LSTM", "Attention"]
        )
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            hidden_layers = st.number_input("éš±è—å±¤æ•¸", min_value=1, max_value=10, value=3)
            hidden_units = st.number_input("éš±è—å–®å…ƒæ•¸", min_value=32, max_value=512, value=128)
        
        with col2:
            dropout_rate = st.slider("Dropout ç‡", min_value=0.0, max_value=0.5, value=0.2)
            learning_rate = st.number_input("å­¸ç¿’ç‡", min_value=0.0001, max_value=0.1, value=0.001, format="%.4f")
        
        with col3:
            batch_size = st.number_input("æ‰¹æ¬¡å¤§å°", min_value=16, max_value=512, value=64)
            epochs = st.number_input("è¨“ç·´è¼ªæ•¸", min_value=10, max_value=1000, value=100)
    
    # é«˜ç´šç‰¹å¾µå·¥ç¨‹
    with st.expander("ğŸ”¬ é«˜ç´šç‰¹å¾µå·¥ç¨‹"):
        st.multiselect(
            "ç‰¹å¾µå·¥ç¨‹æŠ€è¡“",
            options=[
                "ä¸»æˆåˆ†åˆ†æ (PCA)",
                "ç¨ç«‹æˆåˆ†åˆ†æ (ICA)", 
                "è‡ªç·¨ç¢¼å™¨ç‰¹å¾µ",
                "æ™‚é–“åºåˆ—åˆ†è§£",
                "å°æ³¢è®Šæ›",
                "å‚…ç«‹è‘‰è®Šæ›"
            ],
            default=["ä¸»æˆåˆ†åˆ†æ (PCA)", "æ™‚é–“åºåˆ—åˆ†è§£"]
        )
    
    # æ¨¡å‹é›†æˆ
    with st.expander("ğŸ­ æ¨¡å‹é›†æˆ"):
        ensemble_method = st.selectbox(
            "é›†æˆæ–¹æ³•",
            options=["Voting", "Bagging", "Boosting", "Stacking"]
        )
        
        base_models = st.multiselect(
            "åŸºç¤æ¨¡å‹",
            options=["RandomForest", "XGBoost", "LightGBM", "Neural Network", "SVM"],
            default=["RandomForest", "XGBoost", "Neural Network"]
        )
    
    if st.button("ğŸš€ é–‹å§‹æ·±åº¦è¨“ç·´", use_container_width=True, type="primary"):
        _start_deep_training(locals())


def show_auto_tuning_config(model_data: Dict, is_editing: bool):
    """é¡¯ç¤ºè‡ªå‹•èª¿å„ªé…ç½®
    
    Args:
        model_data: æ¨¡å‹è³‡æ–™
        is_editing: æ˜¯å¦ç‚ºç·¨è¼¯æ¨¡å¼
    """
    st.subheader("ğŸ›ï¸ è‡ªå‹•èª¿å„ªé…ç½®")
    
    create_info_card(
        "è‡ªå‹•èª¿å„ª",
        "ä½¿ç”¨è‡ªå‹•åŒ–æ©Ÿå™¨å­¸ç¿’ (AutoML) æŠ€è¡“ï¼Œè‡ªå‹•é¸æ“‡æœ€ä½³æ¼”ç®—æ³•å’Œè¶…åƒæ•¸ã€‚",
        "ğŸ›ï¸"
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        optimization_metric = st.selectbox(
            "å„ªåŒ–æŒ‡æ¨™",
            options=["accuracy", "f1_score", "roc_auc", "precision", "recall", "mse", "mae"]
        )
        
        search_algorithm = st.selectbox(
            "æœç´¢æ¼”ç®—æ³•",
            options=["Random Search", "Grid Search", "Bayesian Optimization", "Genetic Algorithm"]
        )
    
    with col2:
        max_trials = st.number_input("æœ€å¤§è©¦é©—æ¬¡æ•¸", min_value=10, max_value=1000, value=100)
        max_time_hours = st.number_input("æœ€å¤§æ™‚é–“ (å°æ™‚)", min_value=1, max_value=48, value=6)
    
    if st.button("ğŸš€ é–‹å§‹è‡ªå‹•èª¿å„ª", use_container_width=True, type="primary"):
        _start_auto_tuning(optimization_metric, search_algorithm, max_trials, max_time_hours)


def show_training_results():
    """é¡¯ç¤ºè¨“ç·´çµæœ"""
    st.subheader("ğŸ“Š è¨“ç·´çµæœ")
    
    # æ¨¡æ“¬è¨“ç·´çµæœè³‡æ–™
    results = _get_mock_training_results()
    
    # é¡¯ç¤ºé—œéµæŒ‡æ¨™
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æº–ç¢ºç‡", f"{results['accuracy']:.3f}", "â†‘0.05")
    
    with col2:
        st.metric("F1 åˆ†æ•¸", f"{results['f1_score']:.3f}", "â†‘0.03")
    
    with col3:
        st.metric("è¨“ç·´æ™‚é–“", f"{results['training_time']:.1f}åˆ†", "â†“2.3åˆ†")
    
    with col4:
        st.metric("é©—è­‰æå¤±", f"{results['val_loss']:.4f}", "â†“0.02")
    
    # è¨“ç·´æ›²ç·š
    _show_training_curves(results)
    
    # ç‰¹å¾µé‡è¦æ€§
    _show_feature_importance(results)


def show_model_training():
    """é¡¯ç¤ºæ¨¡å‹è¨“ç·´é é¢ (ç°¡åŒ–ç‰ˆ)"""
    st.header("ğŸ¯ æ¨¡å‹è¨“ç·´")
    st.info("è«‹ä½¿ç”¨ä¸Šæ–¹çš„å¢å¼·ç‰ˆæ¨¡å‹è¨“ç·´åŠŸèƒ½")


def _show_training_mode_info(mode: str) -> None:
    """é¡¯ç¤ºè¨“ç·´æ¨¡å¼è³‡è¨Š"""
    mode_info = {
        "quick": ("âš¡", "å¿«é€Ÿè¨“ç·´", "ä½¿ç”¨é è¨­åƒæ•¸ï¼Œ5-15åˆ†é˜å®Œæˆ"),
        "standard": ("ğŸ¯", "æ¨™æº–è¨“ç·´", "å¹³è¡¡çš„é…ç½®é¸é …ï¼Œ30åˆ†é˜-2å°æ™‚"),
        "deep": ("ğŸ§ ", "æ·±åº¦è¨“ç·´", "å®Œæ•´é…ç½®ï¼Œæ”¯æ´æ·±åº¦å­¸ç¿’ï¼Œ2-24å°æ™‚"),
        "auto_tuning": ("ğŸ›ï¸", "è‡ªå‹•èª¿å„ª", "AutoMLè‡ªå‹•å„ªåŒ–ï¼Œ1-48å°æ™‚")
    }
    
    icon, title, description = mode_info.get(mode, ("", "", ""))
    create_info_card(title, description, icon)


def _show_hyperparameter_config(algorithm: str) -> None:
    """é¡¯ç¤ºè¶…åƒæ•¸é…ç½®"""
    if algorithm == "RandomForest":
        col1, col2 = st.columns(2)
        with col1:
            st.number_input("n_estimators", min_value=10, max_value=1000, value=100)
            st.number_input("max_depth", min_value=1, max_value=50, value=10)
        with col2:
            st.slider("min_samples_split", min_value=2, max_value=20, value=2)
            st.slider("min_samples_leaf", min_value=1, max_value=20, value=1)


def _start_quick_training(model_name, algorithm, target_column, data_source, train_size, max_time, uploaded_file):
    """é–‹å§‹å¿«é€Ÿè¨“ç·´"""
    if not all([model_name, algorithm, target_column]):
        st.error("è«‹å¡«å¯«æ‰€æœ‰å¿…å¡«æ¬„ä½")
        return
    
    with st.spinner("æ­£åœ¨é–‹å§‹å¿«é€Ÿè¨“ç·´..."):
        st.success("âœ… å¿«é€Ÿè¨“ç·´å·²é–‹å§‹ï¼")
        st.info("è¨“ç·´é€²åº¦å°‡åœ¨è¨“ç·´çµæœé é¢é¡¯ç¤º")


def _start_standard_training(config):
    """é–‹å§‹æ¨™æº–è¨“ç·´"""
    st.success("âœ… æ¨™æº–è¨“ç·´å·²é–‹å§‹ï¼")


def _start_deep_training(config):
    """é–‹å§‹æ·±åº¦è¨“ç·´"""
    st.success("âœ… æ·±åº¦è¨“ç·´å·²é–‹å§‹ï¼")


def _start_auto_tuning(metric, algorithm, trials, time_hours):
    """é–‹å§‹è‡ªå‹•èª¿å„ª"""
    st.success("âœ… è‡ªå‹•èª¿å„ªå·²é–‹å§‹ï¼")


def _get_mock_training_results():
    """ç²å–æ¨¡æ“¬è¨“ç·´çµæœ"""
    return {
        'accuracy': 0.856,
        'f1_score': 0.834,
        'training_time': 12.5,
        'val_loss': 0.234,
        'epochs': list(range(1, 51)),
        'train_loss': np.random.exponential(0.5, 50)[::-1] + 0.1,
        'val_loss_history': np.random.exponential(0.6, 50)[::-1] + 0.15
    }


def _show_training_curves(results):
    """é¡¯ç¤ºè¨“ç·´æ›²ç·š"""
    st.subheader("ğŸ“ˆ è¨“ç·´æ›²ç·š")
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=results['epochs'],
        y=results['train_loss'],
        mode='lines',
        name='è¨“ç·´æå¤±'
    ))
    fig.add_trace(go.Scatter(
        x=results['epochs'],
        y=results['val_loss_history'],
        mode='lines',
        name='é©—è­‰æå¤±'
    ))
    
    fig.update_layout(
        title="è¨“ç·´èˆ‡é©—è­‰æå¤±",
        xaxis_title="Epoch",
        yaxis_title="Loss"
    )
    
    st.plotly_chart(fig, use_container_width=True)


def _show_feature_importance(results):
    """é¡¯ç¤ºç‰¹å¾µé‡è¦æ€§"""
    st.subheader("ğŸ¯ ç‰¹å¾µé‡è¦æ€§")
    
    # æ¨¡æ“¬ç‰¹å¾µé‡è¦æ€§è³‡æ–™
    features = ['price', 'volume', 'ma_5', 'ma_20', 'rsi', 'macd', 'bollinger']
    importance = np.random.random(len(features))
    
    fig = px.bar(
        x=importance,
        y=features,
        orientation='h',
        title="ç‰¹å¾µé‡è¦æ€§æ’å"
    )
    
    st.plotly_chart(fig, use_container_width=True)
