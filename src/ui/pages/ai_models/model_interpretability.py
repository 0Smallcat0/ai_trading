"""
AI æ¨¡å‹è§£é‡‹æ€§åˆ†ææ¨¡çµ„

æ­¤æ¨¡çµ„æä¾›æ¨¡å‹è§£é‡‹æ€§åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- SHAP åˆ†æ
- LIME åˆ†æ
- ç‰¹å¾µé‡è¦æ€§åˆ†æ
- æ¨¡å‹æ±ºç­–é‚Šç•Œè¦–è¦ºåŒ–
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from typing import Dict, List, Optional, Any

from .base import get_ai_model_service, safe_strftime, create_info_card


def show_model_interpretability():
    """é¡¯ç¤ºæ¨¡å‹è§£é‡‹æ€§åˆ†æé é¢"""
    st.header("ğŸ” æ¨¡å‹è§£é‡‹æ€§åˆ†æ")
    
    # ç²å–å¯ç”¨æ¨¡å‹
    service = get_ai_model_service()
    models = service.get_models()
    active_models = [m for m in models if m.get('status') == 'active']
    
    if not active_models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ´»èºæ¨¡å‹")
        return
    
    # æ¨¡å‹é¸æ“‡
    model_options = {f"{m['name']} ({m['id']})": m for m in active_models}
    selected_model_key = st.selectbox("é¸æ“‡æ¨¡å‹", options=list(model_options.keys()))
    selected_model = model_options[selected_model_key]
    
    # è§£é‡‹æ–¹æ³•é¸æ“‡
    explanation_methods = {
        "SHAP åˆ†æ": "shap",
        "LIME åˆ†æ": "lime",
        "ç‰¹å¾µé‡è¦æ€§": "feature_importance",
        "éƒ¨åˆ†ä¾è³´åœ–": "partial_dependence"
    }
    
    selected_method = st.selectbox("è§£é‡‹æ–¹æ³•", options=list(explanation_methods.keys()))
    method_key = explanation_methods[selected_method]
    
    # é¡¯ç¤ºæ–¹æ³•èªªæ˜
    show_explanation_method_info(method_key)
    
    # æ¨£æœ¬è³‡æ–™ç”Ÿæˆ
    st.subheader("ğŸ“Š æ¨£æœ¬è³‡æ–™")
    
    col1, col2 = st.columns(2)
    
    with col1:
        sample_size = st.number_input("æ¨£æœ¬æ•¸é‡", min_value=1, max_value=1000, value=100)
        data_source = st.selectbox("è³‡æ–™ä¾†æº", ["ç”Ÿæˆæ¨¡æ“¬è³‡æ–™", "ä¸Šå‚³æª”æ¡ˆ", "å¾è³‡æ–™åº«è¼‰å…¥"])
    
    with col2:
        if st.button("ğŸ² ç”Ÿæˆæ¨£æœ¬è³‡æ–™", use_container_width=True):
            sample_data = generate_sample_data(selected_model, sample_size)
            st.session_state.sample_data = sample_data
    
    # å¦‚æœæœ‰æ¨£æœ¬è³‡æ–™ï¼Œé¡¯ç¤ºè§£é‡‹åˆ†æ
    if hasattr(st.session_state, 'sample_data'):
        st.subheader("ğŸ” è§£é‡‹åˆ†æ")
        
        if st.button("ğŸš€ é–‹å§‹åˆ†æ", use_container_width=True, type="primary"):
            _perform_explanation_analysis(selected_model, method_key, st.session_state.sample_data, service)


def generate_sample_data(model: Dict, sample_size: int) -> Dict:
    """ç”Ÿæˆç”¨æ–¼è§£é‡‹çš„æ¨£æœ¬æ•¸æ“š
    
    Args:
        model: æ¨¡å‹è³‡è¨Š
        sample_size: æ¨£æœ¬æ•¸é‡
        
    Returns:
        åŒ…å«æ¨£æœ¬è³‡æ–™çš„å­—å…¸
    """
    # æ¨¡æ“¬ç‰¹å¾µè³‡æ–™
    features = ['price', 'volume', 'ma_5', 'ma_20', 'rsi', 'macd', 'bollinger_upper', 'bollinger_lower']
    
    data = {}
    for feature in features:
        if feature == 'price':
            data[feature] = np.random.uniform(50, 200, sample_size)
        elif feature == 'volume':
            data[feature] = np.random.uniform(1000, 100000, sample_size)
        elif feature in ['ma_5', 'ma_20']:
            data[feature] = np.random.uniform(45, 205, sample_size)
        elif feature == 'rsi':
            data[feature] = np.random.uniform(0, 100, sample_size)
        elif feature == 'macd':
            data[feature] = np.random.uniform(-5, 5, sample_size)
        else:
            data[feature] = np.random.uniform(40, 210, sample_size)
    
    df = pd.DataFrame(data)
    
    # é¡¯ç¤ºè³‡æ–™é è¦½
    st.write("**ç”Ÿæˆçš„æ¨£æœ¬è³‡æ–™é è¦½ï¼š**")
    st.dataframe(df.head(10), use_container_width=True)
    
    return {
        'dataframe': df,
        'features': features,
        'sample_size': sample_size,
        'generated_at': datetime.now()
    }


def show_explanation_results(explanation_result: Dict, method: str):
    """é¡¯ç¤ºè§£é‡‹åˆ†æçµæœ
    
    Args:
        explanation_result: è§£é‡‹çµæœ
        method: è§£é‡‹æ–¹æ³•
    """
    st.subheader(f"ğŸ“ˆ {method.upper()} åˆ†æçµæœ")
    
    if method == "shap":
        _show_shap_results(explanation_result)
    elif method == "lime":
        _show_lime_results(explanation_result)
    elif method == "feature_importance":
        _show_feature_importance_results(explanation_result)
    elif method == "partial_dependence":
        _show_partial_dependence_results(explanation_result)


def show_explanation_method_info(method: str):
    """é¡¯ç¤ºè§£é‡‹æ–¹æ³•çš„èªªæ˜è³‡è¨Š
    
    Args:
        method: è§£é‡‹æ–¹æ³•
    """
    method_info = {
        "shap": {
            "title": "SHAP (SHapley Additive exPlanations)",
            "description": "åŸºæ–¼åšå¼ˆè«–çš„ç‰¹å¾µé‡è¦æ€§åˆ†æï¼Œæä¾›æ¯å€‹ç‰¹å¾µå°é æ¸¬çµæœçš„è²¢ç»åº¦ã€‚",
            "advantages": ["å…¨åŸŸå’Œå±€éƒ¨è§£é‡‹", "ç†è«–åŸºç¤å …å¯¦", "æ”¯æ´å¤šç¨®æ¨¡å‹é¡å‹"],
            "use_cases": ["ç‰¹å¾µé‡è¦æ€§æ’åº", "é æ¸¬çµæœè§£é‡‹", "æ¨¡å‹åå·®æª¢æ¸¬"]
        },
        "lime": {
            "title": "LIME (Local Interpretable Model-agnostic Explanations)",
            "description": "é€šéåœ¨å±€éƒ¨å€åŸŸæ“¬åˆç°¡å–®æ¨¡å‹ä¾†è§£é‡‹è¤‡é›œæ¨¡å‹çš„é æ¸¬çµæœã€‚",
            "advantages": ["æ¨¡å‹ç„¡é—œ", "å±€éƒ¨è§£é‡‹", "ç›´è§€æ˜“æ‡‚"],
            "use_cases": ["å–®ä¸€é æ¸¬è§£é‡‹", "ç•°å¸¸æª¢æ¸¬", "æ±ºç­–æ”¯æ´"]
        },
        "feature_importance": {
            "title": "ç‰¹å¾µé‡è¦æ€§åˆ†æ",
            "description": "åˆ†æå„å€‹ç‰¹å¾µå°æ¨¡å‹æ•´é«”æ€§èƒ½çš„è²¢ç»ç¨‹åº¦ã€‚",
            "advantages": ["è¨ˆç®—ç°¡å–®", "å…¨åŸŸè¦–è§’", "ç‰¹å¾µé¸æ“‡æŒ‡å°"],
            "use_cases": ["ç‰¹å¾µé¸æ“‡", "æ¨¡å‹ç°¡åŒ–", "æ¥­å‹™æ´å¯Ÿ"]
        },
        "partial_dependence": {
            "title": "éƒ¨åˆ†ä¾è³´åœ– (Partial Dependence Plot)",
            "description": "é¡¯ç¤ºç‰¹å¾µèˆ‡é æ¸¬çµæœä¹‹é–“çš„é‚Šéš›é—œä¿‚ã€‚",
            "advantages": ["è¦–è¦ºåŒ–ç›´è§€", "é—œä¿‚æ¸…æ™°", "æ”¯æ´äº¤äº’ä½œç”¨"],
            "use_cases": ["ç‰¹å¾µæ•ˆæ‡‰åˆ†æ", "é–¾å€¼è¨­å®š", "æ¥­å‹™è¦å‰‡åˆ¶å®š"]
        }
    }
    
    info = method_info.get(method, {})
    if info:
        create_info_card(
            info["title"],
            info["description"],
            "ğŸ”"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**å„ªå‹¢ï¼š**")
            for advantage in info.get("advantages", []):
                st.write(f"â€¢ {advantage}")
        
        with col2:
            st.write("**æ‡‰ç”¨å ´æ™¯ï¼š**")
            for use_case in info.get("use_cases", []):
                st.write(f"â€¢ {use_case}")


def _perform_explanation_analysis(model: Dict, method: str, sample_data: Dict, service) -> None:
    """åŸ·è¡Œè§£é‡‹åˆ†æ"""
    try:
        with st.spinner(f"æ­£åœ¨é€²è¡Œ {method.upper()} åˆ†æ..."):
            # æ¨¡æ“¬è§£é‡‹çµæœ
            explanation_result = service.explain_prediction(
                model['id'], 
                sample_data['dataframe'], 
                method
            )
            
            # å¢å¼·æ¨¡æ“¬çµæœ
            if method == "shap":
                explanation_result = _generate_mock_shap_results(sample_data)
            elif method == "lime":
                explanation_result = _generate_mock_lime_results(sample_data)
            elif method == "feature_importance":
                explanation_result = _generate_mock_feature_importance_results(sample_data)
            elif method == "partial_dependence":
                explanation_result = _generate_mock_partial_dependence_results(sample_data)
            
            st.success(f"âœ… {method.upper()} åˆ†æå®Œæˆï¼")
            show_explanation_results(explanation_result, method)
            
    except Exception as e:
        st.error(f"âŒ è§£é‡‹åˆ†æå¤±æ•—: {e}")


def _generate_mock_shap_results(sample_data: Dict) -> Dict:
    """ç”Ÿæˆæ¨¡æ“¬ SHAP çµæœ"""
    features = sample_data['features']
    sample_size = min(sample_data['sample_size'], 10)  # é™åˆ¶é¡¯ç¤ºæ•¸é‡
    
    # ç”Ÿæˆ SHAP å€¼
    shap_values = np.random.uniform(-0.5, 0.5, (sample_size, len(features)))
    
    return {
        'shap_values': shap_values,
        'features': features,
        'feature_importance': {feature: np.abs(shap_values[:, i]).mean() 
                             for i, feature in enumerate(features)},
        'base_value': 0.5,
        'sample_size': sample_size
    }


def _generate_mock_lime_results(sample_data: Dict) -> Dict:
    """ç”Ÿæˆæ¨¡æ“¬ LIME çµæœ"""
    features = sample_data['features']
    
    return {
        'feature_weights': {feature: np.random.uniform(-1, 1) for feature in features},
        'intercept': np.random.uniform(0.3, 0.7),
        'score': np.random.uniform(0.7, 0.95),
        'local_prediction': np.random.uniform(0, 1)
    }


def _generate_mock_feature_importance_results(sample_data: Dict) -> Dict:
    """ç”Ÿæˆæ¨¡æ“¬ç‰¹å¾µé‡è¦æ€§çµæœ"""
    features = sample_data['features']
    importance_scores = np.random.random(len(features))
    importance_scores = importance_scores / importance_scores.sum()  # æ­£è¦åŒ–
    
    return {
        'feature_importance': dict(zip(features, importance_scores)),
        'method': 'permutation_importance',
        'std': np.random.uniform(0.01, 0.05, len(features))
    }


def _generate_mock_partial_dependence_results(sample_data: Dict) -> Dict:
    """ç”Ÿæˆæ¨¡æ“¬éƒ¨åˆ†ä¾è³´åœ–çµæœ"""
    features = sample_data['features']
    
    results = {}
    for feature in features[:3]:  # åªç‚ºå‰3å€‹ç‰¹å¾µç”Ÿæˆ
        x_values = np.linspace(
            sample_data['dataframe'][feature].min(),
            sample_data['dataframe'][feature].max(),
            50
        )
        y_values = np.sin(x_values / x_values.max() * np.pi) * 0.3 + 0.5 + np.random.normal(0, 0.05, 50)
        
        results[feature] = {
            'x_values': x_values,
            'y_values': y_values
        }
    
    return results


def _show_shap_results(result: Dict) -> None:
    """é¡¯ç¤º SHAP çµæœ"""
    # ç‰¹å¾µé‡è¦æ€§æ¢å½¢åœ–
    st.subheader("ğŸ“Š ç‰¹å¾µé‡è¦æ€§ (SHAP)")
    
    importance_df = pd.DataFrame(
        list(result['feature_importance'].items()),
        columns=['ç‰¹å¾µ', 'é‡è¦æ€§']
    ).sort_values('é‡è¦æ€§', ascending=True)
    
    fig = px.bar(
        importance_df,
        x='é‡è¦æ€§',
        y='ç‰¹å¾µ',
        orientation='h',
        title="SHAP ç‰¹å¾µé‡è¦æ€§"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # SHAP å€¼ç†±åŠ›åœ–
    st.subheader("ğŸ”¥ SHAP å€¼ç†±åŠ›åœ–")
    
    fig = px.imshow(
        result['shap_values'].T,
        x=[f"æ¨£æœ¬ {i+1}" for i in range(result['sample_size'])],
        y=result['features'],
        color_continuous_scale='RdBu',
        title="SHAP å€¼åˆ†ä½ˆ"
    )
    st.plotly_chart(fig, use_container_width=True)


def _show_lime_results(result: Dict) -> None:
    """é¡¯ç¤º LIME çµæœ"""
    st.subheader("ğŸ“Š LIME ç‰¹å¾µæ¬Šé‡")
    
    weights_df = pd.DataFrame(
        list(result['feature_weights'].items()),
        columns=['ç‰¹å¾µ', 'æ¬Šé‡']
    ).sort_values('æ¬Šé‡', ascending=True)
    
    # å‰µå»ºé¡è‰²æ˜ å°„
    colors = ['red' if w < 0 else 'blue' for w in weights_df['æ¬Šé‡']]
    
    fig = px.bar(
        weights_df,
        x='æ¬Šé‡',
        y='ç‰¹å¾µ',
        orientation='h',
        title=f"LIME å±€éƒ¨è§£é‡‹ (é æ¸¬å€¼: {result['local_prediction']:.3f})",
        color=weights_df['æ¬Šé‡'],
        color_continuous_scale='RdBu'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # é¡¯ç¤ºè§£é‡‹çµ±è¨ˆ
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("å±€éƒ¨é æ¸¬å€¼", f"{result['local_prediction']:.3f}")
        st.metric("è§£é‡‹åˆ†æ•¸", f"{result['score']:.3f}")
    
    with col2:
        st.metric("æˆªè·", f"{result['intercept']:.3f}")
        st.metric("ç‰¹å¾µæ•¸é‡", len(result['feature_weights']))


def _show_feature_importance_results(result: Dict) -> None:
    """é¡¯ç¤ºç‰¹å¾µé‡è¦æ€§çµæœ"""
    st.subheader("ğŸ“Š ç‰¹å¾µé‡è¦æ€§æ’åº")
    
    importance_df = pd.DataFrame(
        list(result['feature_importance'].items()),
        columns=['ç‰¹å¾µ', 'é‡è¦æ€§']
    ).sort_values('é‡è¦æ€§', ascending=False)
    
    fig = px.bar(
        importance_df,
        x='ç‰¹å¾µ',
        y='é‡è¦æ€§',
        title="ç‰¹å¾µé‡è¦æ€§æ’åº"
    )
    fig.update_xaxis(tickangle=45)
    st.plotly_chart(fig, use_container_width=True)
    
    # é¡¯ç¤ºè©³ç´°è¡¨æ ¼
    st.subheader("ğŸ“‹ è©³ç´°æ•¸æ“š")
    st.dataframe(importance_df, use_container_width=True)


def _show_partial_dependence_results(result: Dict) -> None:
    """é¡¯ç¤ºéƒ¨åˆ†ä¾è³´åœ–çµæœ"""
    st.subheader("ğŸ“ˆ éƒ¨åˆ†ä¾è³´åœ–")
    
    for feature, data in result.items():
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=data['x_values'],
            y=data['y_values'],
            mode='lines+markers',
            name=f'{feature} éƒ¨åˆ†ä¾è³´'
        ))
        
        fig.update_layout(
            title=f"{feature} çš„éƒ¨åˆ†ä¾è³´é—œä¿‚",
            xaxis_title=feature,
            yaxis_title="é æ¸¬å€¼"
        )
        
        st.plotly_chart(fig, use_container_width=True)
