"""
AI æ¨¡å‹æ¸…å–®ç®¡ç†æ¨¡çµ„

æ­¤æ¨¡çµ„æä¾›æ¨¡å‹æ¸…å–®çš„ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ¨¡å‹æ¸…å–®é¡¯ç¤ºå’Œç¯©é¸
- æ¨¡å‹ä¸Šå‚³å’ŒåŒ¯å…¥
- æ¨¡å‹åŸºæœ¬è³‡è¨Šç·¨è¼¯
- æ¨¡å‹ç‹€æ…‹ç®¡ç†
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional

from .base import get_ai_model_service, safe_strftime, create_status_badge, format_model_metrics


def show_model_list():
    """é¡¯ç¤ºæ¨¡å‹æ¸…å–®é é¢
    
    æä¾›æ¨¡å‹çš„æ¸…å–®æª¢è¦–ï¼ŒåŒ…æ‹¬ï¼š
    - æ¨¡å‹åŸºæœ¬è³‡è¨Šè¡¨æ ¼
    - æœå°‹å’Œç¯©é¸åŠŸèƒ½
    - æ¨¡å‹æ“ä½œæŒ‰éˆ•
    - æ‰¹é‡æ“ä½œåŠŸèƒ½
    """
    st.header("ğŸ“‹ æ¨¡å‹æ¸…å–®")
    
    # ç²å–æœå‹™å¯¦ä¾‹
    service = get_ai_model_service()
    
    # æ§åˆ¶é¢æ¿
    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
    
    with col1:
        search_term = st.text_input("ğŸ” æœå°‹æ¨¡å‹", placeholder="è¼¸å…¥æ¨¡å‹åç¨±æˆ–ID...")
    
    with col2:
        status_filter = st.selectbox(
            "ç‹€æ…‹ç¯©é¸",
            options=["å…¨éƒ¨", "active", "training", "inactive", "error"],
            index=0
        )
    
    with col3:
        type_filter = st.selectbox(
            "é¡å‹ç¯©é¸", 
            options=["å…¨éƒ¨", "classification", "regression", "clustering"],
            index=0
        )
    
    with col4:
        st.markdown("<br>", unsafe_allow_html=True)  # ç©ºè¡Œå°é½Š
        if st.button("ğŸ”„ é‡æ–°æ•´ç†", use_container_width=True):
            st.rerun()
    
    # ç²å–æ¨¡å‹åˆ—è¡¨
    try:
        models = service.get_models()
        
        # æ‡‰ç”¨ç¯©é¸
        filtered_models = _apply_filters(models, search_term, status_filter, type_filter)
        
        if not filtered_models:
            st.info("ğŸ“­ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ¨¡å‹")
            return
        
        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        _show_model_statistics(filtered_models)
        
        # é¡¯ç¤ºæ¨¡å‹è¡¨æ ¼
        _show_model_table(filtered_models, service)
        
        # æ‰¹é‡æ“ä½œ
        _show_batch_operations(filtered_models, service)
        
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥æ¨¡å‹æ¸…å–®å¤±æ•—: {e}")


def show_model_upload_form(uploaded_file):
    """é¡¯ç¤ºæ¨¡å‹ä¸Šå‚³è¡¨å–®
    
    Args:
        uploaded_file: Streamlit ä¸Šå‚³çš„æª”æ¡ˆç‰©ä»¶
    """
    st.header("ğŸ“¤ æ¨¡å‹ä¸Šå‚³")
    
    if uploaded_file is None:
        st.info("è«‹é¸æ“‡è¦ä¸Šå‚³çš„æ¨¡å‹æª”æ¡ˆ")
        return
    
    # æª”æ¡ˆè³‡è¨Š
    st.subheader("ğŸ“„ æª”æ¡ˆè³‡è¨Š")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**æª”æ¡ˆåç¨±**: {uploaded_file.name}")
        st.write(f"**æª”æ¡ˆå¤§å°**: {uploaded_file.size / 1024 / 1024:.2f} MB")
    
    with col2:
        st.write(f"**æª”æ¡ˆé¡å‹**: {uploaded_file.type}")
        st.write(f"**ä¸Šå‚³æ™‚é–“**: {safe_strftime(datetime.now())}")
    
    # æ¨¡å‹é…ç½®è¡¨å–®
    st.subheader("âš™ï¸ æ¨¡å‹é…ç½®")
    
    with st.form("model_upload_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            model_name = st.text_input("æ¨¡å‹åç¨±*", placeholder="è¼¸å…¥æ¨¡å‹åç¨±")
            model_type = st.selectbox("æ¨¡å‹é¡å‹*", ["classification", "regression", "clustering"])
            algorithm = st.text_input("æ¼”ç®—æ³•*", placeholder="ä¾‹å¦‚: RandomForest, XGBoost")
        
        with col2:
            version = st.text_input("ç‰ˆæœ¬", value="1.0.0", placeholder="ä¾‹å¦‚: 1.0.0")
            description = st.text_area("æè¿°", placeholder="æ¨¡å‹æè¿°...")
            tags = st.text_input("æ¨™ç±¤", placeholder="ç”¨é€—è™Ÿåˆ†éš”ï¼Œä¾‹å¦‚: è‚¡ç¥¨,é æ¸¬,æ©Ÿå™¨å­¸ç¿’")
        
        # é€²éšè¨­å®š
        with st.expander("ğŸ”§ é€²éšè¨­å®š"):
            auto_deploy = st.checkbox("è‡ªå‹•éƒ¨ç½²", value=False)
            enable_monitoring = st.checkbox("å•Ÿç”¨ç›£æ§", value=True)
            max_memory = st.number_input("æœ€å¤§è¨˜æ†¶é«” (MB)", min_value=128, max_value=8192, value=512)
            timeout = st.number_input("è¶…æ™‚æ™‚é–“ (ç§’)", min_value=1, max_value=300, value=30)
        
        # æäº¤æŒ‰éˆ•
        submitted = st.form_submit_button("ğŸ“¤ ä¸Šå‚³æ¨¡å‹", use_container_width=True)
        
        if submitted:
            # é©—è­‰å¿…å¡«æ¬„ä½
            if not all([model_name, model_type, algorithm]):
                st.error("âŒ è«‹å¡«å¯«æ‰€æœ‰å¿…å¡«æ¬„ä½ï¼ˆæ¨™è¨˜*çš„æ¬„ä½ï¼‰")
                return
            
            # æº–å‚™æ¨¡å‹è³‡æ–™
            model_data = {
                'name': model_name,
                'type': model_type,
                'algorithm': algorithm,
                'version': version,
                'description': description,
                'tags': [tag.strip() for tag in tags.split(',') if tag.strip()],
                'file_name': uploaded_file.name,
                'file_size': uploaded_file.size,
                'auto_deploy': auto_deploy,
                'enable_monitoring': enable_monitoring,
                'max_memory': max_memory,
                'timeout': timeout,
                'uploaded_at': datetime.now().isoformat()
            }
            
            # ä¸Šå‚³æ¨¡å‹
            _upload_model(model_data, uploaded_file)


def _apply_filters(models: List[Dict], search_term: str, status_filter: str, type_filter: str) -> List[Dict]:
    """æ‡‰ç”¨ç¯©é¸æ¢ä»¶
    
    Args:
        models: æ¨¡å‹åˆ—è¡¨
        search_term: æœå°‹é—œéµå­—
        status_filter: ç‹€æ…‹ç¯©é¸
        type_filter: é¡å‹ç¯©é¸
        
    Returns:
        ç¯©é¸å¾Œçš„æ¨¡å‹åˆ—è¡¨
    """
    filtered = models
    
    # æœå°‹ç¯©é¸
    if search_term:
        filtered = [
            model for model in filtered
            if search_term.lower() in model.get('name', '').lower() or
               search_term.lower() in model.get('id', '').lower()
        ]
    
    # ç‹€æ…‹ç¯©é¸
    if status_filter != "å…¨éƒ¨":
        filtered = [model for model in filtered if model.get('status') == status_filter]
    
    # é¡å‹ç¯©é¸
    if type_filter != "å…¨éƒ¨":
        filtered = [model for model in filtered if model.get('type') == type_filter]
    
    return filtered


def _show_model_statistics(models: List[Dict]) -> None:
    """é¡¯ç¤ºæ¨¡å‹çµ±è¨ˆè³‡è¨Š
    
    Args:
        models: æ¨¡å‹åˆ—è¡¨
    """
    col1, col2, col3, col4 = st.columns(4)
    
    total_models = len(models)
    active_models = len([m for m in models if m.get('status') == 'active'])
    training_models = len([m for m in models if m.get('status') == 'training'])
    avg_accuracy = np.mean([m.get('accuracy', 0) for m in models if m.get('accuracy')])
    
    with col1:
        st.metric("ç¸½æ¨¡å‹æ•¸", total_models)
    
    with col2:
        st.metric("æ´»èºæ¨¡å‹", active_models, f"{active_models/total_models*100:.1f}%")
    
    with col3:
        st.metric("è¨“ç·´ä¸­", training_models)
    
    with col4:
        st.metric("å¹³å‡æº–ç¢ºç‡", f"{avg_accuracy:.3f}" if avg_accuracy > 0 else "N/A")


def _show_model_table(models: List[Dict], service) -> None:
    """é¡¯ç¤ºæ¨¡å‹è¡¨æ ¼
    
    Args:
        models: æ¨¡å‹åˆ—è¡¨
        service: AI æ¨¡å‹æœå‹™å¯¦ä¾‹
    """
    st.subheader("ğŸ“Š æ¨¡å‹è©³ç´°è³‡è¨Š")
    
    # æº–å‚™è¡¨æ ¼è³‡æ–™
    table_data = []
    for model in models:
        table_data.append({
            'ID': model.get('id', 'N/A'),
            'åç¨±': model.get('name', 'N/A'),
            'é¡å‹': model.get('type', 'N/A'),
            'ç‹€æ…‹': model.get('status', 'unknown'),
            'æº–ç¢ºç‡': f"{model.get('accuracy', 0):.3f}" if model.get('accuracy') else 'N/A',
            'å‰µå»ºæ™‚é–“': safe_strftime(model.get('created_at', datetime.now())),
            'æ“ä½œ': model.get('id', '')
        })
    
    # é¡¯ç¤ºè¡¨æ ¼
    df = pd.DataFrame(table_data)
    
    # ä½¿ç”¨ st.data_editor æä¾›äº’å‹•åŠŸèƒ½
    edited_df = st.data_editor(
        df,
        column_config={
            "ç‹€æ…‹": st.column_config.SelectboxColumn(
                "ç‹€æ…‹",
                options=["active", "training", "inactive", "error"],
                required=True
            ),
            "æ“ä½œ": st.column_config.Column("æ“ä½œ", disabled=True)
        },
        disabled=["ID", "åç¨±", "é¡å‹", "æº–ç¢ºç‡", "å‰µå»ºæ™‚é–“", "æ“ä½œ"],
        hide_index=True,
        use_container_width=True
    )
    
    # è™•ç†ç‹€æ…‹è®Šæ›´
    if not df.equals(edited_df):
        _handle_status_changes(df, edited_df, service)


def _show_batch_operations(models: List[Dict], service) -> None:
    """é¡¯ç¤ºæ‰¹é‡æ“ä½œ
    
    Args:
        models: æ¨¡å‹åˆ—è¡¨
        service: AI æ¨¡å‹æœå‹™å¯¦ä¾‹
    """
    st.subheader("ğŸ”§ æ‰¹é‡æ“ä½œ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸš€ æ‰¹é‡å•Ÿå‹•", use_container_width=True):
            _batch_activate_models(models, service)
    
    with col2:
        if st.button("â¸ï¸ æ‰¹é‡åœæ­¢", use_container_width=True):
            _batch_deactivate_models(models, service)
    
    with col3:
        if st.button("ğŸ“Š åŒ¯å‡ºæ¸…å–®", use_container_width=True):
            _export_model_list(models)
    
    with col4:
        if st.button("ğŸ—‘ï¸ æ‰¹é‡åˆªé™¤", use_container_width=True, type="secondary"):
            _batch_delete_models(models, service)


def _upload_model(model_data: Dict, uploaded_file) -> None:
    """ä¸Šå‚³æ¨¡å‹
    
    Args:
        model_data: æ¨¡å‹è³‡æ–™
        uploaded_file: ä¸Šå‚³çš„æª”æ¡ˆ
    """
    try:
        with st.spinner("æ­£åœ¨ä¸Šå‚³æ¨¡å‹..."):
            service = get_ai_model_service()
            result = service.create_model(model_data)
            
            if result.get('success'):
                st.success(f"âœ… æ¨¡å‹ä¸Šå‚³æˆåŠŸï¼æ¨¡å‹ID: {result.get('model_id')}")
                st.balloons()
            else:
                st.error(f"âŒ æ¨¡å‹ä¸Šå‚³å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                
    except Exception as e:
        st.error(f"âŒ ä¸Šå‚³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")


def _handle_status_changes(original_df: pd.DataFrame, edited_df: pd.DataFrame, service) -> None:
    """è™•ç†ç‹€æ…‹è®Šæ›´
    
    Args:
        original_df: åŸå§‹è³‡æ–™æ¡†
        edited_df: ç·¨è¼¯å¾Œçš„è³‡æ–™æ¡†
        service: AI æ¨¡å‹æœå‹™å¯¦ä¾‹
    """
    # æ‰¾å‡ºè®Šæ›´çš„è¡Œ
    changes = original_df.compare(edited_df)
    if not changes.empty:
        st.info("æª¢æ¸¬åˆ°ç‹€æ…‹è®Šæ›´ï¼Œæ­£åœ¨æ›´æ–°...")
        # é€™è£¡å¯ä»¥å¯¦ä½œå¯¦éš›çš„ç‹€æ…‹æ›´æ–°é‚è¼¯


def _batch_activate_models(models: List[Dict], service) -> None:
    """æ‰¹é‡å•Ÿå‹•æ¨¡å‹"""
    st.info("æ‰¹é‡å•Ÿå‹•åŠŸèƒ½é–‹ç™¼ä¸­...")


def _batch_deactivate_models(models: List[Dict], service) -> None:
    """æ‰¹é‡åœæ­¢æ¨¡å‹"""
    st.info("æ‰¹é‡åœæ­¢åŠŸèƒ½é–‹ç™¼ä¸­...")


def _export_model_list(models: List[Dict]) -> None:
    """åŒ¯å‡ºæ¨¡å‹æ¸…å–®"""
    df = pd.DataFrame(models)
    csv = df.to_csv(index=False)
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰ CSV",
        data=csv,
        file_name=f"model_list_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )


def _batch_delete_models(models: List[Dict], service) -> None:
    """æ‰¹é‡åˆªé™¤æ¨¡å‹"""
    st.warning("âš ï¸ æ‰¹é‡åˆªé™¤åŠŸèƒ½éœ€è¦ç®¡ç†å“¡æ¬Šé™")
