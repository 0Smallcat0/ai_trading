# -*- coding: utf-8 -*-
"""æ–‡æœ¬åˆ†æWebç•Œé¢

æ­¤æ¨¡çµ„æä¾›æ–‡æœ¬åˆ†æåŠŸèƒ½çš„Streamlit Webç•Œé¢ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€
æ–°èåˆ†é¡ã€è‚¡ç¥¨é—œè¯åˆ†æç­‰åŠŸèƒ½çš„å¯è¦–åŒ–å±•ç¤ºã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- å¯¦æ™‚æ–‡æœ¬åˆ†æ
- æ‰¹é‡æ–‡æœ¬è™•ç†
- æƒ…æ„Ÿè¶¨å‹¢å¯è¦–åŒ–
- æ–°èåˆ†é¡çµ±è¨ˆ
- è‚¡ç¥¨é—œè¯åˆ†æ
- çµæœå°å‡ºåŠŸèƒ½

Example:
    åœ¨Streamlitæ‡‰ç”¨ä¸­ä½¿ç”¨ï¼š
    >>> from src.ui.pages.text_analysis import render_text_analysis_page
    >>> render_text_analysis_page()
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import time

from src.nlp.text_analysis_adapter import TextAnalysisAdapter
from src.nlp.news_crawler import NewsCrawler, NewsItem
from src.nlp.news_classifier import NewsCategory


def render_text_analysis_page():
    """æ¸²æŸ“æ–‡æœ¬åˆ†æé é¢"""
    st.title("ğŸ“ æ–‡æœ¬åˆ†æç³»çµ±")
    st.markdown("---")
    
    # åˆå§‹åŒ–é©é…å™¨
    if 'text_adapter' not in st.session_state:
        with st.spinner("åˆå§‹åŒ–æ–‡æœ¬åˆ†æç³»çµ±..."):
            st.session_state.text_adapter = TextAnalysisAdapter()
    
    adapter = st.session_state.text_adapter
    
    # å´é‚Šæ¬„é…ç½®
    render_sidebar_config()
    
    # ä¸»è¦åŠŸèƒ½æ¨™ç±¤é 
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ¯ å¯¦æ™‚åˆ†æ", "ğŸ“Š æ‰¹é‡è™•ç†", "ğŸ“ˆ è¶¨å‹¢åˆ†æ", 
        "ğŸ“° æ–°èåˆ†æ", "ğŸ“‹ ç³»çµ±ç‹€æ…‹"
    ])
    
    with tab1:
        render_realtime_analysis_tab(adapter)
    
    with tab2:
        render_batch_processing_tab(adapter)
    
    with tab3:
        render_trend_analysis_tab(adapter)
    
    with tab4:
        render_news_analysis_tab(adapter)
    
    with tab5:
        render_system_status_tab(adapter)


def render_sidebar_config():
    """æ¸²æŸ“å´é‚Šæ¬„é…ç½®"""
    st.sidebar.header("âš™ï¸ ç³»çµ±é…ç½®")
    
    # åˆ†æé¸é …
    st.sidebar.subheader("åˆ†æé¸é …")
    st.session_state.enable_sentiment = st.sidebar.checkbox("æƒ…æ„Ÿåˆ†æ", value=True)
    st.session_state.enable_classification = st.sidebar.checkbox("æ–°èåˆ†é¡", value=True)
    st.session_state.enable_stock_analysis = st.sidebar.checkbox("è‚¡ç¥¨é—œè¯", value=True)
    
    # é¡¯ç¤ºé¸é …
    st.sidebar.subheader("é¡¯ç¤ºé¸é …")
    st.session_state.show_keywords = st.sidebar.checkbox("é¡¯ç¤ºé—œéµè©", value=True)
    st.session_state.show_confidence = st.sidebar.checkbox("é¡¯ç¤ºç½®ä¿¡åº¦", value=True)
    st.session_state.show_processing_time = st.sidebar.checkbox("é¡¯ç¤ºè™•ç†æ™‚é–“", value=False)
    
    # å¿«å–æ§åˆ¶
    st.sidebar.subheader("å¿«å–æ§åˆ¶")
    if st.sidebar.button("æ¸…ç©ºå¿«å–"):
        st.session_state.text_adapter.clear_cache()
        st.sidebar.success("å¿«å–å·²æ¸…ç©º")


def render_realtime_analysis_tab(adapter: TextAnalysisAdapter):
    """æ¸²æŸ“å¯¦æ™‚åˆ†ææ¨™ç±¤é """
    st.header("ğŸ¯ å¯¦æ™‚æ–‡æœ¬åˆ†æ")
    
    # æ–‡æœ¬è¼¸å…¥
    col1, col2 = st.columns([3, 1])
    
    with col1:
        input_text = st.text_area(
            "è«‹è¼¸å…¥è¦åˆ†æçš„æ–‡æœ¬ï¼š",
            height=150,
            placeholder="ä¾‹å¦‚ï¼šå¤®è¡Œå®£å¸ƒé™æº–0.5å€‹ç™¾åˆ†é»ï¼Œè‚¡å¸‚å¤§å¹…ä¸Šæ¼²...",
            key="realtime_text_input"
        )
    
    with col2:
        st.write("**å¿«é€Ÿç¤ºä¾‹ï¼š**")
        example_texts = [
            "è‚¡å¸‚å¤§æ¼²ï¼ŒæŠ•è³‡è€…ä¿¡å¿ƒå¢å¼·",
            "å¤®è¡Œé™æº–ï¼Œæµå‹•æ€§å¯¬é¬†",
            "å…¬å¸æ¥­ç¸¾ä¸‹æ»‘ï¼Œè‚¡åƒ¹æ‰¿å£“",
            "æ–°æ”¿ç­–åˆ©å¥½ç§‘æŠ€è¡Œæ¥­ç™¼å±•"
        ]
        
        for i, example in enumerate(example_texts):
            if st.button(f"ç¤ºä¾‹ {i+1}", key=f"example_{i}"):
                st.session_state.example_text = example
    
    # ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬
    if 'example_text' in st.session_state:
        input_text = st.session_state.example_text
        del st.session_state.example_text
    
    # åˆ†ææŒ‰éˆ•
    if st.button("ğŸ” é–‹å§‹åˆ†æ", type="primary", key="realtime_analysis_start_btn") and input_text:
        with st.spinner("åˆ†æä¸­..."):
            result = adapter.analyze_text(input_text)

            # é¡¯ç¤ºåˆ†æçµæœ
            render_analysis_result(result)

    elif st.button("ğŸ” é–‹å§‹åˆ†æ", type="primary", key="realtime_analysis_warning_btn"):
        st.warning("è«‹è¼¸å…¥è¦åˆ†æçš„æ–‡æœ¬")


def render_analysis_result(result):
    """æ¸²æŸ“åˆ†æçµæœ"""
    # ä¸»è¦æŒ‡æ¨™
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        sentiment_color = "red" if result.sentiment_score > 0 else "green" if result.sentiment_score < 0 else "gray"
        st.metric(
            "æƒ…æ„Ÿåˆ†æ•¸",
            f"{result.sentiment_score:.3f}",
            delta=None,
            delta_color="normal"
        )
    
    with col2:
        st.metric(
            "æ–°èåˆ†é¡",
            result.category.value if result.category != NewsCategory.UNKNOWN else "æœªçŸ¥",
            delta=None
        )
    
    with col3:
        if st.session_state.show_confidence:
            st.metric(
                "åˆ†é¡ç½®ä¿¡åº¦",
                f"{result.classification_confidence:.2%}",
                delta=None
            )
    
    with col4:
        if st.session_state.show_processing_time:
            processing_time = result.metadata.get('processing_time', 0)
            st.metric(
                "è™•ç†æ™‚é–“",
                f"{processing_time:.3f}s",
                delta=None
            )
    
    # è©³ç´°ä¿¡æ¯
    if st.session_state.show_keywords and result.keywords:
        st.subheader("ğŸ”‘ é—œéµè©")
        keywords_text = " | ".join([f"`{kw}`" for kw in result.keywords[:10]])
        st.markdown(keywords_text)
    
    # æƒ…æ„Ÿå¯è¦–åŒ–
    if result.sentiment_score != 0:
        st.subheader("ğŸ“Š æƒ…æ„Ÿåˆ†æå¯è¦–åŒ–")
        
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = result.sentiment_score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "æƒ…æ„Ÿåˆ†æ•¸"},
            delta = {'reference': 0},
            gauge = {
                'axis': {'range': [-1, 1]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [-1, -0.5], 'color': "red"},
                    {'range': [-0.5, 0], 'color': "orange"},
                    {'range': [0, 0.5], 'color': "lightgreen"},
                    {'range': [0.5, 1], 'color': "green"}
                ],
                'threshold': {
                    'line': {'color': "black", 'width': 4},
                    'thickness': 0.75,
                    'value': 0
                }
            }
        ))
        
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)


def render_batch_processing_tab(adapter: TextAnalysisAdapter):
    """æ¸²æŸ“æ‰¹é‡è™•ç†æ¨™ç±¤é """
    st.header("ğŸ“Š æ‰¹é‡æ–‡æœ¬è™•ç†")
    
    # æ–‡æœ¬è¼¸å…¥æ–¹å¼é¸æ“‡
    input_method = st.radio(
        "é¸æ“‡è¼¸å…¥æ–¹å¼ï¼š",
        ["æ‰‹å‹•è¼¸å…¥", "æ–‡ä»¶ä¸Šå‚³", "ç¤ºä¾‹æ•¸æ“š"],
        key="batch_input_method_radio"
    )
    
    texts = []
    
    if input_method == "æ‰‹å‹•è¼¸å…¥":
        text_input = st.text_area(
            "è«‹è¼¸å…¥å¤šè¡Œæ–‡æœ¬ï¼ˆæ¯è¡Œä¸€å€‹æ–‡æœ¬ï¼‰ï¼š",
            height=200,
            placeholder="ç¬¬ä¸€æ¢æ–‡æœ¬\nç¬¬äºŒæ¢æ–‡æœ¬\nç¬¬ä¸‰æ¢æ–‡æœ¬...",
            key="batch_text_input"
        )
        
        if text_input:
            texts = [line.strip() for line in text_input.split('\n') if line.strip()]
    
    elif input_method == "æ–‡ä»¶ä¸Šå‚³":
        uploaded_file = st.file_uploader(
            "ä¸Šå‚³æ–‡æœ¬æ–‡ä»¶",
            type=['txt', 'csv'],
            help="æ”¯æ´ .txt å’Œ .csv æ ¼å¼"
        )
        
        if uploaded_file:
            if uploaded_file.type == "text/plain":
                content = str(uploaded_file.read(), "utf-8")
                texts = [line.strip() for line in content.split('\n') if line.strip()]
            elif uploaded_file.type == "text/csv":
                df = pd.read_csv(uploaded_file)
                if 'text' in df.columns:
                    texts = df['text'].dropna().tolist()
                else:
                    st.error("CSVæ–‡ä»¶å¿…é ˆåŒ…å« 'text' åˆ—")
    
    else:  # ç¤ºä¾‹æ•¸æ“š
        example_texts = [
            "å¤®è¡Œå®£å¸ƒé™æº–ï¼Œå¸‚å ´æµå‹•æ€§å……è£•",
            "ç§‘æŠ€è‚¡å¤§å¹…ä¸Šæ¼²ï¼ŒæŠ•è³‡è€…æƒ…ç·’é«˜æ¼²",
            "æˆ¿åœ°ç”¢æ”¿ç­–æ”¶ç·Šï¼Œç›¸é—œè‚¡ç¥¨ä¸‹è·Œ",
            "æ–°èƒ½æºæ±½è»ŠéŠ·é‡å‰µæ–°é«˜",
            "é†«è—¥è¡Œæ¥­ç›£ç®¡åŠ å¼·ï¼Œè‚¡åƒ¹æ‰¿å£“",
            "é‡‘èç§‘æŠ€ç™¼å±•è¿…é€Ÿï¼Œå‰æ™¯çœ‹å¥½",
            "ç–«æƒ…å½±éŸ¿æ¶ˆè²»ï¼Œé›¶å”®æ¥­é¢è‡¨æŒ‘æˆ°",
            "åŸºå»ºæŠ•è³‡åŠ ç¢¼ï¼Œç›¸é—œæ¿å¡Šå—ç›Š"
        ]
        
        texts = example_texts
        st.info(f"å·²è¼‰å…¥ {len(texts)} æ¢ç¤ºä¾‹æ–‡æœ¬")
    
    # æ‰¹é‡è™•ç†
    if texts and st.button("ğŸš€ é–‹å§‹æ‰¹é‡è™•ç†", type="primary", key="batch_analysis_start_btn"):
        with st.spinner(f"æ­£åœ¨è™•ç† {len(texts)} æ¢æ–‡æœ¬..."):
            results = adapter.batch_analyze_texts(texts)

            # é¡¯ç¤ºè™•ç†çµæœ
            render_batch_results(results)

    elif st.button("ğŸš€ é–‹å§‹æ‰¹é‡è™•ç†", type="primary", key="batch_analysis_warning_btn"):
        st.warning("è«‹å…ˆè¼¸å…¥è¦è™•ç†çš„æ–‡æœ¬")


def render_batch_results(results):
    """æ¸²æŸ“æ‰¹é‡è™•ç†çµæœ"""
    st.subheader("ğŸ“‹ æ‰¹é‡è™•ç†çµæœ")
    
    # çµ±è¨ˆæ‘˜è¦
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("è™•ç†æ–‡æœ¬æ•¸", len(results))
    
    with col2:
        avg_sentiment = np.mean([r.sentiment_score for r in results])
        st.metric("å¹³å‡æƒ…æ„Ÿåˆ†æ•¸", f"{avg_sentiment:.3f}")
    
    with col3:
        avg_confidence = np.mean([r.classification_confidence for r in results])
        st.metric("å¹³å‡åˆ†é¡ç½®ä¿¡åº¦", f"{avg_confidence:.2%}")
    
    with col4:
        positive_count = sum(1 for r in results if r.sentiment_score > 0.1)
        st.metric("æ­£é¢æ–‡æœ¬æ•¸", positive_count)
    
    # åˆ†é¡åˆ†ä½ˆåœ–
    st.subheader("ğŸ“Š åˆ†é¡åˆ†ä½ˆ")
    
    category_counts = {}
    for result in results:
        category = result.category.value
        category_counts[category] = category_counts.get(category, 0) + 1
    
    if category_counts:
        fig = px.pie(
            values=list(category_counts.values()),
            names=list(category_counts.keys()),
            title="æ–°èåˆ†é¡åˆ†ä½ˆ"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # æƒ…æ„Ÿåˆ†ä½ˆåœ–
    st.subheader("ğŸ“ˆ æƒ…æ„Ÿåˆ†ä½ˆ")
    
    sentiment_scores = [r.sentiment_score for r in results]
    
    fig = px.histogram(
        x=sentiment_scores,
        nbins=20,
        title="æƒ…æ„Ÿåˆ†æ•¸åˆ†ä½ˆ",
        labels={'x': 'æƒ…æ„Ÿåˆ†æ•¸', 'y': 'é »æ¬¡'}
    )
    fig.add_vline(x=0, line_dash="dash", line_color="red", annotation_text="ä¸­æ€§ç·š")
    st.plotly_chart(fig, use_container_width=True)
    
    # è©³ç´°çµæœè¡¨æ ¼
    st.subheader("ğŸ“‹ è©³ç´°çµæœ")
    
    # æº–å‚™è¡¨æ ¼æ•¸æ“š
    table_data = []
    for i, result in enumerate(results):
        table_data.append({
            'åºè™Ÿ': i + 1,
            'æ–‡æœ¬': result.text[:50] + "..." if len(result.text) > 50 else result.text,
            'æƒ…æ„Ÿåˆ†æ•¸': f"{result.sentiment_score:.3f}",
            'åˆ†é¡': result.category.value,
            'ç½®ä¿¡åº¦': f"{result.classification_confidence:.2%}",
            'é—œéµè©': ", ".join(result.keywords[:3])
        })
    
    df = pd.DataFrame(table_data)
    st.dataframe(df, use_container_width=True)
    
    # å°å‡ºåŠŸèƒ½
    if st.button("ğŸ“¥ å°å‡ºçµæœ", key="export_results_btn"):
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ä¸‹è¼‰CSVæ–‡ä»¶",
            data=csv,
            file_name=f"text_analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )


def render_trend_analysis_tab(adapter: TextAnalysisAdapter):
    """æ¸²æŸ“è¶¨å‹¢åˆ†ææ¨™ç±¤é """
    st.header("ğŸ“ˆ æƒ…æ„Ÿè¶¨å‹¢åˆ†æ")
    
    st.info("æ­¤åŠŸèƒ½éœ€è¦æ™‚é–“åºåˆ—æ•¸æ“šï¼Œå¯ä»¥çµåˆæ–°èçˆ¬å–åŠŸèƒ½ä½¿ç”¨")
    
    # ç¤ºä¾‹è¶¨å‹¢æ•¸æ“š
    if st.button("ğŸ“Š ç”Ÿæˆç¤ºä¾‹è¶¨å‹¢", key="generate_trend_example_btn"):
        # ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š
        dates = pd.date_range(start='2024-01-01', end='2024-01-31', freq='D')
        sentiment_scores = np.random.normal(0, 0.3, len(dates))
        
        # æ·»åŠ ä¸€äº›è¶¨å‹¢
        trend = np.linspace(-0.2, 0.3, len(dates))
        sentiment_scores += trend
        
        # å‰µå»ºè¶¨å‹¢åœ–
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=dates,
            y=sentiment_scores,
            mode='lines+markers',
            name='æƒ…æ„Ÿåˆ†æ•¸',
            line=dict(color='blue', width=2)
        ))
        
        fig.add_hline(y=0, line_dash="dash", line_color="red", annotation_text="ä¸­æ€§ç·š")
        
        fig.update_layout(
            title="æƒ…æ„Ÿè¶¨å‹¢åˆ†æ",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="æƒ…æ„Ÿåˆ†æ•¸",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)


def render_news_analysis_tab(adapter: TextAnalysisAdapter):
    """æ¸²æŸ“æ–°èåˆ†ææ¨™ç±¤é """
    st.header("ğŸ“° æ–°èåˆ†æ")
    
    st.info("æ­¤åŠŸèƒ½æ•´åˆæ–°èçˆ¬å–å’Œåˆ†æåŠŸèƒ½")
    
    # æ–°èä¾†æºé¸æ“‡
    news_source = st.selectbox(
        "é¸æ“‡æ–°èä¾†æºï¼š",
        ["æ–°æµªè²¡ç¶“", "æ±æ–¹è²¡å¯Œ", "è­‰åˆ¸æ™‚å ±", "å…¨éƒ¨ä¾†æº"],
        key="news_source_selectbox"
    )
    
    # çˆ¬å–æ•¸é‡
    news_count = st.slider("çˆ¬å–æ–°èæ•¸é‡ï¼š", 10, 100, 50, key="news_count_slider")
    
    if st.button("ğŸ“¡ çˆ¬å–ä¸¦åˆ†ææ–°è", key="crawl_news_analysis_btn"):
        with st.spinner("æ­£åœ¨çˆ¬å–æ–°è..."):
            # é€™è£¡æ‡‰è©²èª¿ç”¨æ–°èçˆ¬èŸ²
            st.info("æ–°èçˆ¬å–åŠŸèƒ½é–‹ç™¼ä¸­...")


def render_system_status_tab(adapter: TextAnalysisAdapter):
    """æ¸²æŸ“ç³»çµ±ç‹€æ…‹æ¨™ç±¤é """
    st.header("ğŸ“‹ ç³»çµ±ç‹€æ…‹")
    
    # ç²å–æ€§èƒ½çµ±è¨ˆ
    stats = adapter.get_performance_stats()
    
    # åŸºæœ¬çµ±è¨ˆ
    st.subheader("ğŸ“Š åŸºæœ¬çµ±è¨ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç¸½åˆ†ææ¬¡æ•¸", stats.get('total_analyzed', 0))
    
    with col2:
        st.metric("å¿«å–å‘½ä¸­ç‡", f"{stats.get('cache_hit_rate', 0):.1%}")
    
    with col3:
        st.metric("å¹³å‡è™•ç†æ™‚é–“", f"{stats.get('avg_processing_time', 0):.3f}s")
    
    with col4:
        st.metric("å¿«å–å¤§å°", stats.get('cache_hits', 0) + stats.get('cache_misses', 0))
    
    # çµ„ä»¶ç‹€æ…‹
    st.subheader("ğŸ”§ çµ„ä»¶ç‹€æ…‹")
    
    components = [
        ("æƒ…æ„Ÿåˆ†æå™¨", stats.get('sentiment_analyzer_stats', {})),
        ("å¯¦æ™‚è©•åˆ†å™¨", stats.get('sentiment_scorer_stats', {})),
        ("æ–°èåˆ†é¡å™¨", stats.get('news_classifier_stats', {})),
        ("è‚¡ç¥¨åˆ†æå™¨", stats.get('stock_analyzer_stats', {})),
        ("æ–‡æœ¬è™•ç†å™¨", stats.get('text_processor_stats', {}))
    ]
    
    for name, component_stats in components:
        with st.expander(f"{name} ç‹€æ…‹"):
            if component_stats:
                st.json(component_stats)
            else:
                st.info("æš«ç„¡çµ±è¨ˆæ•¸æ“š")
    
    # ç³»çµ±ä¿¡æ¯
    st.subheader("â„¹ï¸ ç³»çµ±ä¿¡æ¯")
    
    adapter_info = adapter.get_adapter_info()
    st.json(adapter_info)


def show() -> None:
    """é¡¯ç¤ºæ–‡æœ¬åˆ†æé é¢ (Web UI å…¥å£é»).

    Returns:
        None
    """
    render_text_analysis_page()


if __name__ == "__main__":
    render_text_analysis_page()
