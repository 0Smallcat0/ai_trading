"""
æ•ˆèƒ½å„ªåŒ–æ¨¡çµ„

æä¾›é é¢è¼‰å…¥å„ªåŒ–ã€è³‡æºå£“ç¸®ã€å»¶é²è¼‰å…¥ç­‰æ•ˆèƒ½å„ªåŒ–åŠŸèƒ½ã€‚
æ”¯æ´ <2 ç§’é é¢åŠ è¼‰æ™‚é–“ç›®æ¨™å’Œæ™ºèƒ½ç‹€æ…‹ç®¡ç†ã€‚
"""

import time
import gzip
import io
import threading
import asyncio
from typing import Any, Dict, List, Optional, Callable, Union
from functools import wraps
import streamlit as st
import pandas as pd
import logging
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class PerformanceOptimizer:
    """æ•ˆèƒ½å„ªåŒ–å™¨é¡åˆ¥

    æä¾›å„ç¨®æ•ˆèƒ½å„ªåŒ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬è³‡æºå£“ç¸®ã€å»¶é²è¼‰å…¥ã€æ‰¹æ¬¡è™•ç†ç­‰ã€‚
    ç›®æ¨™ï¼šé é¢åŠ è¼‰æ™‚é–“ <2 ç§’ï¼Œå„ªåŒ–ç‹€æ…‹ç®¡ç†å’Œçµ„ä»¶æ‡¶åŠ è¼‰ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–æ•ˆèƒ½å„ªåŒ–å™¨"""
        self.performance_metrics = {
            "page_load_times": [],
            "query_times": [],
            "render_times": [],
            "memory_usage": [],
            "component_load_times": [],
            "state_update_times": [],
        }
        self._lock = threading.Lock()
        self.lazy_load_registry = {}
        self.component_cache = {}
        self.state_optimization_enabled = True
        self.target_load_time = 2.0  # 2 ç§’ç›®æ¨™

    def measure_time(self, operation_type: str = "general"):
        """æ¸¬é‡åŸ·è¡Œæ™‚é–“çš„è£é£¾å™¨

        Args:
            operation_type: æ“ä½œé¡å‹

        Returns:
            è£é£¾å™¨å‡½æ•¸
        """

        def decorator(func: Callable) -> Callable:
            @wraps(func)
            def wrapper(*args, **kwargs):
                start_time = time.time()
                result = func(*args, **kwargs)
                end_time = time.time()

                execution_time = end_time - start_time

                with self._lock:
                    if operation_type == "page_load":
                        self.performance_metrics["page_load_times"].append(
                            execution_time
                        )
                    elif operation_type == "query":
                        self.performance_metrics["query_times"].append(execution_time)
                    elif operation_type == "render":
                        self.performance_metrics["render_times"].append(execution_time)

                logger.debug(f"{func.__name__} åŸ·è¡Œæ™‚é–“: {execution_time:.3f}ç§’")
                return result

            return wrapper

        return decorator

    def compress_data(self, data: str) -> bytes:
        """å£“ç¸®è³‡æ–™

        Args:
            data: è¦å£“ç¸®çš„è³‡æ–™

        Returns:
            å£“ç¸®å¾Œçš„è³‡æ–™
        """
        return gzip.compress(data.encode("utf-8"))

    def decompress_data(self, compressed_data: bytes) -> str:
        """è§£å£“ç¸®è³‡æ–™

        Args:
            compressed_data: å£“ç¸®çš„è³‡æ–™

        Returns:
            è§£å£“ç¸®å¾Œçš„è³‡æ–™
        """
        return gzip.decompress(compressed_data).decode("utf-8")

    def optimize_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """å„ªåŒ– DataFrame è¨˜æ†¶é«”ä½¿ç”¨

        Args:
            df: è¦å„ªåŒ–çš„ DataFrame

        Returns:
            å„ªåŒ–å¾Œçš„ DataFrame
        """
        optimized_df = df.copy()

        # å„ªåŒ–æ•¸å€¼å‹æ¬„ä½
        for col in optimized_df.select_dtypes(include=["int64"]).columns:
            col_min = optimized_df[col].min()
            col_max = optimized_df[col].max()

            if col_min >= -128 and col_max <= 127:
                optimized_df[col] = optimized_df[col].astype("int8")
            elif col_min >= -32768 and col_max <= 32767:
                optimized_df[col] = optimized_df[col].astype("int16")
            elif col_min >= -2147483648 and col_max <= 2147483647:
                optimized_df[col] = optimized_df[col].astype("int32")

        # å„ªåŒ–æµ®é»æ•¸æ¬„ä½
        for col in optimized_df.select_dtypes(include=["float64"]).columns:
            optimized_df[col] = pd.to_numeric(optimized_df[col], downcast="float")

        # å„ªåŒ–å­—ä¸²æ¬„ä½
        for col in optimized_df.select_dtypes(include=["object"]).columns:
            if optimized_df[col].nunique() / len(optimized_df) < 0.5:
                optimized_df[col] = optimized_df[col].astype("category")

        return optimized_df

    def lazy_load_component(self, component_func: Callable, *args, **kwargs):
        """æ™ºèƒ½å»¶é²è¼‰å…¥çµ„ä»¶

        æ”¯æ´çµ„ä»¶å¿«å–å’Œæ¢ä»¶è¼‰å…¥ï¼Œæå‡æ€§èƒ½ã€‚

        Args:
            component_func: çµ„ä»¶å‡½æ•¸
            *args: ä½ç½®åƒæ•¸
            **kwargs: é—œéµå­—åƒæ•¸
        """
        start_time = time.time()

        if "lazy_load_registry" not in st.session_state:
            st.session_state.lazy_load_registry = {}

        component_key = f"{component_func.__name__}_{hash(str(args) + str(kwargs))}"

        # æª¢æŸ¥æ˜¯å¦å·²å¿«å–
        if component_key in self.component_cache:
            cached_result = self.component_cache[component_key]
            if cached_result.get("expires_at", 0) > time.time():
                return cached_result["data"]

        # æª¢æŸ¥æ˜¯å¦éœ€è¦è¼‰å…¥
        if component_key not in st.session_state.lazy_load_registry:
            with st.spinner("è¼‰å…¥ä¸­..."):
                result = component_func(*args, **kwargs)
                st.session_state.lazy_load_registry[component_key] = True

                # å¿«å–çµæœï¼ˆ5åˆ†é˜ï¼‰
                self.component_cache[component_key] = {
                    "data": result,
                    "expires_at": time.time() + 300
                }

                load_time = time.time() - start_time
                with self._lock:
                    self.performance_metrics["component_load_times"].append(load_time)

                return result
        else:
            return component_func(*args, **kwargs)

    def batch_process(
        self, items: List[Any], batch_size: int = 100, process_func: Callable = None
    ) -> List[Any]:
        """æ‰¹æ¬¡è™•ç†è³‡æ–™

        Args:
            items: è¦è™•ç†çš„é …ç›®åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°
            process_func: è™•ç†å‡½æ•¸

        Returns:
            è™•ç†çµæœåˆ—è¡¨
        """
        results = []
        total_batches = len(items) // batch_size + (1 if len(items) % batch_size else 0)

        progress_bar = st.progress(0)
        status_text = st.empty()

        for i in range(0, len(items), batch_size):
            batch = items[i : i + batch_size]
            batch_num = i // batch_size + 1

            status_text.text(f"è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches}")

            if process_func:
                batch_results = process_func(batch)
                results.extend(batch_results)
            else:
                results.extend(batch)

            progress = min(batch_num / total_batches, 1.0)
            progress_bar.progress(progress)

        progress_bar.empty()
        status_text.empty()

        return results

    def optimize_session_state(self) -> None:
        """å„ªåŒ– session state ç®¡ç†

        æ¸…ç†éæœŸçš„ç‹€æ…‹å’Œä¸å¿…è¦çš„æ•¸æ“šï¼Œæ¸›å°‘é‡æ–°æ¸²æŸ“ã€‚
        """
        if not self.state_optimization_enabled:
            return

        start_time = time.time()

        # æ¸…ç†éæœŸçš„æ‡¶åŠ è¼‰è¨»å†Š
        if hasattr(st.session_state, 'lazy_load_registry'):
            # ä¿ç•™æœ€è¿‘ä½¿ç”¨çš„çµ„ä»¶
            current_time = time.time()
            expired_keys = []

            for key in list(self.component_cache.keys()):
                if self.component_cache[key].get("expires_at", 0) < current_time:
                    expired_keys.append(key)

            for key in expired_keys:
                del self.component_cache[key]
                if key in st.session_state.lazy_load_registry:
                    del st.session_state.lazy_load_registry[key]

        # æ¸…ç†å¤§å‹è‡¨æ™‚æ•¸æ“š
        temp_keys = [key for key in st.session_state.keys() if key.startswith('temp_')]
        for key in temp_keys:
            if hasattr(st.session_state[key], '__len__'):
                # å¦‚æœæ˜¯å¤§å‹å°è±¡ï¼ˆ>1MBï¼‰ï¼Œæ¸…ç†å®ƒ
                try:
                    import sys
                    if sys.getsizeof(st.session_state[key]) > 1024 * 1024:
                        del st.session_state[key]
                except:
                    pass

        optimization_time = time.time() - start_time
        with self._lock:
            self.performance_metrics["state_update_times"].append(optimization_time)

        logger.debug(f"Session state å„ªåŒ–å®Œæˆï¼Œè€—æ™‚ {optimization_time:.3f}ç§’")

    def preload_critical_components(self, component_list: List[str]) -> None:
        """é è¼‰å…¥é—œéµçµ„ä»¶

        Args:
            component_list: è¦é è¼‰å…¥çš„çµ„ä»¶åç¨±åˆ—è¡¨
        """
        for component_name in component_list:
            if component_name not in self.lazy_load_registry:
                self.lazy_load_registry[component_name] = {
                    "preloaded": True,
                    "timestamp": time.time()
                }

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ç²å–æ•ˆèƒ½æŒ‡æ¨™

        Returns:
            æ•ˆèƒ½æŒ‡æ¨™å­—å…¸ï¼ŒåŒ…å«æ€§èƒ½åˆ†æå’Œå»ºè­°
        """
        with self._lock:
            metrics = {}

            for metric_type, times in self.performance_metrics.items():
                if times:
                    avg_time = sum(times) / len(times)
                    metrics[metric_type] = {
                        "count": len(times),
                        "avg": avg_time,
                        "min": min(times),
                        "max": max(times),
                        "total": sum(times),
                        "meets_target": avg_time < self.target_load_time if metric_type == "page_load_times" else True
                    }
                else:
                    metrics[metric_type] = {
                        "count": 0,
                        "avg": 0,
                        "min": 0,
                        "max": 0,
                        "total": 0,
                        "meets_target": True
                    }

            # æ·»åŠ æ€§èƒ½åˆ†æ
            metrics["performance_analysis"] = self._analyze_performance()
            metrics["cache_efficiency"] = {
                "component_cache_size": len(self.component_cache),
                "lazy_load_registry_size": len(self.lazy_load_registry)
            }

            return metrics

    def _analyze_performance(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½ä¸¦æä¾›å»ºè­°

        Returns:
            æ€§èƒ½åˆ†æçµæœå’Œå»ºè­°
        """
        analysis = {
            "overall_status": "good",
            "recommendations": [],
            "warnings": []
        }

        # æª¢æŸ¥é é¢åŠ è¼‰æ™‚é–“
        if self.performance_metrics["page_load_times"]:
            avg_load_time = sum(self.performance_metrics["page_load_times"]) / len(self.performance_metrics["page_load_times"])
            if avg_load_time > self.target_load_time:
                analysis["overall_status"] = "needs_improvement"
                analysis["warnings"].append(f"å¹³å‡é é¢åŠ è¼‰æ™‚é–“ {avg_load_time:.2f}s è¶…éç›®æ¨™ {self.target_load_time}s")
                analysis["recommendations"].append("è€ƒæ…®å•Ÿç”¨æ›´å¤šçµ„ä»¶æ‡¶åŠ è¼‰")
                analysis["recommendations"].append("å„ªåŒ–å¤§å‹æ•¸æ“šé›†çš„è™•ç†")

        # æª¢æŸ¥çµ„ä»¶åŠ è¼‰æ™‚é–“
        if self.performance_metrics["component_load_times"]:
            avg_component_time = sum(self.performance_metrics["component_load_times"]) / len(self.performance_metrics["component_load_times"])
            if avg_component_time > 1.0:
                analysis["warnings"].append(f"çµ„ä»¶å¹³å‡åŠ è¼‰æ™‚é–“ {avg_component_time:.2f}s è¼ƒé•·")
                analysis["recommendations"].append("è€ƒæ…®çµ„ä»¶é è¼‰å…¥æˆ–å¿«å–å„ªåŒ–")

        # æª¢æŸ¥å¿«å–æ•ˆç‡
        if len(self.component_cache) > 100:
            analysis["warnings"].append("çµ„ä»¶å¿«å–é …ç›®éå¤šï¼Œå¯èƒ½å½±éŸ¿è¨˜æ†¶é«”ä½¿ç”¨")
            analysis["recommendations"].append("å®šæœŸæ¸…ç†éæœŸå¿«å–")

        return analysis

    def clear_metrics(self):
        """æ¸…ç©ºæ•ˆèƒ½æŒ‡æ¨™"""
        with self._lock:
            for metric_type in self.performance_metrics:
                self.performance_metrics[metric_type].clear()


# å…¨åŸŸæ•ˆèƒ½å„ªåŒ–å™¨å¯¦ä¾‹
performance_optimizer = PerformanceOptimizer()


def optimize_page_load(func: Callable) -> Callable:
    """é é¢è¼‰å…¥å„ªåŒ–è£é£¾å™¨

    Args:
        func: è¦å„ªåŒ–çš„å‡½æ•¸

    Returns:
        å„ªåŒ–å¾Œçš„å‡½æ•¸
    """

    @wraps(func)
    @performance_optimizer.measure_time("page_load")
    def wrapper(*args, **kwargs):
        # è¨­å®šé é¢é…ç½®ä»¥æå‡æ•ˆèƒ½
        if not hasattr(st, "_page_config_set"):
            st.set_page_config(layout="wide", initial_sidebar_state="expanded")
            st._page_config_set = True

        return func(*args, **kwargs)

    return wrapper


def optimize_query(func: Callable) -> Callable:
    """æŸ¥è©¢å„ªåŒ–è£é£¾å™¨

    Args:
        func: è¦å„ªåŒ–çš„æŸ¥è©¢å‡½æ•¸

    Returns:
        å„ªåŒ–å¾Œçš„å‡½æ•¸
    """

    @wraps(func)
    @performance_optimizer.measure_time("query")
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)

    return wrapper


def optimize_render(func: Callable) -> Callable:
    """æ¸²æŸ“å„ªåŒ–è£é£¾å™¨

    Args:
        func: è¦å„ªåŒ–çš„æ¸²æŸ“å‡½æ•¸

    Returns:
        å„ªåŒ–å¾Œçš„å‡½æ•¸
    """

    @wraps(func)
    @performance_optimizer.measure_time("render")
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)

    return wrapper


def create_performance_dashboard():
    """å‰µå»ºå¢å¼·çš„æ•ˆèƒ½ç›£æ§å„€è¡¨æ¿"""
    st.subheader("ğŸš€ æ•ˆèƒ½ç›£æ§å„€è¡¨æ¿")

    metrics = performance_optimizer.get_performance_metrics()
    analysis = metrics.get("performance_analysis", {})

    # ç¸½é«”ç‹€æ…‹æŒ‡ç¤ºå™¨
    status = analysis.get("overall_status", "unknown")
    status_colors = {
        "good": "ğŸŸ¢",
        "needs_improvement": "ğŸŸ¡",
        "poor": "ğŸ”´"
    }
    st.info(f"{status_colors.get(status, 'âšª')} ç¸½é«”æ€§èƒ½ç‹€æ…‹: {status}")

    # ä¸»è¦æŒ‡æ¨™
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        load_time = metrics['page_load_times']['avg']
        target_met = "âœ…" if metrics['page_load_times']['meets_target'] else "âŒ"
        st.metric(
            "å¹³å‡é é¢è¼‰å…¥æ™‚é–“",
            f"{load_time:.3f}s {target_met}",
            f"ç›®æ¨™: <{performance_optimizer.target_load_time}s",
        )

    with col2:
        st.metric(
            "å¹³å‡æŸ¥è©¢æ™‚é–“",
            f"{metrics['query_times']['avg']:.3f}s",
            f"å…± {metrics['query_times']['count']} æ¬¡",
        )

    with col3:
        st.metric(
            "çµ„ä»¶è¼‰å…¥æ™‚é–“",
            f"{metrics['component_load_times']['avg']:.3f}s",
            f"å…± {metrics['component_load_times']['count']} æ¬¡",
        )

    with col4:
        cache_info = metrics.get("cache_efficiency", {})
        st.metric(
            "å¿«å–æ•ˆç‡",
            f"{cache_info.get('component_cache_size', 0)} é …ç›®",
            f"è¨»å†Š: {cache_info.get('lazy_load_registry_size', 0)}",
        )

    # æ€§èƒ½å»ºè­°
    if analysis.get("warnings") or analysis.get("recommendations"):
        st.subheader("ğŸ“Š æ€§èƒ½åˆ†æèˆ‡å»ºè­°")

        if analysis.get("warnings"):
            st.warning("âš ï¸ æ€§èƒ½è­¦å‘Š:")
            for warning in analysis["warnings"]:
                st.write(f"â€¢ {warning}")

        if analysis.get("recommendations"):
            st.info("ğŸ’¡ å„ªåŒ–å»ºè­°:")
            for rec in analysis["recommendations"]:
                st.write(f"â€¢ {rec}")

    # æ§åˆ¶é¢æ¿
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ğŸ§¹ æ¸…ç©ºæŒ‡æ¨™"):
            performance_optimizer.clear_metrics()
            st.rerun()

    with col2:
        if st.button("ğŸ”§ å„ªåŒ– Session State"):
            performance_optimizer.optimize_session_state()
            st.success("Session State å·²å„ªåŒ–")

    with col3:
        if st.button("ğŸ“ˆ å•Ÿç”¨æ€§èƒ½å„ªåŒ–"):
            enable_performance_optimizations()
            st.success("æ€§èƒ½å„ªåŒ–å·²å•Ÿç”¨")

    # è©³ç´°æŒ‡æ¨™ï¼ˆå¯æ‘ºç–Šï¼‰
    with st.expander("ğŸ“‹ è©³ç´°æ•ˆèƒ½æŒ‡æ¨™"):
        st.json(metrics)


def enable_performance_optimizations():
    """å•Ÿç”¨æ•ˆèƒ½å„ªåŒ–è¨­å®š"""
    # è¨­å®š Streamlit æ•ˆèƒ½å„ªåŒ–é¸é …
    if "performance_optimized" not in st.session_state:
        st.session_state.performance_optimized = True

        # å•Ÿç”¨å¿«å–
        st.cache_data.clear()
        st.cache_resource.clear()

        # åˆå§‹åŒ–æ€§èƒ½å„ªåŒ–ç‹€æ…‹
        st.session_state.lazy_load_enabled = True
        st.session_state.component_cache_enabled = True
        st.session_state.auto_optimization = True

        logger.info("æ•ˆèƒ½å„ªåŒ–å·²å•Ÿç”¨")


class SmartStateManager:
    """æ™ºèƒ½ç‹€æ…‹ç®¡ç†å™¨

    æä¾›æ™ºèƒ½çš„ session state ç®¡ç†ï¼Œæ¸›å°‘ä¸å¿…è¦çš„é‡æ–°æ¸²æŸ“ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–æ™ºèƒ½ç‹€æ…‹ç®¡ç†å™¨"""
        self.state_history = {}
        self.change_tracking = {}
        self.optimization_rules = {}

    def smart_update(self, key: str, value: Any, force_update: bool = False) -> bool:
        """æ™ºèƒ½æ›´æ–°ç‹€æ…‹

        åªåœ¨å€¼çœŸæ­£æ”¹è®Šæ™‚æ‰æ›´æ–°ï¼Œé¿å…ä¸å¿…è¦çš„é‡æ–°æ¸²æŸ“ã€‚

        Args:
            key: ç‹€æ…‹éµ
            value: æ–°å€¼
            force_update: æ˜¯å¦å¼·åˆ¶æ›´æ–°

        Returns:
            bool: æ˜¯å¦å¯¦éš›æ›´æ–°äº†ç‹€æ…‹
        """
        current_value = st.session_state.get(key)

        # æª¢æŸ¥å€¼æ˜¯å¦çœŸçš„æ”¹è®Šäº†
        if not force_update and current_value == value:
            return False

        # è¨˜éŒ„è®Šæ›´æ­·å²
        if key not in self.state_history:
            self.state_history[key] = []

        self.state_history[key].append({
            "old_value": current_value,
            "new_value": value,
            "timestamp": datetime.now(),
        })

        # é™åˆ¶æ­·å²è¨˜éŒ„æ•¸é‡
        if len(self.state_history[key]) > 10:
            self.state_history[key] = self.state_history[key][-10:]

        # æ›´æ–°ç‹€æ…‹
        st.session_state[key] = value

        # è¨˜éŒ„è®Šæ›´çµ±è¨ˆ
        if key not in self.change_tracking:
            self.change_tracking[key] = 0
        self.change_tracking[key] += 1

        return True

    def batch_update(self, updates: Dict[str, Any]) -> List[str]:
        """æ‰¹é‡æ›´æ–°ç‹€æ…‹

        Args:
            updates: è¦æ›´æ–°çš„ç‹€æ…‹å­—å…¸

        Returns:
            List[str]: å¯¦éš›æ›´æ–°çš„éµåˆ—è¡¨
        """
        updated_keys = []

        for key, value in updates.items():
            if self.smart_update(key, value):
                updated_keys.append(key)

        return updated_keys

    def get_change_summary(self) -> Dict[str, Any]:
        """ç²å–ç‹€æ…‹è®Šæ›´æ‘˜è¦

        Returns:
            Dict[str, Any]: è®Šæ›´æ‘˜è¦
        """
        return {
            "total_keys": len(self.change_tracking),
            "total_changes": sum(self.change_tracking.values()),
            "most_changed_keys": sorted(
                self.change_tracking.items(),
                key=lambda x: x[1],
                reverse=True
            )[:5],
            "recent_changes": {
                key: history[-3:] for key, history in self.state_history.items()
                if history
            }
        }


# å…¨åŸŸæ™ºèƒ½ç‹€æ…‹ç®¡ç†å™¨
smart_state_manager = SmartStateManager()
