"""
ç‰¹å¾µå·¥ç¨‹å°ˆç”¨ UI çµ„ä»¶

æ­¤æ¨¡çµ„æä¾›ç‰¹å¾µå·¥ç¨‹é é¢å°ˆç”¨çš„ UI çµ„ä»¶ï¼ŒåŒ…æ‹¬ï¼š
- ç‰¹å¾µå±•ç¤ºå¡ç‰‡
- ç‰¹å¾µè¨ˆç®—é€²åº¦é¡¯ç¤º
- ç‰¹å¾µçµ±è¨ˆåœ–è¡¨
- ç‰¹å¾µè™•ç†æ“ä½œä»‹é¢
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, date
from typing import Dict, List, Optional, Any


def show_feature_card(feature_info: Dict, key_prefix: str = ""):
    """é¡¯ç¤ºç‰¹å¾µè³‡è¨Šå¡ç‰‡"""
    with st.container():
        # å¡ç‰‡æ¨™é¡Œ
        st.markdown(f"### {feature_info['name']} - {feature_info['full_name']}")

        # åŸºæœ¬è³‡è¨Š
        col1, col2 = st.columns(2)

        with col1:
            st.markdown(f"**é¡åˆ¥**: {feature_info.get('category', 'N/A')}")
            st.markdown(f"**æè¿°**: {feature_info.get('description', 'N/A')}")

            if "parameters" in feature_info:
                st.markdown(f"**åƒæ•¸**: {feature_info['parameters']}")

            if "value_range" in feature_info:
                st.markdown(f"**å€¼ç¯„åœ**: {feature_info['value_range']}")

        with col2:
            if "interpretation" in feature_info:
                st.markdown(f"**è§£é‡‹**: {feature_info['interpretation']}")

            if "calculation_cost" in feature_info:
                cost_color = {"ä½": "ğŸŸ¢", "ä¸­": "ğŸŸ¡", "é«˜": "ğŸ”´"}.get(
                    feature_info["calculation_cost"], "âšª"
                )
                st.markdown(
                    f"**è¨ˆç®—æˆæœ¬**: {cost_color} {feature_info['calculation_cost']}"
                )

            if "data_requirements" in feature_info:
                st.markdown(
                    f"**è³‡æ–™éœ€æ±‚**: {', '.join(feature_info['data_requirements'])}"
                )

        # ç¨‹å¼ç¢¼ç¯„ä¾‹
        if "example_code" in feature_info:
            with st.expander("ç¨‹å¼ç¢¼ç¯„ä¾‹"):
                st.code(feature_info["example_code"], language="python")


def show_calculation_progress(task_status: Dict, key_prefix: str = ""):
    """é¡¯ç¤ºç‰¹å¾µè¨ˆç®—é€²åº¦"""
    if not task_status or task_status.get("status") == "not_found":
        st.warning("æ‰¾ä¸åˆ°ä»»å‹™ç‹€æ…‹")
        return

    status = task_status.get("status", "unknown")
    progress = task_status.get("progress", 0)
    message = task_status.get("message", "")

    # ç‹€æ…‹é¡¯ç¤º
    status_colors = {
        "running": "ğŸ”„",
        "completed": "âœ…",
        "failed": "âŒ",
        "pending": "â³",
    }

    status_text = {
        "running": "åŸ·è¡Œä¸­",
        "completed": "å·²å®Œæˆ",
        "failed": "å¤±æ•—",
        "pending": "ç­‰å¾…ä¸­",
    }

    st.markdown(
        f"**ç‹€æ…‹**: {status_colors.get(status, 'â“')} {status_text.get(status, status)}"
    )

    # é€²åº¦æ¢
    if status == "running":
        st.progress(progress / 100)
        st.markdown(f"**é€²åº¦**: {progress}%")

    # è¨Šæ¯
    if message:
        st.markdown(f"**è¨Šæ¯**: {message}")

    # æ™‚é–“è³‡è¨Š
    if "start_time" in task_status:
        st.markdown(f"**é–‹å§‹æ™‚é–“**: {task_status['start_time']}")

    if "end_time" in task_status:
        st.markdown(f"**çµæŸæ™‚é–“**: {task_status['end_time']}")

    # çµæœçµ±è¨ˆ
    if status == "completed" and "processed_records" in task_status:
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("è™•ç†è¨˜éŒ„", task_status.get("processed_records", 0))

        with col2:
            st.metric("éŒ¯èª¤è¨˜éŒ„", task_status.get("error_records", 0))

        with col3:
            success_rate = 0
            if task_status.get("processed_records", 0) > 0:
                total = task_status.get("processed_records", 0) + task_status.get(
                    "error_records", 0
                )
                success_rate = (task_status.get("processed_records", 0) / total) * 100
            st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")


def show_feature_statistics_chart(stats: Dict, feature_name: str):
    """é¡¯ç¤ºç‰¹å¾µçµ±è¨ˆåœ–è¡¨"""
    if not stats or stats.get("count", 0) == 0:
        st.warning("æ²’æœ‰çµ±è¨ˆè³‡æ–™å¯é¡¯ç¤º")
        return

    # çµ±è¨ˆæ‘˜è¦
    st.subheader(f"{feature_name} çµ±è¨ˆæ‘˜è¦")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("è³‡æ–™ç­†æ•¸", f"{stats['count']:,}")

    with col2:
        st.metric("å¹³å‡å€¼", f"{stats['mean']:.4f}")

    with col3:
        st.metric("æ¨™æº–å·®", f"{stats['std']:.4f}")

    with col4:
        st.metric("ä¸­ä½æ•¸", f"{stats['median']:.4f}")

    # ç¯„åœè³‡è¨Š
    col1, col2 = st.columns(2)

    with col1:
        st.metric("æœ€å°å€¼", f"{stats['min']:.4f}")

    with col2:
        st.metric("æœ€å¤§å€¼", f"{stats['max']:.4f}")


def show_feature_distribution_chart(data: pd.DataFrame, feature_column: str):
    """é¡¯ç¤ºç‰¹å¾µåˆ†å¸ƒåœ–è¡¨"""
    if data.empty or feature_column not in data.columns:
        st.warning("æ²’æœ‰è³‡æ–™å¯é¡¯ç¤º")
        return

    # å‰µå»ºå­åœ–
    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("ç›´æ–¹åœ–", "ç®±å‹åœ–", "æ™‚é–“åºåˆ—", "Q-Q åœ–"),
        specs=[
            [{"secondary_y": False}, {"secondary_y": False}],
            [{"secondary_y": False}, {"secondary_y": False}],
        ],
    )

    values = data[feature_column].dropna()

    # ç›´æ–¹åœ–
    fig.add_trace(go.Histogram(x=values, name="åˆ†å¸ƒ", nbinsx=30), row=1, col=1)

    # ç®±å‹åœ–
    fig.add_trace(go.Box(y=values, name="ç®±å‹åœ–"), row=1, col=2)

    # æ™‚é–“åºåˆ—ï¼ˆå¦‚æœæœ‰æ—¥æœŸæ¬„ä½ï¼‰
    if "data_date" in data.columns:
        time_data = data.sort_values("data_date")
        fig.add_trace(
            go.Scatter(
                x=time_data["data_date"],
                y=time_data[feature_column],
                mode="lines+markers",
                name="æ™‚é–“åºåˆ—",
            ),
            row=2,
            col=1,
        )
    else:
        # å¦‚æœæ²’æœ‰æ—¥æœŸï¼Œé¡¯ç¤ºç´¢å¼•åœ–
        fig.add_trace(
            go.Scatter(
                x=list(range(len(values))),
                y=values,
                mode="lines+markers",
                name="åºåˆ—åœ–",
            ),
            row=2,
            col=1,
        )

    # Q-Q åœ–ï¼ˆèˆ‡æ­£æ…‹åˆ†å¸ƒæ¯”è¼ƒï¼‰
    from scipy import stats

    theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, len(values)))
    sample_quantiles = np.sort(values)

    fig.add_trace(
        go.Scatter(
            x=theoretical_quantiles, y=sample_quantiles, mode="markers", name="Q-Q åœ–"
        ),
        row=2,
        col=2,
    )

    # æ·»åŠ  Q-Q åœ–çš„åƒè€ƒç·š
    min_val = min(theoretical_quantiles.min(), sample_quantiles.min())
    max_val = max(theoretical_quantiles.max(), sample_quantiles.max())
    fig.add_trace(
        go.Scatter(
            x=[min_val, max_val],
            y=[min_val, max_val],
            mode="lines",
            name="åƒè€ƒç·š",
            line=dict(dash="dash", color="red"),
        ),
        row=2,
        col=2,
    )

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=800, title_text=f"{feature_column} åˆ†å¸ƒåˆ†æ", showlegend=False
    )

    st.plotly_chart(fig, use_container_width=True)


def show_outlier_detection_chart(
    data: pd.DataFrame, feature_column: str, outlier_indices: List[int]
):
    """é¡¯ç¤ºç•°å¸¸å€¼æª¢æ¸¬åœ–è¡¨"""
    if data.empty or feature_column not in data.columns:
        st.warning("æ²’æœ‰è³‡æ–™å¯é¡¯ç¤º")
        return

    # å‰µå»ºæ•£é»åœ–
    fig = go.Figure()

    # æ­£å¸¸å€¼
    normal_mask = ~data.index.isin(outlier_indices)
    normal_data = data[normal_mask]

    if not normal_data.empty:
        fig.add_trace(
            go.Scatter(
                x=normal_data.index,
                y=normal_data[feature_column],
                mode="markers",
                name="æ­£å¸¸å€¼",
                marker=dict(color="blue", size=6),
            )
        )

    # ç•°å¸¸å€¼
    outlier_data = data[data.index.isin(outlier_indices)]

    if not outlier_data.empty:
        fig.add_trace(
            go.Scatter(
                x=outlier_data.index,
                y=outlier_data[feature_column],
                mode="markers",
                name="ç•°å¸¸å€¼",
                marker=dict(color="red", size=8, symbol="x"),
            )
        )

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title=f"{feature_column} ç•°å¸¸å€¼æª¢æ¸¬",
        xaxis_title="ç´¢å¼•",
        yaxis_title=feature_column,
        hovermode="closest",
    )

    st.plotly_chart(fig, use_container_width=True)

    # é¡¯ç¤ºç•°å¸¸å€¼çµ±è¨ˆ
    if outlier_indices:
        st.markdown(f"**æª¢æ¸¬åˆ° {len(outlier_indices)} å€‹ç•°å¸¸å€¼**")

        col1, col2 = st.columns(2)

        with col1:
            st.metric("ç•°å¸¸å€¼æ•¸é‡", len(outlier_indices))

        with col2:
            outlier_rate = (len(outlier_indices) / len(data)) * 100
            st.metric("ç•°å¸¸å€¼æ¯”ä¾‹", f"{outlier_rate:.2f}%")


def show_correlation_heatmap(data: pd.DataFrame, feature_columns: List[str] = None):
    """é¡¯ç¤ºç‰¹å¾µç›¸é—œæ€§ç†±åŠ›åœ–"""
    if data.empty:
        st.warning("æ²’æœ‰è³‡æ–™å¯é¡¯ç¤º")
        return

    # é¸æ“‡æ•¸å€¼æ¬„ä½
    if feature_columns is None:
        numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
        feature_columns = [
            col for col in numeric_columns if col not in ["id", "stock_id"]
        ]

    if len(feature_columns) < 2:
        st.warning("éœ€è¦è‡³å°‘å…©å€‹æ•¸å€¼ç‰¹å¾µæ‰èƒ½è¨ˆç®—ç›¸é—œæ€§")
        return

    # è¨ˆç®—ç›¸é—œæ€§çŸ©é™£
    correlation_matrix = data[feature_columns].corr()

    # å‰µå»ºç†±åŠ›åœ–
    fig = px.imshow(
        correlation_matrix,
        text_auto=True,
        aspect="auto",
        title="ç‰¹å¾µç›¸é—œæ€§ç†±åŠ›åœ–",
        color_continuous_scale="RdBu_r",
        zmin=-1,
        zmax=1,
    )

    fig.update_layout(width=800, height=600)

    st.plotly_chart(fig, use_container_width=True)

    # é¡¯ç¤ºé«˜ç›¸é—œæ€§ç‰¹å¾µå°
    high_corr_pairs = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i + 1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if abs(corr_value) > 0.7:  # é«˜ç›¸é—œæ€§é–¾å€¼
                high_corr_pairs.append(
                    {
                        "ç‰¹å¾µ1": correlation_matrix.columns[i],
                        "ç‰¹å¾µ2": correlation_matrix.columns[j],
                        "ç›¸é—œä¿‚æ•¸": corr_value,
                    }
                )

    if high_corr_pairs:
        st.subheader("é«˜ç›¸é—œæ€§ç‰¹å¾µå° (|r| > 0.7)")
        df_high_corr = pd.DataFrame(high_corr_pairs)
        st.dataframe(df_high_corr, use_container_width=True)


def show_feature_importance_chart(
    feature_names: List[str], importance_scores: List[float]
):
    """é¡¯ç¤ºç‰¹å¾µé‡è¦æ€§åœ–è¡¨"""
    if not feature_names or not importance_scores:
        st.warning("æ²’æœ‰ç‰¹å¾µé‡è¦æ€§è³‡æ–™å¯é¡¯ç¤º")
        return

    # å‰µå»º DataFrame
    df_importance = pd.DataFrame(
        {"ç‰¹å¾µ": feature_names, "é‡è¦æ€§": importance_scores}
    ).sort_values("é‡è¦æ€§", ascending=True)

    # å‰µå»ºæ°´å¹³æ¢å½¢åœ–
    fig = px.bar(
        df_importance,
        x="é‡è¦æ€§",
        y="ç‰¹å¾µ",
        orientation="h",
        title="ç‰¹å¾µé‡è¦æ€§æ’åº",
        labels={"é‡è¦æ€§": "é‡è¦æ€§åˆ†æ•¸", "ç‰¹å¾µ": "ç‰¹å¾µåç¨±"},
    )

    fig.update_layout(
        height=max(400, len(feature_names) * 25),
        yaxis={"categoryorder": "total ascending"},
    )

    st.plotly_chart(fig, use_container_width=True)


def show_pca_explained_variance_chart(explained_variance_ratio: List[float]):
    """é¡¯ç¤º PCA è§£é‡‹è®Šç•°æ•¸åœ–è¡¨"""
    if not explained_variance_ratio:
        st.warning("æ²’æœ‰ PCA è³‡æ–™å¯é¡¯ç¤º")
        return

    # è¨ˆç®—ç´¯ç©è§£é‡‹è®Šç•°æ•¸
    cumulative_variance = np.cumsum(explained_variance_ratio)

    # å‰µå»ºå­åœ–
    fig = make_subplots(
        rows=1,
        cols=2,
        subplot_titles=("å„ä¸»æˆåˆ†è§£é‡‹è®Šç•°æ•¸", "ç´¯ç©è§£é‡‹è®Šç•°æ•¸"),
        specs=[[{"secondary_y": False}, {"secondary_y": False}]],
    )

    # å„ä¸»æˆåˆ†è§£é‡‹è®Šç•°æ•¸
    fig.add_trace(
        go.Bar(
            x=[f"PC{i+1}" for i in range(len(explained_variance_ratio))],
            y=explained_variance_ratio,
            name="è§£é‡‹è®Šç•°æ•¸",
        ),
        row=1,
        col=1,
    )

    # ç´¯ç©è§£é‡‹è®Šç•°æ•¸
    fig.add_trace(
        go.Scatter(
            x=[f"PC{i+1}" for i in range(len(cumulative_variance))],
            y=cumulative_variance,
            mode="lines+markers",
            name="ç´¯ç©è§£é‡‹è®Šç•°æ•¸",
        ),
        row=1,
        col=2,
    )

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(height=400, title_text="PCA è§£é‡‹è®Šç•°æ•¸åˆ†æ", showlegend=False)

    fig.update_yaxes(title_text="è§£é‡‹è®Šç•°æ•¸æ¯”ä¾‹", row=1, col=1)
    fig.update_yaxes(title_text="ç´¯ç©è§£é‡‹è®Šç•°æ•¸æ¯”ä¾‹", row=1, col=2)
    fig.update_xaxes(title_text="ä¸»æˆåˆ†", row=1, col=1)
    fig.update_xaxes(title_text="ä¸»æˆåˆ†", row=1, col=2)

    st.plotly_chart(fig, use_container_width=True)

    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    col1, col2 = st.columns(2)

    with col1:
        st.metric("ç¸½è§£é‡‹è®Šç•°æ•¸", f"{cumulative_variance[-1]:.2%}")

    with col2:
        # æ‰¾åˆ°è§£é‡‹ 95% è®Šç•°æ•¸æ‰€éœ€çš„ä¸»æˆåˆ†æ•¸
        n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1
        st.metric("95% è®Šç•°æ•¸æ‰€éœ€ä¸»æˆåˆ†", n_components_95)
