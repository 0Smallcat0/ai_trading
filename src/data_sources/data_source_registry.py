#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•¸æ“šæºè¨»å†Šè¡¨
==========

çµ±ä¸€ç®¡ç†æ‰€æœ‰å°è‚¡å…è²»æ•¸æ“šæºçš„è¨»å†Šè¡¨ï¼ŒåŒ…æ‹¬å·²é©—è­‰å¯ç”¨å’Œå¾…å¯¦ç¾çš„æ•¸æ“šæºã€‚
æä¾›çµ±ä¸€çš„æ¥å£ä¾†è¨ªå•æ‰€æœ‰æ•¸æ“šæºåŠŸèƒ½ã€‚
"""

from typing import Dict, List, Optional, Any
import pandas as pd
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class DataSourceRegistry:
    """æ•¸æ“šæºè¨»å†Šè¡¨"""
    
    def __init__(self):
        self.verified_crawler = None
        self.comprehensive_crawler = None
        self._initialize_crawlers()
    
    def _initialize_crawlers(self):
        """åˆå§‹åŒ–çˆ¬èŸ²å¯¦ä¾‹"""
        try:
            from .verified_crawler import VerifiedCrawler
            self.verified_crawler = VerifiedCrawler()
            logger.info("âœ… å·²é©—è­‰çˆ¬èŸ²åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ å·²é©—è­‰çˆ¬èŸ²åˆå§‹åŒ–å¤±æ•—: {e}")
        
        try:
            from .comprehensive_crawler import ComprehensiveCrawler
            self.comprehensive_crawler = ComprehensiveCrawler()
            logger.info("âœ… ç¶œåˆçˆ¬èŸ²åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ ç¶œåˆçˆ¬èŸ²åˆå§‹åŒ–å¤±æ•—: {e}")
    
    def get_all_data_sources(self) -> Dict[str, Dict[str, Dict[str, Any]]]:
        """ç²å–æ‰€æœ‰æ•¸æ“šæºçš„å®Œæ•´è¨»å†Šè¡¨"""
        return {
            'technical': {
                # å·²é©—è­‰å¯ç”¨ âœ…
                'twse_backtest_index': {
                    'name': 'å›æ¸¬åŸºæº–æŒ‡æ•¸',
                    'source': 'TWSE OpenAPI JSON',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_twse_backtest_index',
                    'description': 'å°è‚¡å›æ¸¬åŸºæº–æŒ‡æ•¸æ•¸æ“š'
                },
                'yahoo_adjusted_price': {
                    'name': 'é‚„åŸæ¬Šå€¼è‚¡åƒ¹',
                    'source': 'Yahoo Finance API',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_yahoo_adjusted_price',
                    'description': 'è‚¡ç¥¨é‚„åŸæ¬Šå€¼åƒ¹æ ¼æ•¸æ“š'
                },
                'twse_market_indicators': {
                    'name': 'å¤§ç›¤å¸‚æ³æŒ‡æ¨™',
                    'source': 'TWSE OpenAPI JSON',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_twse_market_indicators',
                    'description': 'å°è‚¡å¤§ç›¤å³æ™‚æŒ‡æ¨™æ•¸æ“š'
                },
                'tpex_mainboard_quotes': {
                    'name': 'TPEXä¸Šæ«ƒè‚¡ç¥¨',
                    'source': 'TPEX OpenAPI JSON',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_tpex_mainboard_quotes',
                    'description': 'ä¸Šæ«ƒè‚¡ç¥¨å³æ™‚å ±åƒ¹æ•¸æ“š'
                },
                # å¾…å¯¦ç¾ ğŸ”„
                'twse_zero_share': {
                    'name': 'ä¸Šå¸‚æ«ƒç›¤å¾Œé›¶è‚¡æˆäº¤è³‡è¨Š',
                    'source': 'TWSE CSV',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_zero_share',
                    'description': 'é›¶è‚¡äº¤æ˜“æˆäº¤è³‡è¨Š'
                },
                'tpex_cb_trading': {
                    'name': 'å¯è½‰æ›å…¬å¸å‚µæˆäº¤è³‡è¨Š',
                    'source': 'TPEX HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_tpex_cb_trading',
                    'description': 'å¯è½‰å‚µäº¤æ˜“è³‡è¨Š'
                },
                'twse_trading_change': {
                    'name': 'ä¸Šå¸‚æ«ƒè®Šæ›´äº¤æ˜“',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_trading_change',
                    'description': 'è‚¡ç¥¨äº¤æ˜“è®Šæ›´è³‡è¨Š'
                },
                'tpex_disposal_stocks': {
                    'name': 'æ’é™¤è™•ç½®è‚¡',
                    'source': 'TPEX HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_tpex_disposal_stocks',
                    'description': 'è™•ç½®è‚¡ç¥¨æ¸…å–®'
                },
                'twse_attention_stocks': {
                    'name': 'æ’é™¤æ³¨æ„è‚¡',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_attention_stocks',
                    'description': 'æ³¨æ„è‚¡ç¥¨æ¸…å–®'
                },
                'taifex_futures_daily': {
                    'name': 'æœŸè²¨æ—¥æˆäº¤è³‡è¨Š',
                    'source': 'TAIFEX CSV',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_taifex_futures_daily',
                    'description': 'æœŸè²¨å¸‚å ´æ—¥æˆäº¤æ•¸æ“š'
                }
            },
            'fundamental': {
                # å·²é©—è­‰å¯ç”¨ âœ…
                'gov_company_info': {
                    'name': 'ä¼æ¥­åŸºæœ¬è³‡è¨Š',
                    'source': 'æ”¿åºœé–‹æ”¾å¹³å° JSON',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_gov_company_info',
                    'description': 'ä¼æ¥­åŸºæœ¬è³‡æ–™å’Œè³‡æœ¬é¡'
                },
                'finmind_financial_data': {
                    'name': 'è²¡å‹™æŒ‡æ¨™',
                    'source': 'FinMind API JSON',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_finmind_financial_data',
                    'description': 'å…¬å¸è²¡å‹™å ±è¡¨å’ŒæŒ‡æ¨™'
                },
                # å¾…å¯¦ç¾ ğŸ”„
                'twse_dividend_announcement': {
                    'name': 'è‘£äº‹æœƒæ±ºæ“¬è­°åˆ†é…è‚¡åˆ©å…¬å‘Š',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_dividend_announcement',
                    'description': 'è‚¡åˆ©åˆ†é…å…¬å‘Šè³‡è¨Š'
                },
                'tpex_capital_reduction': {
                    'name': 'ä¸Šæ«ƒæ¸›è³‡',
                    'source': 'TPEX HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_tpex_capital_reduction',
                    'description': 'ä¸Šæ«ƒå…¬å¸æ¸›è³‡è³‡è¨Š'
                },
                'twse_capital_reduction': {
                    'name': 'ä¸Šå¸‚æ¸›è³‡',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_capital_reduction',
                    'description': 'ä¸Šå¸‚å…¬å¸æ¸›è³‡è³‡è¨Š'
                },
                'twse_business_info': {
                    'name': 'ä¼æ¥­ä¸»è¦ç¶“ç‡Ÿæ¥­å‹™',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_business_info',
                    'description': 'å…¬å¸ä¸»è¦æ¥­å‹™ç¯„åœ'
                },
                'twse_monthly_revenue': {
                    'name': 'ä¸Šå¸‚æ«ƒæœˆç‡Ÿæ”¶',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_monthly_revenue',
                    'description': 'å…¬å¸æœˆç‡Ÿæ”¶æ•¸æ“š'
                }
            },
            'chip': {
                # å·²é©—è­‰å¯ç”¨ âœ…
                'twse_broker_trading': {
                    'name': 'åˆ¸å•†åˆ†é»è²·è³£è¶…å‰15å¤§åˆ¸å•†æ˜ç´°',
                    'source': 'TWSE HTML',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_twse_broker_trading',
                    'description': 'åˆ¸å•†è²·è³£è¶…æ˜ç´°æ•¸æ“š'
                },
                'twse_foreign_holding': {
                    'name': 'å¤–è³‡æŒè‚¡æ¯”ç‡',
                    'source': 'TWSE HTML',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_twse_foreign_holding',
                    'description': 'å¤–è³‡æŒè‚¡æ¯”ä¾‹æ•¸æ“š'
                },
                # å¾…å¯¦ç¾ ğŸ”„
                'twse_broker_mapping': {
                    'name': 'åˆ¸å•†åˆ†é»åç¨±å°ç…§è¡¨',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_broker_mapping',
                    'description': 'åˆ¸å•†åˆ†é»ä»£ç¢¼å°ç…§'
                },
                'taifex_institutional_trading': {
                    'name': 'æœŸè²¨ä¸‰å¤§æ³•äººç›¤å¾Œè³‡è¨Š',
                    'source': 'TAIFEX CSV',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_taifex_institutional_trading',
                    'description': 'æœŸè²¨ä¸‰å¤§æ³•äººäº¤æ˜“æ•¸æ“š'
                },
                'twse_margin_trading': {
                    'name': 'èè³‡èåˆ¸',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_margin_trading',
                    'description': 'èè³‡èåˆ¸é¤˜é¡æ•¸æ“š'
                },
                'twse_securities_lending': {
                    'name': 'å€Ÿåˆ¸',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_securities_lending',
                    'description': 'è­‰åˆ¸å€Ÿè²¸æ•¸æ“š'
                }
            },
            'event': {
                # å¾…å¯¦ç¾ ğŸ”„
                'twse_announcements': {
                    'name': 'é‡è¨Šå…¬å‘Š',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_announcements',
                    'description': 'é‡å¤§è¨Šæ¯å…¬å‘Š'
                },
                'twse_investor_conference': {
                    'name': 'æ³•èªªæœƒæœŸç¨‹',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_investor_conference',
                    'description': 'æ³•äººèªªæ˜æœƒæ™‚ç¨‹'
                },
                'twse_shareholder_meeting': {
                    'name': 'è‚¡æ±æœƒæœŸç¨‹',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_shareholder_meeting',
                    'description': 'è‚¡æ±æœƒå¬é–‹æ™‚ç¨‹'
                },
                'twse_treasury_stock': {
                    'name': 'åº«è—è‚¡',
                    'source': 'TWSE HTML',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_twse_treasury_stock',
                    'description': 'åº«è—è‚¡è²·å›è³‡è¨Š'
                },
                'cnyes_news': {
                    'name': 'å°è‚¡æ–°è',
                    'source': 'cnyes RSS',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_cnyes_news',
                    'description': 'å°è‚¡ç›¸é—œæ–°èè³‡è¨Š'
                }
            },
            'macro': {
                # å·²é©—è­‰å¯ç”¨ âœ…
                'gov_economic_indicators': {
                    'name': 'å°ç£æ™¯æ°£æŒ‡æ¨™',
                    'source': 'æ”¿åºœé–‹æ”¾å¹³å° JSON',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_gov_economic_indicators',
                    'description': 'å°ç£ç¸½é«”ç¶“æ¿Ÿæ™¯æ°£æŒ‡æ¨™'
                },
                'yahoo_world_indices': {
                    'name': 'ä¸–ç•ŒæŒ‡æ•¸',
                    'source': 'Yahoo Finance API',
                    'status': 'verified',
                    'crawler': 'verified',
                    'method': 'crawl_yahoo_world_indices',
                    'description': 'å…¨çƒä¸»è¦è‚¡å¸‚æŒ‡æ•¸'
                },
                # å¾…å¯¦ç¾ ğŸ”„
                'gov_manufacturing_pmi': {
                    'name': 'å°ç£è£½é€ æ¥­æ¡è³¼ç¶“ç†äººæŒ‡æ•¸',
                    'source': 'æ”¿åºœé–‹æ”¾å¹³å° JSON',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_gov_manufacturing_pmi',
                    'description': 'è£½é€ æ¥­PMIæŒ‡æ¨™'
                },
                'gov_service_pmi': {
                    'name': 'å°ç£éè£½é€ æ¥­æ¡è³¼ç¶“ç†äººæŒ‡æ•¸',
                    'source': 'æ”¿åºœé–‹æ”¾å¹³å° JSON',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_gov_service_pmi',
                    'description': 'æœå‹™æ¥­PMIæŒ‡æ¨™'
                },
                'gov_money_supply': {
                    'name': 'è²¨å¹£ç¸½è¨ˆæ•¸å¹´å¢ç‡',
                    'source': 'æ”¿åºœé–‹æ”¾å¹³å° JSON',
                    'status': 'implemented',
                    'crawler': 'comprehensive',
                    'method': 'crawl_gov_money_supply',
                    'description': 'è²¨å¹£ä¾›çµ¦æˆé•·ç‡'
                }
            }
        }
    
    def get_verified_sources(self) -> Dict[str, List[str]]:
        """ç²å–å·²é©—è­‰å¯ç”¨çš„æ•¸æ“šæº"""
        all_sources = self.get_all_data_sources()
        verified_sources = {}
        
        for category, sources in all_sources.items():
            verified_list = []
            for source_id, source_info in sources.items():
                if source_info['status'] == 'verified':
                    verified_list.append(source_id)
            if verified_list:
                verified_sources[category] = verified_list
        
        return verified_sources
    
    def get_implemented_sources(self) -> Dict[str, List[str]]:
        """ç²å–å·²å¯¦ç¾çš„æ•¸æ“šæºï¼ˆåŒ…æ‹¬å·²é©—è­‰å’Œå¾…æ¸¬è©¦ï¼‰"""
        all_sources = self.get_all_data_sources()
        implemented_sources = {}
        
        for category, sources in all_sources.items():
            implemented_list = []
            for source_id, source_info in sources.items():
                if source_info['status'] in ['verified', 'implemented']:
                    implemented_list.append(source_id)
            if implemented_list:
                implemented_sources[category] = implemented_list
        
        return implemented_sources
    
    def crawl_data_source(self, source_id: str, category: str, **kwargs) -> pd.DataFrame:
        """çˆ¬å–æŒ‡å®šçš„æ•¸æ“šæº"""
        all_sources = self.get_all_data_sources()
        
        if category not in all_sources or source_id not in all_sources[category]:
            logger.error(f"æœªçŸ¥çš„æ•¸æ“šæº: {category}.{source_id}")
            return pd.DataFrame()
        
        source_info = all_sources[category][source_id]
        crawler_type = source_info['crawler']
        method_name = source_info['method']
        
        try:
            # é¸æ“‡å°æ‡‰çš„çˆ¬èŸ²
            if crawler_type == 'verified' and self.verified_crawler:
                crawler = self.verified_crawler
            elif crawler_type == 'comprehensive' and self.comprehensive_crawler:
                crawler = self.comprehensive_crawler
            else:
                logger.error(f"çˆ¬èŸ² {crawler_type} ä¸å¯ç”¨")
                return pd.DataFrame()
            
            # ç²å–æ–¹æ³•
            method = getattr(crawler, method_name, None)
            if not method:
                logger.error(f"æ–¹æ³• {method_name} ä¸å­˜åœ¨")
                return pd.DataFrame()
            
            # èª¿ç”¨æ–¹æ³•
            if method_name in ['crawl_yahoo_adjusted_price']:
                if 'symbol' in kwargs and 'start_date' in kwargs and 'end_date' in kwargs:
                    return method(kwargs['symbol'], kwargs['start_date'], kwargs['end_date'])
                else:
                    return method('2330.TW', '2025-07-20', '2025-07-25')
            elif method_name in ['crawl_gov_company_info', 'crawl_gov_economic_indicators']:
                return method(kwargs.get('api_key'))
            elif method_name == 'crawl_finmind_financial_data':
                return method(kwargs.get('symbol', '2330'))
            else:
                return method()
                
        except Exception as e:
            logger.error(f"çˆ¬å–æ•¸æ“šæº {source_id} å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def get_source_statistics(self) -> Dict[str, Any]:
        """ç²å–æ•¸æ“šæºçµ±è¨ˆè³‡è¨Š"""
        all_sources = self.get_all_data_sources()
        
        stats = {
            'total_sources': 0,
            'verified_sources': 0,
            'implemented_sources': 0,
            'by_category': {},
            'by_status': {'verified': 0, 'implemented': 0}
        }
        
        for category, sources in all_sources.items():
            category_stats = {
                'total': len(sources),
                'verified': 0,
                'implemented': 0
            }
            
            for source_info in sources.values():
                stats['total_sources'] += 1
                
                if source_info['status'] == 'verified':
                    stats['verified_sources'] += 1
                    stats['by_status']['verified'] += 1
                    category_stats['verified'] += 1
                elif source_info['status'] == 'implemented':
                    stats['implemented_sources'] += 1
                    stats['by_status']['implemented'] += 1
                    category_stats['implemented'] += 1
            
            stats['by_category'][category] = category_stats
        
        return stats
