# -*- coding: utf-8 -*-
"""
è‡ªå‹•åŒ–é©—è­‰ç®¡é“

æ­¤æ¨¡çµ„å¯¦ç¾æ•¸æ“šæºé©—è­‰å ±å‘Šæ”¹é€²å»ºè­°ä¸­çš„è‡ªå‹•åŒ–æ¸¬è©¦ç®¡é“ï¼Œ
å»ºç«‹æ¯é€±é©—è­‰è…³æœ¬ï¼Œæ•´åˆpytestæ¡†æ¶ï¼Œç”Ÿæˆè‡ªå‹•æ‘˜è¦å ±å‘Šã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- å®šæœŸæ•¸æ“šæºé©—è­‰
- è‡ªå‹•åŒ–æ¸¬è©¦åŸ·è¡Œ
- é©—è­‰çµæœå ±å‘Šç”Ÿæˆ
- ç•°å¸¸è­¦å ±æ©Ÿåˆ¶
- æ€§èƒ½ç›£æ§å’Œçµ±è¨ˆ

Example:
    åŸºæœ¬ä½¿ç”¨ï¼š
    ```python
    from src.data_sources.automated_validation_pipeline import AutomatedValidationPipeline
    
    pipeline = AutomatedValidationPipeline()
    pipeline.run_full_validation()
    ```

Note:
    æ­¤æ¨¡çµ„å°ˆé–€è§£æ±ºæ•¸æ“šæºé©—è­‰å ±å‘Šä¸­æåˆ°çš„å®šæœŸé©—è­‰éœ€æ±‚ï¼Œ
    å¯¦ç¾è‡ªå‹•åŒ–çš„æ•¸æ“šæºå¥åº·ç›£æ§å’Œå“è³ªä¿è­‰æ©Ÿåˆ¶ã€‚
"""

import logging
import json
import time
import schedule
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from pathlib import Path
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import pytest

from .enhanced_html_parser import EnhancedHTMLParser
from .multi_tier_backup_manager import MultiTierBackupManager
from .enhanced_data_validator import EnhancedDataValidator, DataQualityReport
from .verified_crawler import VerifiedCrawler
from .comprehensive_crawler import ComprehensiveCrawler

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


@dataclass
class ValidationResult:
    """é©—è­‰çµæœ"""
    source_name: str
    category: str
    data_type: str
    success: bool
    record_count: int
    response_time: float
    error_message: Optional[str]
    quality_report: Optional[DataQualityReport]
    timestamp: datetime


@dataclass
class ValidationSummary:
    """é©—è­‰æ‘˜è¦"""
    total_sources: int
    successful_sources: int
    failed_sources: int
    avg_response_time: float
    overall_success_rate: float
    quality_distribution: Dict[str, int]
    critical_issues: List[str]
    recommendations: List[str]
    timestamp: datetime


class AutomatedValidationPipeline:
    """
    è‡ªå‹•åŒ–é©—è­‰ç®¡é“
    
    æä¾›å®šæœŸæ•¸æ“šæºé©—è­‰ã€è‡ªå‹•åŒ–æ¸¬è©¦å’Œå ±å‘Šç”ŸæˆåŠŸèƒ½ã€‚
    """
    
    def __init__(self, output_dir: str = "logs/validation_reports"):
        """
        åˆå§‹åŒ–è‡ªå‹•åŒ–é©—è­‰ç®¡é“
        
        Args:
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.html_parser = EnhancedHTMLParser()
        self.backup_manager = MultiTierBackupManager()
        self.data_validator = EnhancedDataValidator()
        self.verified_crawler = VerifiedCrawler()
        self.comprehensive_crawler = ComprehensiveCrawler()
        
        # é©—è­‰é…ç½®
        self.validation_config = self._load_validation_config()
        
        # èª¿åº¦å™¨
        self.scheduler_thread = None
        self.is_running = False
        
        logger.info("âœ… è‡ªå‹•åŒ–é©—è­‰ç®¡é“åˆå§‹åŒ–å®Œæˆ")
        
    def _load_validation_config(self) -> Dict[str, Any]:
        """è¼‰å…¥é©—è­‰é…ç½®"""
        return {
            'verified_sources': {
                'æŠ€è¡“é¢': [
                    'crawl_twse_backtest_index',
                    'crawl_yahoo_adjusted_price',
                    'crawl_twse_market_indicators',
                    'crawl_tpex_mainboard_quotes'
                ],
                'åŸºæœ¬é¢': [
                    'crawl_gov_company_info',
                    'crawl_finmind_financial_data'
                ],
                'ç±Œç¢¼é¢': [
                    'crawl_twse_broker_trading',
                    'crawl_twse_foreign_holding'
                ],
                'ç¸½ç¶“é¢': [
                    'crawl_gov_economic_indicators',
                    'crawl_yahoo_world_indices'
                ]
            },
            'comprehensive_sources': {
                'æŠ€è¡“é¢': [
                    'crawl_twse_afterhours_oddlot',
                    'crawl_tpex_convertible_bonds'
                ],
                'åŸºæœ¬é¢': [
                    'crawl_twse_dividend_announcement',
                    'crawl_twse_monthly_revenue'
                ],
                'ç±Œç¢¼é¢': [
                    'crawl_twse_broker_branch_mapping',
                    'crawl_twse_margin_trading'
                ],
                'äº‹ä»¶é¢': [
                    'crawl_twse_announcements',
                    'crawl_cnyes_news'
                ]
            },
            'validation_params': {
                'timeout': 30,
                'max_workers': 5,
                'retry_attempts': 3,
                'quality_threshold': 70.0
            }
        }
        
    def run_full_validation(self) -> ValidationSummary:
        """
        åŸ·è¡Œå®Œæ•´é©—è­‰
        
        Returns:
            ValidationSummary: é©—è­‰æ‘˜è¦
        """
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´æ•¸æ“šæºé©—è­‰")
        start_time = time.time()
        
        all_results = []
        
        # é©—è­‰å·²é©—è­‰æ•¸æ“šæº
        verified_results = self._validate_sources(
            self.verified_crawler,
            self.validation_config['verified_sources'],
            'verified'
        )
        all_results.extend(verified_results)
        
        # é©—è­‰ç¶œåˆæ•¸æ“šæº
        comprehensive_results = self._validate_sources(
            self.comprehensive_crawler,
            self.validation_config['comprehensive_sources'],
            'comprehensive'
        )
        all_results.extend(comprehensive_results)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_summary(all_results)
        
        # ä¿å­˜çµæœ
        self._save_validation_results(all_results, summary)
        
        # ç”Ÿæˆå ±å‘Š
        self._generate_html_report(all_results, summary)
        
        total_time = time.time() - start_time
        logger.info(f"âœ… å®Œæ•´é©—è­‰å®Œæˆï¼Œè€—æ™‚ {total_time:.2f} ç§’")
        
        return summary
        
    def _validate_sources(self, crawler, source_config: Dict[str, List[str]], 
                         crawler_type: str) -> List[ValidationResult]:
        """
        é©—è­‰æ•¸æ“šæº
        
        Args:
            crawler: çˆ¬èŸ²å¯¦ä¾‹
            source_config: æ•¸æ“šæºé…ç½®
            crawler_type: çˆ¬èŸ²é¡å‹
            
        Returns:
            List[ValidationResult]: é©—è­‰çµæœåˆ—è¡¨
        """
        results = []
        max_workers = self.validation_config['validation_params']['max_workers']
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_source = {}
            
            for category, methods in source_config.items():
                for method_name in methods:
                    future = executor.submit(
                        self._validate_single_source,
                        crawler, category, method_name, crawler_type
                    )
                    future_to_source[future] = (category, method_name)
                    
            for future in as_completed(future_to_source):
                category, method_name = future_to_source[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    status = "âœ…" if result.success else "âŒ"
                    logger.info(f"{status} {category}/{method_name}: "
                              f"{result.record_count} ç­†è¨˜éŒ„, "
                              f"{result.response_time:.2f}s")
                              
                except Exception as e:
                    logger.error(f"âŒ é©—è­‰å¤±æ•— {category}/{method_name}: {e}")
                    results.append(ValidationResult(
                        source_name=method_name,
                        category=category,
                        data_type=crawler_type,
                        success=False,
                        record_count=0,
                        response_time=0.0,
                        error_message=str(e),
                        quality_report=None,
                        timestamp=datetime.now()
                    ))
                    
        return results
        
    def _validate_single_source(self, crawler, category: str, method_name: str, 
                               crawler_type: str) -> ValidationResult:
        """
        é©—è­‰å–®ä¸€æ•¸æ“šæº
        
        Args:
            crawler: çˆ¬èŸ²å¯¦ä¾‹
            category: æ•¸æ“šåˆ†é¡
            method_name: æ–¹æ³•åç¨±
            crawler_type: çˆ¬èŸ²é¡å‹
            
        Returns:
            ValidationResult: é©—è­‰çµæœ
        """
        start_time = time.time()
        
        try:
            method = getattr(crawler, method_name)
            
            # åŸ·è¡Œæ•¸æ“šç²å–
            if method_name == 'crawl_yahoo_adjusted_price':
                df = method('2330.TW', '2025-07-20', '2025-07-25')
            elif method_name in ['crawl_gov_company_info', 'crawl_gov_economic_indicators']:
                df = method(None)  # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
            else:
                df = method()
                
            response_time = time.time() - start_time
            
            # æ•¸æ“šå“è³ªé©—è­‰
            quality_report = None
            if not df.empty:
                quality_report = self.data_validator.validate_data_quality(
                    df, data_type=category
                )
                
            return ValidationResult(
                source_name=method_name,
                category=category,
                data_type=crawler_type,
                success=not df.empty,
                record_count=len(df),
                response_time=response_time,
                error_message=None,
                quality_report=quality_report,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            response_time = time.time() - start_time
            return ValidationResult(
                source_name=method_name,
                category=category,
                data_type=crawler_type,
                success=False,
                record_count=0,
                response_time=response_time,
                error_message=str(e),
                quality_report=None,
                timestamp=datetime.now()
            )
            
    def _generate_summary(self, results: List[ValidationResult]) -> ValidationSummary:
        """
        ç”Ÿæˆé©—è­‰æ‘˜è¦
        
        Args:
            results: é©—è­‰çµæœåˆ—è¡¨
            
        Returns:
            ValidationSummary: é©—è­‰æ‘˜è¦
        """
        total_sources = len(results)
        successful_sources = sum(1 for r in results if r.success)
        failed_sources = total_sources - successful_sources
        
        # è¨ˆç®—å¹³å‡éŸ¿æ‡‰æ™‚é–“
        response_times = [r.response_time for r in results if r.response_time > 0]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0.0
        
        # è¨ˆç®—æˆåŠŸç‡
        overall_success_rate = (successful_sources / total_sources * 100) if total_sources > 0 else 0.0
        
        # å“è³ªåˆ†å¸ƒçµ±è¨ˆ
        quality_distribution = {}
        quality_reports = [r.quality_report for r in results if r.quality_report]
        
        if quality_reports:
            validator_summary = self.data_validator.get_validation_summary(quality_reports)
            quality_distribution = validator_summary.get('quality_distribution', {})
            
        # é—œéµå•é¡Œ
        critical_issues = []
        for result in results:
            if not result.success:
                critical_issues.append(f"{result.category}/{result.source_name}: {result.error_message}")
            elif result.quality_report and result.quality_report.quality_score < 60:
                critical_issues.append(f"{result.category}/{result.source_name}: æ•¸æ“šå“è³ªéä½ ({result.quality_report.quality_score:.1f}%)")
                
        # å»ºè­°
        recommendations = self._generate_recommendations(results, overall_success_rate)
        
        return ValidationSummary(
            total_sources=total_sources,
            successful_sources=successful_sources,
            failed_sources=failed_sources,
            avg_response_time=avg_response_time,
            overall_success_rate=overall_success_rate,
            quality_distribution=quality_distribution,
            critical_issues=critical_issues[:10],  # é™åˆ¶å‰10å€‹
            recommendations=recommendations,
            timestamp=datetime.now()
        )
        
    def _generate_recommendations(self, results: List[ValidationResult], 
                                success_rate: float) -> List[str]:
        """
        ç”Ÿæˆæ”¹é€²å»ºè­°
        
        Args:
            results: é©—è­‰çµæœåˆ—è¡¨
            success_rate: æˆåŠŸç‡
            
        Returns:
            List[str]: å»ºè­°åˆ—è¡¨
        """
        recommendations = []
        
        # æˆåŠŸç‡å»ºè­°
        if success_rate < 70:
            recommendations.append("æ•´é«”æˆåŠŸç‡éä½ï¼Œå»ºè­°æª¢æŸ¥ç¶²è·¯é€£æ¥å’Œæ•¸æ“šæºå¯ç”¨æ€§")
        elif success_rate < 85:
            recommendations.append("éƒ¨åˆ†æ•¸æ“šæºä¸ç©©å®šï¼Œå»ºè­°å¯¦æ–½å‚™æ´æ©Ÿåˆ¶")
            
        # HTMLè§£æå•é¡Œ
        html_failures = [r for r in results if not r.success and 'HTML' in str(r.error_message)]
        if len(html_failures) > 3:
            recommendations.append("HTMLè§£æå¤±æ•—è¼ƒå¤šï¼Œå»ºè­°ä½¿ç”¨å¢å¼·HTMLè§£æå™¨")
            
        # éŸ¿æ‡‰æ™‚é–“å•é¡Œ
        slow_sources = [r for r in results if r.response_time > 20]
        if len(slow_sources) > 2:
            recommendations.append("éƒ¨åˆ†æ•¸æ“šæºéŸ¿æ‡‰ç·©æ…¢ï¼Œå»ºè­°å„ªåŒ–è«‹æ±‚é…ç½®æˆ–å¢åŠ è¶…æ™‚è¨­å®š")
            
        # æ•¸æ“šå“è³ªå•é¡Œ
        quality_issues = [r for r in results if r.quality_report and r.quality_report.quality_score < 70]
        if len(quality_issues) > 0:
            recommendations.append("ç™¼ç¾æ•¸æ“šå“è³ªå•é¡Œï¼Œå»ºè­°åŠ å¼·æ•¸æ“šé©—è­‰å’Œæ¸…ç†æ©Ÿåˆ¶")
            
        # é€šç”¨å»ºè­°
        if not recommendations:
            recommendations.append("æ•¸æ“šæºç‹€æ…‹è‰¯å¥½ï¼Œå»ºè­°ç¶­æŒç•¶å‰ç›£æ§é »ç‡")
        else:
            recommendations.append("å»ºè­°å¯¦æ–½å¤šå±¤å‚™æ´æ©Ÿåˆ¶å’Œè‡ªå‹•æ•…éšœè½‰ç§»")
            
        return recommendations
        
    def _save_validation_results(self, results: List[ValidationResult], 
                               summary: ValidationSummary) -> None:
        """
        ä¿å­˜é©—è­‰çµæœ
        
        Args:
            results: é©—è­‰çµæœåˆ—è¡¨
            summary: é©—è­‰æ‘˜è¦
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜è©³ç´°çµæœ
        results_file = self.output_dir / f"validation_results_{timestamp}.json"
        results_data = [asdict(result) for result in results]
        
        # è™•ç†datetimeåºåˆ—åŒ–
        for result_data in results_data:
            result_data['timestamp'] = result_data['timestamp'].isoformat()
            if result_data['quality_report']:
                result_data['quality_report']['timestamp'] = result_data['quality_report']['timestamp'].isoformat()
                
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, ensure_ascii=False, indent=2)
            
        # ä¿å­˜æ‘˜è¦
        summary_file = self.output_dir / f"validation_summary_{timestamp}.json"
        summary_data = asdict(summary)
        summary_data['timestamp'] = summary_data['timestamp'].isoformat()
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
        logger.info(f"âœ… é©—è­‰çµæœå·²ä¿å­˜: {results_file}, {summary_file}")
        
    def _generate_html_report(self, results: List[ValidationResult], 
                            summary: ValidationSummary) -> None:
        """
        ç”ŸæˆHTMLå ±å‘Š
        
        Args:
            results: é©—è­‰çµæœåˆ—è¡¨
            summary: é©—è­‰æ‘˜è¦
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"validation_report_{timestamp}.html"
        
        # ç°¡åŒ–çš„HTMLå ±å‘Šæ¨¡æ¿
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>æ•¸æ“šæºé©—è­‰å ±å‘Š</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .summary {{ background: #f5f5f5; padding: 15px; border-radius: 5px; }}
                .success {{ color: green; }}
                .failure {{ color: red; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <h1>æ•¸æ“šæºé©—è­‰å ±å‘Š</h1>
            <div class="summary">
                <h2>é©—è­‰æ‘˜è¦</h2>
                <p>ç¸½æ•¸æ“šæº: {summary.total_sources}</p>
                <p>æˆåŠŸ: <span class="success">{summary.successful_sources}</span></p>
                <p>å¤±æ•—: <span class="failure">{summary.failed_sources}</span></p>
                <p>æˆåŠŸç‡: {summary.overall_success_rate:.1f}%</p>
                <p>å¹³å‡éŸ¿æ‡‰æ™‚é–“: {summary.avg_response_time:.2f}ç§’</p>
                <p>é©—è­‰æ™‚é–“: {summary.timestamp.strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <h2>è©³ç´°çµæœ</h2>
            <table>
                <tr>
                    <th>æ•¸æ“šæº</th>
                    <th>åˆ†é¡</th>
                    <th>ç‹€æ…‹</th>
                    <th>è¨˜éŒ„æ•¸</th>
                    <th>éŸ¿æ‡‰æ™‚é–“</th>
                    <th>å“è³ªåˆ†æ•¸</th>
                </tr>
        """
        
        for result in results:
            status_class = "success" if result.success else "failure"
            status_text = "âœ… æˆåŠŸ" if result.success else "âŒ å¤±æ•—"
            quality_score = result.quality_report.quality_score if result.quality_report else "N/A"
            
            html_content += f"""
                <tr>
                    <td>{result.source_name}</td>
                    <td>{result.category}</td>
                    <td class="{status_class}">{status_text}</td>
                    <td>{result.record_count}</td>
                    <td>{result.response_time:.2f}s</td>
                    <td>{quality_score}</td>
                </tr>
            """
            
        html_content += """
            </table>
        </body>
        </html>
        """
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        logger.info(f"âœ… HTMLå ±å‘Šå·²ç”Ÿæˆ: {report_file}")
        
    def start_scheduled_validation(self, interval_hours: int = 24) -> None:
        """
        å•Ÿå‹•å®šæœŸé©—è­‰
        
        Args:
            interval_hours: é©—è­‰é–“éš”ï¼ˆå°æ™‚ï¼‰
        """
        if self.is_running:
            logger.warning("å®šæœŸé©—è­‰å·²åœ¨é‹è¡Œä¸­")
            return
            
        # è¨­å®šèª¿åº¦
        schedule.every(interval_hours).hours.do(self.run_full_validation)
        
        self.is_running = True
        self.scheduler_thread = threading.Thread(target=self._scheduler_loop, daemon=True)
        self.scheduler_thread.start()
        
        logger.info(f"âœ… å®šæœŸé©—è­‰å·²å•Ÿå‹•ï¼Œé–“éš” {interval_hours} å°æ™‚")
        
    def stop_scheduled_validation(self) -> None:
        """åœæ­¢å®šæœŸé©—è­‰"""
        self.is_running = False
        schedule.clear()
        
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5)
            
        logger.info("âœ… å®šæœŸé©—è­‰å·²åœæ­¢")
        
    def _scheduler_loop(self) -> None:
        """èª¿åº¦å™¨å¾ªç’°"""
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
            except Exception as e:
                logger.error(f"èª¿åº¦å™¨éŒ¯èª¤: {e}")
                time.sleep(60)
