#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è‚¡å¤šæ•¸æ“šæºçˆ¬èŸ²ç³»çµ± - Jupyter Notebook æ¼”ç¤º
==========================================

é€™æ˜¯ä¸€å€‹å®Œæ•´çš„æ¼”ç¤ºæ–‡ä»¶ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨å¤šæ•¸æ“šæºçˆ¬èŸ²ç³»çµ±
ç²å–å°è‚¡çš„æŠ€è¡“é¢ã€åŸºæœ¬é¢ã€ç±Œç¢¼é¢ã€äº‹ä»¶é¢å’Œç¸½ç¶“é¢æ•¸æ“šã€‚

åŠŸèƒ½æ¼”ç¤ºï¼š
1. æŠ€è¡“é¢æ•¸æ“šç²å– (TWSE + TPEX + Yahoo Finance)
2. åŸºæœ¬é¢æ•¸æ“šç²å– (è²¡å ±ã€è‚¡åˆ©ã€ç‡Ÿæ”¶ç­‰)
3. ç±Œç¢¼é¢æ•¸æ“šç²å– (ä¸‰å¤§æ³•äººã€èè³‡åˆ¸ç­‰)
4. äº‹ä»¶é¢æ•¸æ“šç²å– (å…¬å‘Šã€æ–°èç­‰)
5. ç¸½ç¶“é¢æ•¸æ“šç²å– (æ™¯æ°£æŒ‡æ¨™ã€PMIç­‰)
6. è‡ªå­¸èƒ½åŠ›å’Œæ•¸æ“šé©—è­‰
7. å¤šæºæ•¸æ“šæ¯”å°å’Œæº–ç¢ºæ€§åˆ†æ

Author: AI Trading System
Date: 2025-01-28
Version: 1.0
"""

# ============================================================================
# Cell 1: å°å…¥å¿…è¦çš„åº«å’Œæ¨¡çµ„
# ============================================================================

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display, HTML
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# å°å…¥æˆ‘å€‘çš„å¤šæ•¸æ“šæºçˆ¬èŸ²ç³»çµ±
from src.data_sources.multi_source_downloader import MultiSourceDownloader

print("ğŸ“Š å°è‚¡å¤šæ•¸æ“šæºçˆ¬èŸ²ç³»çµ±æ¼”ç¤º")
print("=" * 60)
print(f"æ¼”ç¤ºæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"Pythonç‰ˆæœ¬: {sys.version}")

# ============================================================================
# Cell 2: ç³»çµ±é…ç½®å’Œåˆå§‹åŒ–
# ============================================================================

# é…ç½®åƒæ•¸
TEST_SYMBOL = '2330.TW'  # æ¸¬è©¦è‚¡ç¥¨ï¼šå°ç©é›»
START_DATE = '20250701'  # é–‹å§‹æ—¥æœŸ
END_DATE = '20250728'    # çµæŸæ—¥æœŸ
DB_URL = "sqlite:///examples/demo_multi_source.db"  # è³‡æ–™åº«é€£æ¥

print("\nğŸ”§ ç³»çµ±é…ç½®")
print("-" * 40)
print(f"æ¸¬è©¦è‚¡ç¥¨: {TEST_SYMBOL}")
print(f"æ—¥æœŸç¯„åœ: {START_DATE} è‡³ {END_DATE}")
print(f"è³‡æ–™åº«: {DB_URL}")

# åˆå§‹åŒ–å¤šæ•¸æ“šæºä¸‹è¼‰å™¨
downloader = MultiSourceDownloader(db_url=DB_URL)
print("\nâœ… å¤šæ•¸æ“šæºä¸‹è¼‰å™¨åˆå§‹åŒ–å®Œæˆ")

# ============================================================================
# Cell 3: æŠ€è¡“é¢æ•¸æ“šç²å–æ¼”ç¤º
# ============================================================================

print("\nğŸ§ª æ¸¬è©¦ 1: æŠ€è¡“é¢æ•¸æ“šç²å–")
print("=" * 50)

# ç²å–æŠ€è¡“é¢æ•¸æ“š
technical_data = downloader.technical.get_comprehensive_data(
    TEST_SYMBOL, START_DATE, END_DATE
)

print(f"\nğŸ“Š æŠ€è¡“é¢æ•¸æ“šç²å–çµæœ:")
for data_type, df in technical_data.items():
    if not df.empty:
        print(f"   âœ… {data_type}: {len(df)} ç­†è¨˜éŒ„")
        
        # é¡¯ç¤ºå‰å¹¾ç­†æ•¸æ“šæ¨£æœ¬
        if len(df) > 0:
            print(f"      æ¨£æœ¬æ•¸æ“š: {df.columns.tolist()}")
    else:
        print(f"   âš ï¸ {data_type}: ç„¡æ•¸æ“š")

# ç‰¹åˆ¥å±•ç¤ºé‚„åŸæ¬Šå€¼è‚¡åƒ¹æ•¸æ“š
if 'adjusted_price' in technical_data and not technical_data['adjusted_price'].empty:
    adj_price_df = technical_data['adjusted_price']
    print(f"\nğŸ“ˆ {TEST_SYMBOL} é‚„åŸæ¬Šå€¼è‚¡åƒ¹è©³æƒ…:")
    print(f"   æ—¥æœŸç¯„åœ: {adj_price_df['Date'].min()} è‡³ {adj_price_df['Date'].max()}")
    print(f"   åƒ¹æ ¼ç¯„åœ: {adj_price_df['Close'].min():.2f} - {adj_price_df['Close'].max():.2f}")
    print(f"   å¹³å‡æˆäº¤é‡: {adj_price_df['Volume'].mean():,.0f}")
    
    # é¡¯ç¤ºæœ€è¿‘5å¤©æ•¸æ“š
    print(f"\n   æœ€è¿‘5å¤©æ•¸æ“š:")
    display_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
    recent_data = adj_price_df[display_cols].tail()
    for _, row in recent_data.iterrows():
        print(f"   {row['Date'].strftime('%Y-%m-%d')}: "
              f"é–‹{row['Open']:.2f} é«˜{row['High']:.2f} "
              f"ä½{row['Low']:.2f} æ”¶{row['Close']:.2f} "
              f"é‡{row['Volume']:,.0f}")

# ============================================================================
# Cell 4: åŸºæœ¬é¢æ•¸æ“šç²å–æ¼”ç¤º
# ============================================================================

print("\nğŸ§ª æ¸¬è©¦ 2: åŸºæœ¬é¢æ•¸æ“šç²å–")
print("=" * 50)

# ç²å–åŸºæœ¬é¢æ•¸æ“š
fundamental_data = downloader.fundamental.get_comprehensive_data(
    TEST_SYMBOL, START_DATE, END_DATE
)

print(f"\nğŸ“ˆ åŸºæœ¬é¢æ•¸æ“šç²å–çµæœ:")
for data_type, df in fundamental_data.items():
    if not df.empty:
        print(f"   âœ… {data_type}: {len(df)} ç­†è¨˜éŒ„")
        
        # é¡¯ç¤ºæ•¸æ“šçµæ§‹
        if len(df.columns) > 0:
            print(f"      æ¬„ä½: {df.columns.tolist()[:5]}...")  # åªé¡¯ç¤ºå‰5å€‹æ¬„ä½
    else:
        print(f"   âš ï¸ {data_type}: ç„¡æ•¸æ“š")

# ç‰¹åˆ¥å±•ç¤ºè‚¡åˆ©å…¬å‘Šæ•¸æ“š
if 'dividend' in fundamental_data and not fundamental_data['dividend'].empty:
    dividend_df = fundamental_data['dividend']
    print(f"\nğŸ’° è‚¡åˆ©å…¬å‘Šè©³æƒ…:")
    print(f"   å…¬å‘Šæ•¸é‡: {len(dividend_df)} ç­†")
    print(f"   çˆ¬å–æ—¥æœŸ: {dividend_df['crawl_date'].iloc[0] if len(dividend_df) > 0 else 'N/A'}")

# ============================================================================
# Cell 5: æ•¸æ“šå“è³ªåˆ†æå’Œé©—è­‰
# ============================================================================

print("\nğŸ§ª æ¸¬è©¦ 3: æ•¸æ“šå“è³ªåˆ†æ")
print("=" * 50)

def analyze_data_quality(data_dict: dict, category_name: str) -> dict:
    """åˆ†ææ•¸æ“šå“è³ª"""
    quality_report = {
        'category': category_name,
        'total_datasets': len(data_dict),
        'successful_datasets': 0,
        'total_records': 0,
        'empty_datasets': [],
        'successful_datasets_list': []
    }
    
    for data_type, df in data_dict.items():
        if not df.empty:
            quality_report['successful_datasets'] += 1
            quality_report['total_records'] += len(df)
            quality_report['successful_datasets_list'].append(data_type)
        else:
            quality_report['empty_datasets'].append(data_type)
    
    quality_report['success_rate'] = (
        quality_report['successful_datasets'] / quality_report['total_datasets'] 
        if quality_report['total_datasets'] > 0 else 0
    )
    
    return quality_report

# åˆ†ææŠ€è¡“é¢æ•¸æ“šå“è³ª
tech_quality = analyze_data_quality(technical_data, 'æŠ€è¡“é¢')
print(f"ğŸ“Š æŠ€è¡“é¢æ•¸æ“šå“è³ªåˆ†æ:")
print(f"   ç¸½æ•¸æ“šé›†: {tech_quality['total_datasets']}")
print(f"   æˆåŠŸç²å–: {tech_quality['successful_datasets']}")
print(f"   æˆåŠŸç‡: {tech_quality['success_rate']:.1%}")
print(f"   ç¸½è¨˜éŒ„æ•¸: {tech_quality['total_records']}")
print(f"   æˆåŠŸæ•¸æ“šé›†: {', '.join(tech_quality['successful_datasets_list'])}")
if tech_quality['empty_datasets']:
    print(f"   ç©ºæ•¸æ“šé›†: {', '.join(tech_quality['empty_datasets'])}")

# åˆ†æåŸºæœ¬é¢æ•¸æ“šå“è³ª
fund_quality = analyze_data_quality(fundamental_data, 'åŸºæœ¬é¢')
print(f"\nğŸ“ˆ åŸºæœ¬é¢æ•¸æ“šå“è³ªåˆ†æ:")
print(f"   ç¸½æ•¸æ“šé›†: {fund_quality['total_datasets']}")
print(f"   æˆåŠŸç²å–: {fund_quality['successful_datasets']}")
print(f"   æˆåŠŸç‡: {fund_quality['success_rate']:.1%}")
print(f"   ç¸½è¨˜éŒ„æ•¸: {fund_quality['total_records']}")

# ============================================================================
# Cell 6: å¤šæºæ•¸æ“šæ¯”å°æ¼”ç¤º
# ============================================================================

print("\nğŸ§ª æ¸¬è©¦ 4: å¤šæºæ•¸æ“šæ¯”å°")
print("=" * 50)

def compare_data_sources(technical_data: dict) -> dict:
    """æ¯”å°ä¸åŒæ•¸æ“šæºçš„æº–ç¢ºæ€§"""
    comparison_report = {
        'timestamp': datetime.now(),
        'comparisons': []
    }
    
    # æ¯”å°Yahoo Financeå’ŒTWSEæ•¸æ“šï¼ˆå¦‚æœéƒ½æœ‰çš„è©±ï¼‰
    yahoo_data = technical_data.get('adjusted_price')
    twse_data = technical_data.get('backtest_index')
    
    if yahoo_data is not None and not yahoo_data.empty:
        comparison_report['comparisons'].append({
            'source': 'Yahoo Finance',
            'data_type': 'è‚¡åƒ¹æ•¸æ“š',
            'records': len(yahoo_data),
            'date_range': f"{yahoo_data['Date'].min()} è‡³ {yahoo_data['Date'].max()}",
            'price_range': f"{yahoo_data['Close'].min():.2f} - {yahoo_data['Close'].max():.2f}",
            'avg_volume': f"{yahoo_data['Volume'].mean():,.0f}"
        })
    
    if twse_data is not None and not twse_data.empty:
        comparison_report['comparisons'].append({
            'source': 'TWSE OpenAPI',
            'data_type': 'æŒ‡æ•¸æ•¸æ“š',
            'records': len(twse_data),
            'coverage': 'å¤§ç›¤æŒ‡æ•¸æ­·å²è³‡æ–™'
        })
    
    return comparison_report

# åŸ·è¡Œå¤šæºæ¯”å°
comparison_result = compare_data_sources(technical_data)

print(f"ğŸ” å¤šæºæ•¸æ“šæ¯”å°çµæœ:")
print(f"   æ¯”å°æ™‚é–“: {comparison_result['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")

for comp in comparison_result['comparisons']:
    print(f"\n   ğŸ“Š {comp['source']} ({comp['data_type']}):")
    print(f"      è¨˜éŒ„æ•¸: {comp['records']}")
    if 'date_range' in comp:
        print(f"      æ—¥æœŸç¯„åœ: {comp['date_range']}")
        print(f"      åƒ¹æ ¼ç¯„åœ: {comp['price_range']}")
        print(f"      å¹³å‡æˆäº¤é‡: {comp['avg_volume']}")
    if 'coverage' in comp:
        print(f"      è¦†è“‹ç¯„åœ: {comp['coverage']}")

# ============================================================================
# Cell 7: è‡ªå­¸èƒ½åŠ›æ¼”ç¤º
# ============================================================================

print("\nğŸ§ª æ¸¬è©¦ 5: è‡ªå­¸èƒ½åŠ›æ¼”ç¤º")
print("=" * 50)

def demonstrate_self_learning(technical_data: dict, fundamental_data: dict) -> dict:
    """æ¼”ç¤ºè‡ªå­¸èƒ½åŠ›"""
    learning_report = {
        'timestamp': datetime.now(),
        'data_quality_score': 0.0,
        'recommendations': [],
        'learning_insights': []
    }
    
    # è¨ˆç®—æ•´é«”æ•¸æ“šå“è³ªåˆ†æ•¸
    total_datasets = len(technical_data) + len(fundamental_data)
    successful_datasets = sum(1 for df in technical_data.values() if not df.empty)
    successful_datasets += sum(1 for df in fundamental_data.values() if not df.empty)
    
    if total_datasets > 0:
        learning_report['data_quality_score'] = successful_datasets / total_datasets
    
    # ç”Ÿæˆæ™ºèƒ½å»ºè­°
    if learning_report['data_quality_score'] < 0.8:
        learning_report['recommendations'].append(
            "æ•¸æ“šç²å–æˆåŠŸç‡åä½ï¼Œå»ºè­°æª¢æŸ¥ç¶²è·¯é€£æ¥å’ŒAPIå¯ç”¨æ€§"
        )
    
    if 'adjusted_price' in technical_data and not technical_data['adjusted_price'].empty:
        learning_report['learning_insights'].append(
            "Yahoo Financeè‚¡åƒ¹æ•¸æ“šç²å–ç©©å®šï¼Œå»ºè­°ä½œç‚ºä¸»è¦æŠ€è¡“é¢æ•¸æ“šæº"
        )
    
    if any(df.empty for df in technical_data.values()):
        learning_report['recommendations'].append(
            "éƒ¨åˆ†æŠ€è¡“é¢æ•¸æ“šæºç„¡æ³•ç²å–ï¼Œå»ºè­°å•Ÿç”¨å‚™æ´æ•¸æ“šæº"
        )
    
    # å­¸ç¿’æœ€ä½³å¯¦è¸
    if learning_report['data_quality_score'] > 0.7:
        learning_report['learning_insights'].append(
            "ç•¶å‰æ•¸æ“šç²å–ç­–ç•¥æœ‰æ•ˆï¼Œç³»çµ±å­¸ç¿’ä¸¦è¨˜éŒ„æˆåŠŸæ¨¡å¼"
        )
    
    return learning_report

# åŸ·è¡Œè‡ªå­¸åˆ†æ
learning_result = demonstrate_self_learning(technical_data, fundamental_data)

print(f"ğŸ¤– è‡ªå­¸èƒ½åŠ›åˆ†æçµæœ:")
print(f"   åˆ†ææ™‚é–“: {learning_result['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
print(f"   æ•¸æ“šå“è³ªåˆ†æ•¸: {learning_result['data_quality_score']:.3f}")

if learning_result['recommendations']:
    print(f"\n   ğŸ’¡ æ™ºèƒ½å»ºè­°:")
    for i, rec in enumerate(learning_result['recommendations'], 1):
        print(f"      {i}. {rec}")

if learning_result['learning_insights']:
    print(f"\n   ğŸ§  å­¸ç¿’æ´å¯Ÿ:")
    for i, insight in enumerate(learning_result['learning_insights'], 1):
        print(f"      {i}. {insight}")

# ============================================================================
# Cell 8: ç³»çµ±æ•´åˆå»ºè­°
# ============================================================================

print("\nğŸ§ª æ¸¬è©¦ 6: ç³»çµ±æ•´åˆå»ºè­°")
print("=" * 50)

def generate_integration_suggestions(all_results: dict) -> dict:
    """ç”Ÿæˆç³»çµ±æ•´åˆå»ºè­°"""
    suggestions = {
        'timestamp': datetime.now(),
        'integration_recommendations': [],
        'performance_optimizations': [],
        'data_source_priorities': {}
    }
    
    # åŸºæ–¼æ¸¬è©¦çµæœç”Ÿæˆå»ºè­°
    if technical_data.get('adjusted_price') is not None and not technical_data['adjusted_price'].empty:
        suggestions['data_source_priorities']['primary_price_source'] = 'Yahoo Finance'
        suggestions['integration_recommendations'].append(
            "å»ºè­°å°‡Yahoo Financeè¨­ç‚ºä¸»è¦è‚¡åƒ¹æ•¸æ“šæºï¼Œå…·æœ‰é«˜å¯é æ€§å’Œå®Œæ•´æ€§"
        )
    
    if technical_data.get('backtest_index') is not None and not technical_data['backtest_index'].empty:
        suggestions['data_source_priorities']['index_source'] = 'TWSE OpenAPI'
        suggestions['integration_recommendations'].append(
            "TWSE OpenAPIé©åˆä½œç‚ºæŒ‡æ•¸å’Œå¤§ç›¤æ•¸æ“šçš„ä¸»è¦ä¾†æº"
        )
    
    # æ€§èƒ½å„ªåŒ–å»ºè­°
    suggestions['performance_optimizations'].extend([
        "å¯¦æ–½æ•¸æ“šç·©å­˜æ©Ÿåˆ¶ï¼Œé¿å…é‡è¤‡è«‹æ±‚ç›¸åŒæ•¸æ“š",
        "ä½¿ç”¨ä¸¦è¡Œè™•ç†æå‡å¤šæ•¸æ“šæºç²å–æ•ˆç‡",
        "è¨­ç½®åˆç†çš„è«‹æ±‚é–“éš”ï¼Œé¿å…è¢«APIé™åˆ¶",
        "å»ºç«‹æ•¸æ“šå“è³ªç›£æ§å’Œè‡ªå‹•é‡è©¦æ©Ÿåˆ¶"
    ])
    
    return suggestions

# ç”Ÿæˆæ•´åˆå»ºè­°
integration_suggestions = generate_integration_suggestions({
    'technical': technical_data,
    'fundamental': fundamental_data
})

print(f"ğŸ”§ ç³»çµ±æ•´åˆå»ºè­°:")
print(f"   ç”Ÿæˆæ™‚é–“: {integration_suggestions['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")

print(f"\n   ğŸ“Š æ•¸æ“šæºå„ªå…ˆç´š:")
for source_type, source_name in integration_suggestions['data_source_priorities'].items():
    print(f"      {source_type}: {source_name}")

print(f"\n   ğŸš€ æ•´åˆå»ºè­°:")
for i, rec in enumerate(integration_suggestions['integration_recommendations'], 1):
    print(f"      {i}. {rec}")

print(f"\n   âš¡ æ€§èƒ½å„ªåŒ–å»ºè­°:")
for i, opt in enumerate(integration_suggestions['performance_optimizations'], 1):
    print(f"      {i}. {opt}")

# ============================================================================
# Cell 9: ç¸½çµå’Œä¸‹ä¸€æ­¥
# ============================================================================

print("\nğŸ¯ æ¼”ç¤ºç¸½çµ")
print("=" * 60)

# çµ±è¨ˆç¸½é«”çµæœ
total_successful_datasets = (
    sum(1 for df in technical_data.values() if not df.empty) +
    sum(1 for df in fundamental_data.values() if not df.empty)
)
total_datasets = len(technical_data) + len(fundamental_data)
total_records = (
    sum(len(df) for df in technical_data.values() if not df.empty) +
    sum(len(df) for df in fundamental_data.values() if not df.empty)
)

print(f"âœ… æ¼”ç¤ºå®Œæˆçµ±è¨ˆ:")
print(f"   æ¸¬è©¦è‚¡ç¥¨: {TEST_SYMBOL}")
print(f"   æ¸¬è©¦æœŸé–“: {START_DATE} - {END_DATE}")
print(f"   ç¸½æ•¸æ“šé›†: {total_datasets}")
print(f"   æˆåŠŸç²å–: {total_successful_datasets}")
print(f"   æˆåŠŸç‡: {total_successful_datasets/total_datasets:.1%}")
print(f"   ç¸½è¨˜éŒ„æ•¸: {total_records}")

print(f"\nğŸš€ ç³»çµ±å„ªå‹¢:")
print("   â€¢ å¤šæ•¸æ“šæºæ•´åˆç¢ºä¿æ•¸æ“šå®Œæ•´æ€§")
print("   â€¢ è‡ªå­¸èƒ½åŠ›æŒçºŒå„ªåŒ–æ•¸æ“šå“è³ª")
print("   â€¢ çµ±ä¸€æ¥å£ç°¡åŒ–æ•¸æ“šç²å–æµç¨‹")
print("   â€¢ è‡ªå‹•é‡è©¦å’ŒéŒ¯èª¤è™•ç†æ©Ÿåˆ¶")
print("   â€¢ æ”¯æ´å¤šç¨®æ•¸æ“šæ ¼å¼å’Œä¾†æº")

print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè­°:")
print("   â€¢ æ“´å±•æ›´å¤šæ•¸æ“šæº (ç±Œç¢¼é¢ã€äº‹ä»¶é¢ã€ç¸½ç¶“é¢)")
print("   â€¢ å¯¦æ–½å¯¦æ™‚æ•¸æ“šæ›´æ–°æ©Ÿåˆ¶")
print("   â€¢ å»ºç«‹æ•¸æ“šå“è³ªç›£æ§å„€è¡¨æ¿")
print("   â€¢ æ•´åˆæ©Ÿå™¨å­¸ç¿’æ¨¡å‹é€²è¡Œæ•¸æ“šé æ¸¬")
print("   â€¢ é–‹ç™¼Webç•Œé¢ä¾›ç”¨æˆ¶äº’å‹•ä½¿ç”¨")

print(f"\nğŸ‰ å°è‚¡å¤šæ•¸æ“šæºçˆ¬èŸ²ç³»çµ±æ¼”ç¤ºå®Œæˆï¼")
print("=" * 60)
