"""æ¸¬è©¦å„ªåŒ–å’Œç®¡ç†å·¥å…·

æ­¤æ¨¡çµ„æä¾›æ¸¬è©¦çš„å„ªåŒ–å’Œç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ¸¬è©¦æª”æ¡ˆå¤§å°æª¢æŸ¥
- æ¸¬è©¦è¦†è“‹ç‡åˆ†æ
- æ¸¬è©¦æ€§èƒ½ç›£æ§
- æ¸¬è©¦è³‡æ–™ç®¡ç†
- è‡ªå‹•åŒ–æ¸¬è©¦å ±å‘Š

ç¬¦åˆæ¸¬è©¦æ¨™æº–ï¼šâ‰¥80% è¦†è“‹ç‡ï¼ˆæ ¸å¿ƒæ¨¡çµ„ â‰¥90%ï¼‰ï¼Œæª”æ¡ˆ â‰¤300 è¡Œ
"""

import os
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import logging
import json
import time
from datetime import datetime

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


class TestOptimizer:
    """æ¸¬è©¦å„ªåŒ–å™¨
    
    æä¾›æ¸¬è©¦çš„å„ªåŒ–å’Œç®¡ç†åŠŸèƒ½ã€‚
    """
    
    # æ¸¬è©¦æ¨™æº–
    COVERAGE_THRESHOLDS = {
        "core_modules": 90,      # æ ¸å¿ƒæ¨¡çµ„è¦†è“‹ç‡è¦æ±‚
        "general_modules": 80,   # ä¸€èˆ¬æ¨¡çµ„è¦†è“‹ç‡è¦æ±‚
        "ui_modules": 70,        # UI æ¨¡çµ„è¦†è“‹ç‡è¦æ±‚
    }
    
    MAX_FILE_LINES = 300        # æœ€å¤§æª”æ¡ˆè¡Œæ•¸
    
    # æ ¸å¿ƒæ¨¡çµ„åˆ—è¡¨
    CORE_MODULES = [
        "src/core",
        "src/api",
        "src/portfolio",
        "src/risk",
        "src/trading",
        "src/data",
    ]
    
    def __init__(self, project_root: Optional[str] = None):
        """åˆå§‹åŒ–æ¸¬è©¦å„ªåŒ–å™¨
        
        Args:
            project_root: å°ˆæ¡ˆæ ¹ç›®éŒ„è·¯å¾‘
        """
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.tests_dir = self.project_root / "tests"
        self.src_dir = self.project_root / "src"
        
    def check_test_file_sizes(self) -> Dict[str, Any]:
        """æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆå¤§å°
        
        Returns:
            æª¢æŸ¥çµæœå­—å…¸
        """
        logger.info("æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆå¤§å°...")
        
        results = {
            "total_files": 0,
            "oversized_files": [],
            "compliant_files": [],
            "summary": {}
        }
        
        # éæ­·æ‰€æœ‰æ¸¬è©¦æª”æ¡ˆ
        for test_file in self.tests_dir.rglob("*.py"):
            if test_file.name.startswith("__"):
                continue
                
            try:
                with open(test_file, 'r', encoding='utf-8') as f:
                    lines = len(f.readlines())
                
                results["total_files"] += 1
                
                file_info = {
                    "path": str(test_file.relative_to(self.project_root)),
                    "lines": lines,
                    "compliant": lines <= self.MAX_FILE_LINES
                }
                
                if lines > self.MAX_FILE_LINES:
                    results["oversized_files"].append(file_info)
                    logger.warning(f"æ¸¬è©¦æª”æ¡ˆéå¤§: {test_file} ({lines} è¡Œ)")
                else:
                    results["compliant_files"].append(file_info)
                    
            except Exception as e:
                logger.error(f"è®€å–æ¸¬è©¦æª”æ¡ˆå¤±æ•— {test_file}: {e}")
        
        # ç”Ÿæˆæ‘˜è¦
        results["summary"] = {
            "total_files": results["total_files"],
            "oversized_count": len(results["oversized_files"]),
            "compliant_count": len(results["compliant_files"]),
            "compliance_rate": (
                len(results["compliant_files"]) / results["total_files"] * 100
                if results["total_files"] > 0 else 0
            )
        }
        
        logger.info(f"æ¸¬è©¦æª”æ¡ˆå¤§å°æª¢æŸ¥å®Œæˆ: {results['summary']}")
        return results
    
    def run_coverage_analysis(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ¸¬è©¦è¦†è“‹ç‡åˆ†æ
        
        Returns:
            è¦†è“‹ç‡åˆ†æçµæœ
        """
        logger.info("åŸ·è¡Œæ¸¬è©¦è¦†è“‹ç‡åˆ†æ...")
        
        try:
            # åŸ·è¡Œ pytest è¦†è“‹ç‡æª¢æŸ¥
            cmd = [
                sys.executable, "-m", "pytest",
                str(self.tests_dir),
                "--cov=src",
                "--cov-report=term-missing",
                "--cov-report=json:coverage.json",
                "--cov-report=html:htmlcov",
                "-v"
            ]
            
            start_time = time.time()
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=self.project_root,
                timeout=300  # 5åˆ†é˜è¶…æ™‚
            )
            execution_time = time.time() - start_time
            
            # è§£æè¦†è“‹ç‡çµæœ
            coverage_data = self._parse_coverage_results()
            
            return {
                "success": result.returncode == 0,
                "execution_time": execution_time,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "coverage_data": coverage_data,
                "timestamp": datetime.now().isoformat()
            }
            
        except subprocess.TimeoutExpired:
            logger.error("æ¸¬è©¦è¦†è“‹ç‡åˆ†æè¶…æ™‚")
            return {"success": False, "error": "æ¸¬è©¦åŸ·è¡Œè¶…æ™‚"}
        except Exception as e:
            logger.error(f"æ¸¬è©¦è¦†è“‹ç‡åˆ†æå¤±æ•—: {e}")
            return {"success": False, "error": str(e)}
    
    def _parse_coverage_results(self) -> Dict[str, Any]:
        """è§£æè¦†è“‹ç‡çµæœ
        
        Returns:
            è§£æå¾Œçš„è¦†è“‹ç‡æ•¸æ“š
        """
        coverage_file = self.project_root / "coverage.json"
        
        if not coverage_file.exists():
            logger.warning("è¦†è“‹ç‡ JSON æª”æ¡ˆä¸å­˜åœ¨")
            return {}
        
        try:
            with open(coverage_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # åˆ†ææ¨¡çµ„è¦†è“‹ç‡
            module_coverage = {}
            for file_path, file_data in data.get("files", {}).items():
                # åˆ¤æ–·æ¨¡çµ„é¡å‹
                module_type = self._classify_module(file_path)
                coverage_percent = file_data.get("summary", {}).get("percent_covered", 0)
                
                if module_type not in module_coverage:
                    module_coverage[module_type] = []
                
                module_coverage[module_type].append({
                    "file": file_path,
                    "coverage": coverage_percent,
                    "lines_covered": file_data.get("summary", {}).get("covered_lines", 0),
                    "lines_missing": file_data.get("summary", {}).get("missing_lines", 0),
                })
            
            # è¨ˆç®—å¹³å‡è¦†è“‹ç‡
            summary = {}
            for module_type, files in module_coverage.items():
                if files:
                    avg_coverage = sum(f["coverage"] for f in files) / len(files)
                    threshold = self.COVERAGE_THRESHOLDS.get(module_type, 80)
                    
                    summary[module_type] = {
                        "average_coverage": avg_coverage,
                        "threshold": threshold,
                        "compliant": avg_coverage >= threshold,
                        "file_count": len(files),
                        "files": files
                    }
            
            return {
                "total_coverage": data.get("totals", {}).get("percent_covered", 0),
                "module_coverage": module_coverage,
                "summary": summary
            }
            
        except Exception as e:
            logger.error(f"è§£æè¦†è“‹ç‡çµæœå¤±æ•—: {e}")
            return {}
    
    def _classify_module(self, file_path: str) -> str:
        """åˆ†é¡æ¨¡çµ„é¡å‹
        
        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            
        Returns:
            æ¨¡çµ„é¡å‹
        """
        for core_module in self.CORE_MODULES:
            if core_module in file_path:
                return "core_modules"
        
        if "ui" in file_path or "streamlit" in file_path:
            return "ui_modules"
        
        return "general_modules"
    
    def generate_test_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        
        Returns:
            æ¸¬è©¦å ±å‘Š
        """
        logger.info("ç”Ÿæˆæ¸¬è©¦å ±å‘Š...")
        
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size_results = self.check_test_file_sizes()
        
        # åŸ·è¡Œè¦†è“‹ç‡åˆ†æ
        coverage_results = self.run_coverage_analysis()
        
        # ç”Ÿæˆç¶œåˆå ±å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "file_size_check": file_size_results,
            "coverage_analysis": coverage_results,
            "recommendations": self._generate_recommendations(
                file_size_results, coverage_results
            )
        }
        
        # ä¿å­˜å ±å‘Š
        report_file = self.project_root / "test_optimization_report.json"
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"æ¸¬è©¦å ±å‘Šå·²ä¿å­˜: {report_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ¸¬è©¦å ±å‘Šå¤±æ•—: {e}")
        
        return report
    
    def _generate_recommendations(
        self, 
        file_size_results: Dict[str, Any], 
        coverage_results: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°
        
        Args:
            file_size_results: æª”æ¡ˆå¤§å°æª¢æŸ¥çµæœ
            coverage_results: è¦†è“‹ç‡åˆ†æçµæœ
            
        Returns:
            æ”¹é€²å»ºè­°åˆ—è¡¨
        """
        recommendations = []
        
        # æª”æ¡ˆå¤§å°å»ºè­°
        if file_size_results["oversized_files"]:
            recommendations.append(
                f"æœ‰ {len(file_size_results['oversized_files'])} å€‹æ¸¬è©¦æª”æ¡ˆè¶…é {self.MAX_FILE_LINES} è¡Œé™åˆ¶ï¼Œå»ºè­°æ‹†åˆ†"
            )
        
        # è¦†è“‹ç‡å»ºè­°
        if coverage_results.get("success") and coverage_results.get("coverage_data"):
            coverage_data = coverage_results["coverage_data"]
            
            for module_type, data in coverage_data.get("summary", {}).items():
                if not data["compliant"]:
                    recommendations.append(
                        f"{module_type} è¦†è“‹ç‡ {data['average_coverage']:.1f}% "
                        f"ä½æ–¼è¦æ±‚çš„ {data['threshold']}%ï¼Œéœ€è¦å¢åŠ æ¸¬è©¦"
                    )
        
        # æ€§èƒ½å»ºè­°
        execution_time = coverage_results.get("execution_time", 0)
        if execution_time > 60:  # è¶…é 1 åˆ†é˜
            recommendations.append(
                f"æ¸¬è©¦åŸ·è¡Œæ™‚é–“ {execution_time:.1f}s éé•·ï¼Œå»ºè­°å„ªåŒ–æ¸¬è©¦æ€§èƒ½"
            )
        
        if not recommendations:
            recommendations.append("æ¸¬è©¦ç‹€æ³è‰¯å¥½ï¼Œç¬¦åˆæ‰€æœ‰æ¨™æº–")
        
        return recommendations


def main():
    """ä¸»å‡½æ•¸"""
    optimizer = TestOptimizer()
    
    print("ğŸš€ é–‹å§‹æ¸¬è©¦å„ªåŒ–åˆ†æ...")
    report = optimizer.generate_test_report()
    
    print("\nğŸ“Š æ¸¬è©¦å„ªåŒ–å ±å‘Š")
    print("=" * 50)
    
    # é¡¯ç¤ºæª”æ¡ˆå¤§å°æª¢æŸ¥çµæœ
    file_summary = report["file_size_check"]["summary"]
    print(f"\nğŸ“ æª”æ¡ˆå¤§å°æª¢æŸ¥:")
    print(f"  ç¸½æª”æ¡ˆæ•¸: {file_summary['total_files']}")
    print(f"  ç¬¦åˆæ¨™æº–: {file_summary['compliant_count']}")
    print(f"  è¶…éé™åˆ¶: {file_summary['oversized_count']}")
    print(f"  åˆè¦ç‡: {file_summary['compliance_rate']:.1f}%")
    
    # é¡¯ç¤ºè¦†è“‹ç‡çµæœ
    if report["coverage_analysis"].get("success"):
        coverage_data = report["coverage_analysis"]["coverage_data"]
        total_coverage = coverage_data.get("total_coverage", 0)
        print(f"\nğŸ“Š æ¸¬è©¦è¦†è“‹ç‡:")
        print(f"  ç¸½è¦†è“‹ç‡: {total_coverage:.1f}%")
        
        for module_type, data in coverage_data.get("summary", {}).items():
            status = "âœ…" if data["compliant"] else "âŒ"
            print(f"  {status} {module_type}: {data['average_coverage']:.1f}% "
                  f"(è¦æ±‚: {data['threshold']}%)")
    
    # é¡¯ç¤ºå»ºè­°
    print(f"\nğŸ’¡ æ”¹é€²å»ºè­°:")
    for i, recommendation in enumerate(report["recommendations"], 1):
        print(f"  {i}. {recommendation}")
    
    print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜è‡³: test_optimization_report.json")


if __name__ == "__main__":
    main()
