"""
è² è¼‰æ¸¬è©¦

æ­¤æ¨¡çµ„æ¸¬è©¦ API åœ¨ä¸åŒè² è¼‰æ¢ä»¶ä¸‹çš„æ•ˆèƒ½è¡¨ç¾ï¼ŒåŒ…æ‹¬ä½µç™¼ç”¨æˆ¶å’ŒæŒçºŒè² è¼‰æ¸¬è©¦ã€‚
"""

import pytest
import asyncio
from typing import Dict, List, Any

from fastapi.testclient import TestClient

from tests.performance.utils.load_tester import LoadTester, LoadTestConfig
from tests.performance.utils.performance_monitor import PerformanceMonitor
from tests.performance.utils.report_generator import ReportGenerator


@pytest.mark.performance
@pytest.mark.load_test
class TestLoadTesting:
    """è² è¼‰æ¸¬è©¦é¡"""

    def test_light_load_performance(
        self, test_client: TestClient, auth_headers: Dict[str, str]
    ):
        """è¼•è² è¼‰æ¸¬è©¦ - 5 å€‹ä½µç™¼ç”¨æˆ¶"""
        load_tester = LoadTester()

        # å®šç¾©æ¸¬è©¦å ´æ™¯
        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/info"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
        ]

        # é…ç½®è¼•è² è¼‰æ¸¬è©¦
        config = LoadTestConfig(
            concurrent_users=5,
            test_duration=30,  # 30 ç§’
            ramp_up_time=5,  # 5 ç§’å…§å•Ÿå‹•æ‰€æœ‰ç”¨æˆ¶
            think_time=0.5,  # ç”¨æˆ¶é–“éš” 0.5 ç§’
        )

        # åŸ·è¡Œè² è¼‰æ¸¬è©¦
        result = load_tester.run_load_test(test_scenarios, config, auth_headers)

        # é©—è­‰çµæœ
        assert (
            result.avg_response_time < 100
        ), f"è¼•è² è¼‰ä¸‹å¹³å‡å›æ‡‰æ™‚é–“ {result.avg_response_time:.1f}ms è¶…éé–¾å€¼"
        assert result.throughput > 10, f"ååé‡ {result.throughput:.1f} req/s éä½"
        assert result.failed_requests == 0, f"ç™¼ç¾ {result.failed_requests} å€‹å¤±æ•—è«‹æ±‚"

        print(f"âœ… è¼•è² è¼‰æ¸¬è©¦é€šé:")
        print(f"   ä½µç™¼ç”¨æˆ¶: {config.concurrent_users}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms")
        print(f"   ååé‡: {result.throughput:.1f} req/s")
        print(
            f"   æˆåŠŸç‡: {(result.successful_requests/result.total_requests*100):.1f}%"
        )

    def test_medium_load_performance(
        self, test_client: TestClient, auth_headers: Dict[str, str]
    ):
        """ä¸­ç­‰è² è¼‰æ¸¬è©¦ - 25 å€‹ä½µç™¼ç”¨æˆ¶"""
        load_tester = LoadTester()

        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
            {"method": "GET", "url": "/api/v1/strategies/", "headers": auth_headers},
            {
                "method": "POST",
                "url": "/api/v1/auth/login",
                "json": {"username": "admin", "password": "admin123"},
            },
        ]

        config = LoadTestConfig(
            concurrent_users=25, test_duration=60, ramp_up_time=10, think_time=1.0
        )

        result = load_tester.run_load_test(test_scenarios, config, auth_headers)

        # ä¸­ç­‰è² è¼‰çš„å¯¬é¬†æ¨™æº–
        assert result.avg_response_time < 150, f"ä¸­ç­‰è² è¼‰ä¸‹å¹³å‡å›æ‡‰æ™‚é–“è¶…éé–¾å€¼"
        assert result.throughput > 20, f"ä¸­ç­‰è² è¼‰ä¸‹ååé‡éä½"
        assert (
            result.successful_requests / result.total_requests
        ) > 0.95, "æˆåŠŸç‡ä½æ–¼ 95%"

        print(f"âœ… ä¸­ç­‰è² è¼‰æ¸¬è©¦é€šé:")
        print(f"   ä½µç™¼ç”¨æˆ¶: {config.concurrent_users}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms")
        print(f"   P95 å›æ‡‰æ™‚é–“: {result.p95_response_time:.1f}ms")
        print(f"   ååé‡: {result.throughput:.1f} req/s")
        print(
            f"   æˆåŠŸç‡: {(result.successful_requests/result.total_requests*100):.1f}%"
        )

    def test_heavy_load_performance(
        self, test_client: TestClient, auth_headers: Dict[str, str]
    ):
        """é‡è² è¼‰æ¸¬è©¦ - 50 å€‹ä½µç™¼ç”¨æˆ¶"""
        load_tester = LoadTester()

        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
            {"method": "GET", "url": "/api/v1/strategies/", "headers": auth_headers},
            {"method": "GET", "url": "/api/v1/models/", "headers": auth_headers},
            {
                "method": "POST",
                "url": "/api/v1/auth/login",
                "json": {"username": "admin", "password": "admin123"},
            },
        ]

        config = LoadTestConfig(
            concurrent_users=50, test_duration=90, ramp_up_time=15, think_time=1.5
        )

        result = load_tester.run_load_test(test_scenarios, config, auth_headers)

        # é‡è² è¼‰çš„æ›´å¯¬é¬†æ¨™æº–
        assert result.avg_response_time < 200, f"é‡è² è¼‰ä¸‹å¹³å‡å›æ‡‰æ™‚é–“è¶…éé–¾å€¼"
        assert result.throughput > 30, f"é‡è² è¼‰ä¸‹ååé‡éä½"
        assert (
            result.successful_requests / result.total_requests
        ) > 0.90, "æˆåŠŸç‡ä½æ–¼ 90%"

        print(f"âœ… é‡è² è¼‰æ¸¬è©¦é€šé:")
        print(f"   ä½µç™¼ç”¨æˆ¶: {config.concurrent_users}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms")
        print(f"   P95 å›æ‡‰æ™‚é–“: {result.p95_response_time:.1f}ms")
        print(f"   P99 å›æ‡‰æ™‚é–“: {result.p99_response_time:.1f}ms")
        print(f"   ååé‡: {result.throughput:.1f} req/s")
        print(
            f"   æˆåŠŸç‡: {(result.successful_requests/result.total_requests*100):.1f}%"
        )

    @pytest.mark.asyncio
    async def test_async_load_performance(self, auth_headers: Dict[str, str]):
        """ç•°æ­¥è² è¼‰æ¸¬è©¦"""
        load_tester = LoadTester("http://127.0.0.1:8000")

        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/info"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
        ]

        config = LoadTestConfig(
            concurrent_users=20, test_duration=45, ramp_up_time=5, think_time=0.5
        )

        result = await load_tester.run_async_load_test(
            test_scenarios, config, auth_headers
        )

        assert result.avg_response_time < 120, "ç•°æ­¥è² è¼‰æ¸¬è©¦å›æ‡‰æ™‚é–“è¶…éé–¾å€¼"
        assert result.throughput > 15, "ç•°æ­¥è² è¼‰æ¸¬è©¦ååé‡éä½"

        print(f"âœ… ç•°æ­¥è² è¼‰æ¸¬è©¦é€šé:")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms")
        print(f"   ååé‡: {result.throughput:.1f} req/s")

    def test_stress_testing(
        self, test_client: TestClient, auth_headers: Dict[str, str]
    ):
        """å£“åŠ›æ¸¬è©¦ - æ¸¬è©¦ç³»çµ±æ¥µé™"""
        load_tester = LoadTester()

        # ç°¡åŒ–çš„æ¸¬è©¦å ´æ™¯ï¼Œå°ˆæ³¨æ–¼æ ¸å¿ƒç«¯é»
        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
        ]

        config = LoadTestConfig(
            concurrent_users=100,  # é«˜ä½µç™¼
            test_duration=60,
            ramp_up_time=20,
            think_time=0.1,  # æœ€å°é–“éš”
        )

        result = load_tester.run_load_test(test_scenarios, config, auth_headers)

        # å£“åŠ›æ¸¬è©¦çš„åŸºæœ¬è¦æ±‚
        assert result.avg_response_time < 500, f"å£“åŠ›æ¸¬è©¦ä¸‹å¹³å‡å›æ‡‰æ™‚é–“éé•·"
        assert (
            result.successful_requests / result.total_requests
        ) > 0.80, "å£“åŠ›æ¸¬è©¦æˆåŠŸç‡ä½æ–¼ 80%"

        print(f"âœ… å£“åŠ›æ¸¬è©¦å®Œæˆ:")
        print(f"   ä½µç™¼ç”¨æˆ¶: {config.concurrent_users}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms")
        print(f"   æœ€å¤§å›æ‡‰æ™‚é–“: {result.max_response_time:.1f}ms")
        print(f"   ååé‡: {result.throughput:.1f} req/s")
        print(
            f"   æˆåŠŸç‡: {(result.successful_requests/result.total_requests*100):.1f}%"
        )
        print(f"   å¤±æ•—è«‹æ±‚: {result.failed_requests}")

    def test_endurance_testing(
        self, test_client: TestClient, auth_headers: Dict[str, str]
    ):
        """è€ä¹…æ€§æ¸¬è©¦ - é•·æ™‚é–“é‹è¡Œ"""
        load_tester = LoadTester()

        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
        ]

        config = LoadTestConfig(
            concurrent_users=10,
            test_duration=300,  # 5 åˆ†é˜
            ramp_up_time=30,
            think_time=2.0,
        )

        result = load_tester.run_load_test(test_scenarios, config, auth_headers)

        # è€ä¹…æ€§æ¸¬è©¦é—œæ³¨ç©©å®šæ€§
        assert result.avg_response_time < 150, "è€ä¹…æ€§æ¸¬è©¦å¹³å‡å›æ‡‰æ™‚é–“è¶…éé–¾å€¼"
        assert (
            result.successful_requests / result.total_requests
        ) > 0.95, "è€ä¹…æ€§æ¸¬è©¦æˆåŠŸç‡éä½"

        print(f"âœ… è€ä¹…æ€§æ¸¬è©¦é€šé:")
        print(f"   æ¸¬è©¦æ™‚é•·: {result.duration:.1f}s")
        print(f"   ç¸½è«‹æ±‚æ•¸: {result.total_requests:,}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms")
        print(
            f"   æˆåŠŸç‡: {(result.successful_requests/result.total_requests*100):.1f}%"
        )

    @pytest.mark.parametrize("concurrent_users", [1, 5, 10, 25, 50])
    def test_scalability_analysis(
        self,
        test_client: TestClient,
        auth_headers: Dict[str, str],
        concurrent_users: int,
    ):
        """å¯æ“´å±•æ€§åˆ†æ - æ¸¬è©¦ä¸åŒä½µç™¼ç´šåˆ¥"""
        load_tester = LoadTester()

        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
        ]

        config = LoadTestConfig(
            concurrent_users=concurrent_users,
            test_duration=30,
            ramp_up_time=5,
            think_time=1.0,
        )

        result = load_tester.run_load_test(test_scenarios, config, auth_headers)

        # è¨˜éŒ„å¯æ“´å±•æ€§æ•¸æ“š
        print(f"ğŸ“Š å¯æ“´å±•æ€§æ•¸æ“š - {concurrent_users} ç”¨æˆ¶:")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms")
        print(f"   ååé‡: {result.throughput:.1f} req/s")
        print(
            f"   æˆåŠŸç‡: {(result.successful_requests/result.total_requests*100):.1f}%"
        )

        # åŸºæœ¬é©—è­‰
        assert result.avg_response_time < 300, f"{concurrent_users} ç”¨æˆ¶ä¸‹å›æ‡‰æ™‚é–“éé•·"
        assert (
            result.successful_requests / result.total_requests
        ) > 0.85, f"{concurrent_users} ç”¨æˆ¶ä¸‹æˆåŠŸç‡éä½"

    def test_generate_load_test_report(
        self, test_client: TestClient, auth_headers: Dict[str, str]
    ):
        """ç”Ÿæˆè² è¼‰æ¸¬è©¦å ±å‘Š"""
        report_generator = ReportGenerator()
        load_tester = LoadTester()
        results = []

        # åŸ·è¡Œä¸åŒè² è¼‰ç´šåˆ¥çš„æ¸¬è©¦
        test_configs = [
            ("è¼•è² è¼‰", 5, 30),
            ("ä¸­ç­‰è² è¼‰", 15, 45),
            ("é‡è² è¼‰", 30, 60),
        ]

        test_scenarios = [
            {"method": "GET", "url": "/health"},
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
        ]

        for test_name, users, duration in test_configs:
            config = LoadTestConfig(
                concurrent_users=users,
                test_duration=duration,
                ramp_up_time=10,
                think_time=1.0,
            )

            result = load_tester.run_load_test(test_scenarios, config, auth_headers)
            result.test_name = f"{test_name} ({users} ç”¨æˆ¶)"
            results.append(result)

        # ç”Ÿæˆå ±å‘Š
        html_report = report_generator.generate_performance_report(
            results, "load_test_report", "html"
        )
        json_report = report_generator.generate_performance_report(
            results, "load_test_report", "json"
        )

        print(f"âœ… è² è¼‰æ¸¬è©¦å ±å‘Šå·²ç”Ÿæˆ:")
        print(f"   HTML: {html_report}")
        print(f"   JSON: {json_report}")

        # é©—è­‰å ±å‘Šæª”æ¡ˆ
        import os

        assert os.path.exists(html_report), "HTML å ±å‘Šæª”æ¡ˆä¸å­˜åœ¨"
        assert os.path.exists(json_report), "JSON å ±å‘Šæª”æ¡ˆä¸å­˜åœ¨"


@pytest.mark.performance
@pytest.mark.load_test
class TestSpecificEndpointLoad:
    """ç‰¹å®šç«¯é»è² è¼‰æ¸¬è©¦"""

    def test_auth_endpoint_load(self, test_client: TestClient):
        """èªè­‰ç«¯é»è² è¼‰æ¸¬è©¦"""
        load_tester = LoadTester()

        test_scenarios = [
            {
                "method": "POST",
                "url": "/api/v1/auth/login",
                "json": {"username": "admin", "password": "admin123"},
            }
        ]

        config = LoadTestConfig(
            concurrent_users=20,
            test_duration=60,
            ramp_up_time=10,
            think_time=2.0,  # èªè­‰è«‹æ±‚é–“éš”è¼ƒé•·
        )

        result = load_tester.run_load_test(test_scenarios, config)

        assert result.avg_response_time < 200, "èªè­‰ç«¯é»è² è¼‰æ¸¬è©¦å›æ‡‰æ™‚é–“è¶…éé–¾å€¼"
        assert (
            result.successful_requests / result.total_requests
        ) > 0.95, "èªè­‰ç«¯é»æˆåŠŸç‡éä½"

        print(
            f"âœ… èªè­‰ç«¯é»è² è¼‰æ¸¬è©¦é€šé - å¹³å‡å›æ‡‰æ™‚é–“: {result.avg_response_time:.1f}ms"
        )

    def test_data_api_load(self, test_client: TestClient, auth_headers: Dict[str, str]):
        """è³‡æ–™ API è² è¼‰æ¸¬è©¦"""
        load_tester = LoadTester()

        test_scenarios = [
            {"method": "GET", "url": "/api/v1/data/", "headers": auth_headers},
            {"method": "GET", "url": "/api/v1/data/sources", "headers": auth_headers},
            {
                "method": "GET",
                "url": "/api/v1/data/quality/summary",
                "headers": auth_headers,
            },
        ]

        config = LoadTestConfig(
            concurrent_users=30, test_duration=90, ramp_up_time=15, think_time=1.0
        )

        result = load_tester.run_load_test(test_scenarios, config, auth_headers)

        assert result.avg_response_time < 150, "è³‡æ–™ API è² è¼‰æ¸¬è©¦å›æ‡‰æ™‚é–“è¶…éé–¾å€¼"
        assert result.throughput > 25, "è³‡æ–™ API ååé‡éä½"

        print(f"âœ… è³‡æ–™ API è² è¼‰æ¸¬è©¦é€šé - ååé‡: {result.throughput:.1f} req/s")
