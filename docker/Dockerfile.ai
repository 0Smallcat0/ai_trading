# AI Trading System - AI Processing Container
# Phase 3 Containerized Deployment Strategy
# Dedicated container for heavy AI processing with memory limits

FROM python:3.10-slim

# Set working directory
WORKDIR /app

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV TF_CPP_MIN_LOG_LEVEL=2
ENV CUDA_VISIBLE_DEVICES=""

# Install system dependencies for AI frameworks
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    make \
    curl \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user
RUN useradd -m -u 1000 aiuser && \
    chown -R aiuser:aiuser /app

# Copy AI-specific requirements
COPY requirements-ai.txt .

# Install AI frameworks with memory optimization
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements-ai.txt

# Copy application code (AI modules only)
COPY src/ai/ ./src/ai/
COPY src/core/ ./src/core/
COPY src/ui/utils/ ./src/ui/utils/
COPY config/ ./config/
COPY .env .env

# Create necessary directories
RUN mkdir -p logs data models && \
    chown -R aiuser:aiuser /app

# Switch to non-root user
USER aiuser

# Health check for AI service
HEALTHCHECK --interval=60s --timeout=30s --start-period=10s --retries=3 \
    CMD python -c "import sys; sys.exit(0)"

# Memory and resource limits (to be set in docker-compose)
# --memory=1024m --cpus=2.0

# Start AI processing service
CMD ["python", "-m", "src.ai.ai_service_worker"]
